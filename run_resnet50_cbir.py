import argparse
import os
import random
import uuid
from tqdm import tqdm
import matplotlib.pyplot as plt
from PIL import Image

from src.datasets.caltech_256 import get_caltech256_datasets
from src.featuring.resnet50 import get_feature_extractor, get_image_transform, extract_features
from src.storage.ChromaDBStore import ChromaDBStore

# --- CONFIGURATION ---
DATASET_PATH = "data/caltech-256/256_ObjectCategories"
DB_PATH = "./chroma_db"
COLLECTION_NAME = "caltech256_resnet50"

def index_images(collection_store, model, transform):
    """
    Duy·ªát qua dataset, tr√≠ch xu·∫•t feature v√† l∆∞u v√†o ChromaDB.
    """
    print(f"\n--- B·∫Øt ƒë·∫ßu qu√° tr√¨nh Indexing ---")

    if not os.path.exists(DATASET_PATH):
        print(f"L·ªói: Th∆∞ m·ª•c dataset kh√¥ng t·ªìn t·∫°i t·∫°i '{DATASET_PATH}'.")
        return

    if collection_store.count() > 0:
        user_input = input(f"Collection '{COLLECTION_NAME}' ƒë√£ c√≥ {collection_store.count()} ·∫£nh. X√≥a v√† index l·∫°i? (y/n): ")
        if user_input.lower() != 'y':
            print("B·ªè qua indexing.")
            return
        print(f"X√≥a collection c≈© '{COLLECTION_NAME}'...")
        collection_store.client.delete_collection(name=COLLECTION_NAME)
        collection_store.collection = collection_store.client.get_or_create_collection(
            name=COLLECTION_NAME,
            metadata={"hnsw:space": "cosine"}
        )
    
    train_dataset, _ = get_caltech256_datasets(DATASET_PATH)

    batch_size = 100
    features_batch, metadatas_batch, ids_batch = [], [], []

    total_images = len(train_dataset)
    for i in tqdm(range(total_images), desc="üñºÔ∏è  ƒêang tr√≠ch xu·∫•t features"):
        image_path, _ = train_dataset.dataset.samples[train_dataset.indices[i]]
        feature_vector = extract_features(image_path, model, transform)
        
        if feature_vector is not None:
            features_batch.append(feature_vector)
            metadatas_batch.append({"filepath": image_path})
            ids_batch.append(str(uuid.uuid4()))

        if len(features_batch) >= batch_size or i == total_images - 1:
            if features_batch:
                collection_store.add(metadatas=metadatas_batch, features=features_batch, ids=ids_batch)
                features_batch, metadatas_batch, ids_batch = [], [], []

    print(f"‚úÖ Indexing ho√†n t·∫•t! Collection hi·ªán c√≥ {collection_store.count()} ·∫£nh.")

def search_similar_images(query_image_path, collection_store, model, transform, n_results=5):
    if not os.path.exists(query_image_path):
        print(f"L·ªói: File ·∫£nh truy v·∫•n kh√¥ng t·ªìn t·∫°i t·∫°i '{query_image_path}'")
        return

    print(f"\n--- T√¨m ki·∫øm {n_results} ·∫£nh t∆∞∆°ng ƒë·ªìng v·ªõi: {os.path.basename(query_image_path)} ---")
    
    query_vector = extract_features(query_image_path, model, transform)
    if query_vector is None:
        return

    results = collection_store.search(feature=query_vector, k=n_results)
    
    print("\n--- üèÜ K·∫øt qu·∫£ t√¨m ki·∫øm (d·∫°ng vƒÉn b·∫£n) ---")
    if not results:
        print("Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ n√†o.")
        return
        
    for i, result in enumerate(results):
        print(f"  - H·∫°ng {i+1}: {result.image} (Kho·∫£ng c√°ch: {result.score:.4f})")

    # --- Hi·ªÉn th·ªã k·∫øt qu·∫£ b·∫±ng Matplotlib ---
    try:
        query_img = Image.open(query_image_path).convert("RGB")

        fig, axs = plt.subplots(1, n_results + 1, figsize=(20, 5))
        fig.suptitle('K·∫øt qu·∫£ t√¨m ki·∫øm', fontsize=20)

        # Hi·ªÉn th·ªã ·∫£nh query
        axs[0].imshow(query_img)
        axs[0].set_title("·∫¢nh truy v·∫•n")
        axs[0].axis('off')

        # Hi·ªÉn th·ªã c√°c ·∫£nh k·∫øt qu·∫£
        for i, result in enumerate(results):
            result_img_path = result.image
            if os.path.exists(result_img_path):
                result_img = Image.open(result_img_path).convert("RGB")
                axs[i + 1].imshow(result_img)
                axs[i + 1].set_title(f"H·∫°ng {i+1}\nDist: {result.score:.4f}")
                axs[i + 1].axis('off')
            else:
                print(f"Warning: Kh√¥ng t√¨m th·∫•y file ·∫£nh k·∫øt qu·∫£ t·∫°i {result_img_path}")
                axs[i + 1].text(0.5, 0.5, 'Image not found', ha='center', va='center')
                axs[i + 1].axis('off')

        plt.tight_layout()
        plt.show()
    except Exception as e:
        print(f"\n‚ö†Ô∏è ƒê√£ x·∫£y ra l·ªói khi c·ªë g·∫Øng hi·ªÉn th·ªã ·∫£nh: {e}")


def main():
    parser = argparse.ArgumentParser(description="H·ªá th·ªëng CBIR d√πng ResNet50 v√† ChromaDB.")
    parser.add_argument("--mode", type=str, required=True, choices=['index', 'search'], help="Ch·∫ø ƒë·ªô ch·∫°y: 'index' ƒë·ªÉ t·∫°o v√† l∆∞u features, 'search' ƒë·ªÉ t√¨m ·∫£nh.")
    parser.add_argument("--query_image", type=str, help="ƒê∆∞·ªùng d·∫´n ƒë·∫øn ·∫£nh truy v·∫•n (b·∫Øt bu·ªôc ·ªü ch·∫ø ƒë·ªô 'search').")
    parser.add_argument("--n_results", type=int, default=5, help="S·ªë l∆∞·ª£ng k·∫øt qu·∫£ t√¨m ki·∫øm (ch·ªâ d√πng ·ªü ch·∫ø ƒë·ªô 'search').")
    args = parser.parse_args()

    print("T·∫£i m√¥ h√¨nh v√† image transform...")
    feature_extractor_model = get_feature_extractor()
    image_transform = get_image_transform()
    
    print("K·∫øt n·ªëi t·ªõi ChromaDB...")
    db_store = ChromaDBStore(db_path=DB_PATH, collection_name=COLLECTION_NAME)

    if args.mode == 'index':
        index_images(db_store, feature_extractor_model, image_transform)
    elif args.mode == 'search':
        if not args.query_image:
            print("L·ªói: ƒê·ªëi s·ªë --query_image l√† b·∫Øt bu·ªôc khi ch·∫°y ·ªü ch·∫ø ƒë·ªô 'search'.")
            parser.print_help()
            return

        if db_store.count() == 0:
            print("L·ªói: C∆° s·ªü d·ªØ li·ªáu tr·ªëng. Vui l√≤ng ch·∫°y ch·∫ø ƒë·ªô 'index' tr∆∞·ªõc.")
            return
        search_similar_images(args.query_image, db_store, feature_extractor_model, image_transform, args.n_results)

if __name__ == "__main__":
    main() 