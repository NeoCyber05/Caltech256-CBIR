{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T04:18:26.070588Z",
     "start_time": "2025-07-12T04:18:18.901127Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.datasets.caltech256 import Caltech256DataModule\n",
    "from src.featuring.rgb_histogram import RGBHistogram\n",
    "from src.storage.VectorDBStore import VectorDBStore\n",
    "from src.retrieval.KNN import KNNRetrieval\n",
    "from src.pipeline import CBIR\n",
    "from src.metrics import average_precision, recall, hit_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84c605e062ed5179",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T04:18:30.921220Z",
     "start_time": "2025-07-12T04:18:30.910666Z"
    }
   },
   "outputs": [],
   "source": [
    "os.makedirs('out', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c00ce3cb06df4f",
   "metadata": {},
   "source": [
    "# INDEXING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f730d283fee6a54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T18:23:01.896733Z",
     "start_time": "2025-07-11T15:59:32.007359Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Dataset root: D:\\AI\\Food-CBIR\\src\\evaluation\\data\\caltech-256\\256_ObjectCategories\n",
      "🔍 Exists: True\n",
      "📂 Found 256 valid categories\n",
      "📊 Loaded 29780 total images from 256 classes\n",
      "📋 Train: 23824 images\n",
      "📂 Found 256 valid categories\n",
      "📊 Loaded 29780 total images from 256 classes\n",
      "📋 Test: 5956 images\n",
      "Train: 23824, Test: 5956\n",
      "🧪 Testing 3 bins × 2 h_types × 2 metrics = 12 combinations\n",
      "\n",
      "🔬 Testing: n_bin=4, h_type=global, metric=cosine\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (4bin_global_cosine): 100%|██████████| 745/745 [04:09<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 249.59s\n",
      "💾 Model saved: 6.14 MB\n",
      "\n",
      "🔬 Testing: n_bin=4, h_type=global, metric=euclidean\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (4bin_global_euclidean): 100%|██████████| 745/745 [02:23<00:00,  5.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 143.44s\n",
      "💾 Model saved: 6.14 MB\n",
      "\n",
      "🔬 Testing: n_bin=4, h_type=region, metric=cosine\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (4bin_region_cosine): 100%|██████████| 745/745 [05:22<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 322.25s\n",
      "💾 Model saved: 39.16 MB\n",
      "\n",
      "🔬 Testing: n_bin=4, h_type=region, metric=euclidean\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (4bin_region_euclidean): 100%|██████████| 745/745 [05:15<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 315.50s\n",
      "💾 Model saved: 39.17 MB\n",
      "\n",
      "🔬 Testing: n_bin=8, h_type=global, metric=cosine\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (8bin_global_cosine): 100%|██████████| 745/745 [02:15<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 135.52s\n",
      "💾 Model saved: 32.44 MB\n",
      "\n",
      "🔬 Testing: n_bin=8, h_type=global, metric=euclidean\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (8bin_global_euclidean): 100%|██████████| 745/745 [03:48<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 228.55s\n",
      "💾 Model saved: 32.44 MB\n",
      "\n",
      "🔬 Testing: n_bin=8, h_type=region, metric=cosine\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (8bin_region_cosine): 100%|██████████| 745/745 [04:43<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 283.92s\n",
      "💾 Model saved: 163.37 MB\n",
      "\n",
      "🔬 Testing: n_bin=8, h_type=region, metric=euclidean\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (8bin_region_euclidean): 100%|██████████| 745/745 [04:53<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 293.81s\n",
      "💾 Model saved: 163.35 MB\n",
      "\n",
      "🔬 Testing: n_bin=12, h_type=global, metric=cosine\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (12bin_global_cosine): 100%|██████████| 745/745 [05:40<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 340.83s\n",
      "💾 Model saved: 77.95 MB\n",
      "\n",
      "🔬 Testing: n_bin=12, h_type=global, metric=euclidean\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (12bin_global_euclidean): 100%|██████████| 745/745 [06:20<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 380.95s\n",
      "💾 Model saved: 77.96 MB\n",
      "\n",
      "🔬 Testing: n_bin=12, h_type=region, metric=cosine\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (12bin_region_cosine): 100%|██████████| 745/745 [12:58<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 778.45s\n",
      "💾 Model saved: 342.13 MB\n",
      "\n",
      "🔬 Testing: n_bin=12, h_type=region, metric=euclidean\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (12bin_region_euclidean): 100%|██████████| 745/745 [13:07<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 787.76s\n",
      "💾 Model saved: 342.10 MB\n",
      "\n",
      "✅ Completed indexing for all 12 combinations!\n"
     ]
    }
   ],
   "source": [
    "TRAIN_SIZE = 24607  # Số lượng ảnh để index\n",
    "TEST_SIZE = 1000   # Giảm test size để test nhanh hơn với nhiều combinations\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Khởi tạo dataset\n",
    "import os\n",
    "root_path = os.path.abspath('data/caltech-256/256_ObjectCategories')\n",
    "print(f\"🔍 Dataset root: {root_path}\")\n",
    "print(f\"🔍 Exists: {os.path.exists(root_path)}\")\n",
    "data_module = Caltech256DataModule(batch_size=32, root=root_path)\n",
    "data_module.setup()\n",
    "train_loader = data_module.train_dataloader()\n",
    "test_loader = data_module.test_dataloader()\n",
    "\n",
    "# Tất cả combinations để test\n",
    "n_bins = [4, 8, 12]\n",
    "h_types = [\"global\", \"region\"]\n",
    "metrics = [\"cosine\", \"euclidean\"]\n",
    "\n",
    "print(f\"🧪 Testing {len(n_bins)} bins × {len(h_types)} h_types × {len(metrics)} metrics = {len(n_bins)*len(h_types)*len(metrics)} combinations\")\n",
    "\n",
    "# Hàm để test một combination\n",
    "def test_combination(n_bin, h_type, metric):\n",
    "    config_name = f\"{n_bin}bin_{h_type}_{metric}\"\n",
    "    print(f\"\\n🔬 Testing: n_bin={n_bin}, h_type={h_type}, metric={metric}\")\n",
    "    \n",
    "    # Khởi tạo CBIR pipeline \n",
    "    feature_extractor = RGBHistogram(n_bin=n_bin, h_type=h_type)\n",
    "    retrieval = KNNRetrieval(metric=metric)\n",
    "    storage = VectorDBStore(retrieval)\n",
    "    cbir = CBIR(feature_extractor, storage)\n",
    "    \n",
    "    # Indexing\n",
    "    print(f\"Indexing {TRAIN_SIZE} images...\")\n",
    "    start = time()\n",
    "    indexed = 0\n",
    "    \n",
    "    for images, labels, _ in tqdm(train_loader, desc=f\"Indexing ({config_name})\"):\n",
    "        if indexed >= TRAIN_SIZE:\n",
    "            break\n",
    "    \n",
    "        if device.type == \"cuda\":\n",
    "            images = images.to(device)\n",
    "    \n",
    "        count = min(len(images), TRAIN_SIZE - indexed)\n",
    "        images = images[:count]\n",
    "        images = (images.cpu().numpy().transpose(0, 2, 3, 1) * 255).astype(np.uint8)\n",
    "    \n",
    "        cbir.add_images(images)\n",
    "        indexed += count\n",
    "    \n",
    "    indexing_time = time() - start\n",
    "    print(f\"Indexed {indexed} images in {indexing_time:.2f}s\")\n",
    "    \n",
    "    # Save model\n",
    "    model_path = f'out/caltech256_model_{config_name}.pkl.gz'\n",
    "    with gzip.open(model_path, 'wb') as f:\n",
    "        pickle.dump(cbir, f)\n",
    "    \n",
    "    file_size = os.path.getsize(model_path) / 1024 / 1024\n",
    "    print(f\"💾 Model saved: {file_size:.2f} MB\")\n",
    "    \n",
    "    return cbir, indexing_time, file_size, indexed, config_name\n",
    "\n",
    "# Test tất cả combinations\n",
    "results_comparison = {}\n",
    "models = {}\n",
    "all_configs = []\n",
    "\n",
    "for n_bin in n_bins:\n",
    "    for h_type in h_types:\n",
    "        for metric in metrics:\n",
    "            config_name = f\"{n_bin}bin_{h_type}_{metric}\"\n",
    "            all_configs.append((n_bin, h_type, metric, config_name))\n",
    "            \n",
    "            cbir, indexing_time, file_size, indexed, _ = test_combination(n_bin, h_type, metric)\n",
    "            \n",
    "            models[config_name] = cbir\n",
    "            results_comparison[config_name] = {\n",
    "                'n_bin': n_bin,\n",
    "                'h_type': h_type, \n",
    "                'metric': metric,\n",
    "                'indexing_time': indexing_time,\n",
    "                'file_size': file_size,\n",
    "                'indexed_images': indexed\n",
    "            }\n",
    "\n",
    "print(f\"\\n✅ Completed indexing for all {len(all_configs)} combinations!\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "08e904c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T05:04:58.049757Z",
     "start_time": "2025-07-12T05:03:32.566585Z"
    }
   },
   "source": [
    "# Load lại tất cả models từ file đã tạo trước đó\n",
    "TRAIN_SIZE = 24607\n",
    "TEST_SIZE = 1000\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Khởi tạo dataset\n",
    "root_path = os.path.abspath('data/caltech-256/256_ObjectCategories')\n",
    "print(f\"🔍 Dataset root: {root_path}\")\n",
    "data_module = Caltech256DataModule(batch_size=32, root=root_path)\n",
    "data_module.setup()\n",
    "train_loader = data_module.train_dataloader()\n",
    "test_loader = data_module.test_dataloader()\n",
    "\n",
    "# Tất cả combinations để test\n",
    "n_bins = [4, 8, 12]\n",
    "h_types = [\"global\", \"region\"]\n",
    "metrics = [\"cosine\", \"euclidean\"]\n",
    "\n",
    "print(f\"🧪 Testing {len(n_bins)} bins × {len(h_types)} h_types × {len(metrics)} metrics = {len(n_bins)*len(h_types)*len(metrics)} combinations\")\n",
    "\n",
    "# Tạo lại biến models và results_comparison\n",
    "models = {}\n",
    "results_comparison = {}\n",
    "\n",
    "# Load tất cả models từ thư mục evaluation/out\n",
    "print(\"🔄 Loading existing models...\")\n",
    "model_files = []\n",
    "for n_bin in n_bins:\n",
    "    for h_type in h_types:\n",
    "        for metric in metrics:\n",
    "            config_name = f\"{n_bin}bin_{h_type}_{metric}\"\n",
    "            model_path = f'out/caltech256_model_{config_name}.pkl.gz'\n",
    "            if os.path.exists(model_path):\n",
    "                print(f\"✅ Found existing model: {config_name}\")\n",
    "                try:\n",
    "                    with gzip.open(model_path, 'rb') as f:\n",
    "                        cbir = pickle.load(f)\n",
    "                    models[config_name] = cbir\n",
    "                    file_size = os.path.getsize(model_path) / 1024 / 1024\n",
    "                    results_comparison[config_name] = {\n",
    "                        'n_bin': n_bin,\n",
    "                        'h_type': h_type,\n",
    "                        'metric': metric,\n",
    "                        'file_size': file_size,\n",
    "                        'indexed_images': 23824  # Từ kết quả indexing trước đó\n",
    "                    }\n",
    "                    model_files.append(config_name)\n",
    "                except Exception as e:\n",
    "                    print(f\"❌ Error loading model {config_name}: {e}\")\n",
    "            else:\n",
    "                print(f\"❌ Model file not found: {config_name}\")\n",
    "\n",
    "print(f\"\\n📊 Loaded {len(models)} models successfully\")\n",
    "print(f\"Model configs: {list(models.keys())}\")\n",
    "\n",
    "# Kiểm tra xem có đủ models không\n",
    "if len(models) == 12:\n",
    "    print(\"🎉 All 12 models loaded successfully!\")\n",
    "elif len(models) > 0:\n",
    "    print(f\"⚠️  Loaded {len(models)}/12 models, proceeding with available models\")\n",
    "else:\n",
    "    print(\"❌ No models found! Please check file paths\")\n",
    "\n",
    "print(f\"\\n🎯 Ready for evaluation with {len(models)} model(s)\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Dataset root: D:\\AI\\Food-CBIR\\src\\evaluation\\data\\caltech-256\\256_ObjectCategories\n",
      "📂 Found 256 valid categories\n",
      "📊 Loaded 29780 total images from 256 classes\n",
      "📋 Train: 23824 images\n",
      "📂 Found 256 valid categories\n",
      "📊 Loaded 29780 total images from 256 classes\n",
      "📋 Test: 5956 images\n",
      "Train: 23824, Test: 5956\n",
      "🧪 Testing 3 bins × 2 h_types × 2 metrics = 12 combinations\n",
      "🔄 Loading existing models...\n",
      "✅ Found existing model: 4bin_global_cosine\n",
      "✅ Found existing model: 4bin_global_euclidean\n",
      "✅ Found existing model: 4bin_region_cosine\n",
      "✅ Found existing model: 4bin_region_euclidean\n",
      "✅ Found existing model: 8bin_global_cosine\n",
      "✅ Found existing model: 8bin_global_euclidean\n",
      "✅ Found existing model: 8bin_region_cosine\n",
      "✅ Found existing model: 8bin_region_euclidean\n",
      "✅ Found existing model: 12bin_global_cosine\n",
      "✅ Found existing model: 12bin_global_euclidean\n",
      "✅ Found existing model: 12bin_region_cosine\n",
      "✅ Found existing model: 12bin_region_euclidean\n",
      "\n",
      "📊 Loaded 12 models successfully\n",
      "Model configs: ['4bin_global_cosine', '4bin_global_euclidean', '4bin_region_cosine', '4bin_region_euclidean', '8bin_global_cosine', '8bin_global_euclidean', '8bin_region_cosine', '8bin_region_euclidean', '12bin_global_cosine', '12bin_global_euclidean', '12bin_region_cosine', '12bin_region_euclidean']\n",
      "🎉 All 12 models loaded successfully!\n",
      "\n",
      "🎯 Ready for evaluation with 12 model(s)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "5bbdf283e6cabd9f",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "id": "b0dc4951ac77839c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T07:18:11.646133Z",
     "start_time": "2025-07-12T05:05:11.924827Z"
    }
   },
   "source": [
    "# Hàm để evaluate một model\n",
    "def evaluate_model(cbir, config_name):\n",
    "    print(f\"\\n📊 Evaluating {config_name.upper()} model...\")\n",
    "    start = time()\n",
    "    results = []\n",
    "    ground_truth = []\n",
    "    tested = 0\n",
    "\n",
    "    # Get dataset targets for evaluation - sử dụng số lượng images đã indexed\n",
    "    dataset_targets = []\n",
    "    indexed_count = 23824  # Số lượng ảnh đã được index từ kết quả trước đó\n",
    "    \n",
    "    for images, labels, _ in train_loader:\n",
    "        if len(dataset_targets) >= indexed_count:\n",
    "            break\n",
    "        count = min(len(labels), indexed_count - len(dataset_targets))\n",
    "        dataset_targets.extend(labels[:count].numpy())\n",
    "    dataset_targets = np.array(dataset_targets)\n",
    "\n",
    "    # Query với k=10 để tính mAP@1,5,10\n",
    "    MAX_K = 10\n",
    "\n",
    "    for images, labels, _ in tqdm(test_loader, desc=f\"Testing ({config_name})\"):\n",
    "        if tested >= TEST_SIZE:\n",
    "            break\n",
    "\n",
    "        if device.type == \"cuda\":\n",
    "            images = images.to(device)\n",
    "\n",
    "        count = min(len(images), TEST_SIZE - tested)\n",
    "        images = images[:count]\n",
    "        labels = labels[:count]\n",
    "\n",
    "        images = (images.cpu().numpy().transpose(0, 2, 3, 1) * 255).astype(np.uint8)\n",
    "\n",
    "        for image in images:\n",
    "            if tested >= TEST_SIZE:\n",
    "                break\n",
    "            # Query với k=10 để tính mAP@1,5,10\n",
    "            result = cbir.query_similar_images(image, k=MAX_K)\n",
    "            results.append(result)\n",
    "            tested += 1\n",
    "\n",
    "        ground_truth.extend(labels.numpy())\n",
    "\n",
    "    retrieval_time = time() - start\n",
    "    print(f\"Tested {tested} images in {retrieval_time:.2f}s\")\n",
    "\n",
    "    # Calculate metrics cho k=1, k=5, k=10\n",
    "    k_values = [1, 5, 10]\n",
    "    metrics_data = {}\n",
    "\n",
    "    print(f\"📈 Calculating metrics for k={k_values}...\")\n",
    "\n",
    "    for k in k_values:\n",
    "        map_k, recall_k, hit_k = [], [], []\n",
    "\n",
    "        for r, gt in zip(results, ground_truth):\n",
    "            # Lấy top-k results\n",
    "            top_k_results = r[:k]\n",
    "            indices = [item.index for item in top_k_results]\n",
    "            preds = np.take(dataset_targets, indices)\n",
    "            relevant = np.where(dataset_targets == gt)[0]\n",
    "\n",
    "            map_k.append(average_precision(preds.tolist(), [gt], k))\n",
    "            recall_k.append(recall(indices, relevant, k))\n",
    "            hit_k.append(hit_rate(preds.tolist(), [gt], k))\n",
    "\n",
    "        # Store metrics\n",
    "        metrics_data[f'mAP@{k}'] = np.mean(map_k)\n",
    "        metrics_data[f'Recall@{k}'] = np.mean(recall_k)\n",
    "        metrics_data[f'HitRate@{k}'] = np.mean(hit_k)\n",
    "\n",
    "        print(f\"   k={k}: mAP={np.mean(map_k):.4f}, Recall={np.mean(recall_k):.4f}, HR={np.mean(hit_k):.4f}\")\n",
    "\n",
    "    # Tính average mAP score cho ranking\n",
    "    avg_map = (metrics_data['mAP@1'] + metrics_data['mAP@5'] + metrics_data['mAP@10']) / 3\n",
    "    metrics_data['avg_mAP'] = avg_map\n",
    "\n",
    "    # Add config và timing metrics\n",
    "    if config_name in results_comparison:\n",
    "        metrics_data.update(results_comparison[config_name])\n",
    "    metrics_data['retrieval_time'] = retrieval_time\n",
    "    metrics_data['tested_images'] = tested\n",
    "    metrics_data['config_name'] = config_name\n",
    "\n",
    "    return metrics_data\n",
    "\n",
    "# Evaluate tất cả 12 models\n",
    "print(f\"\\n🚀 Starting evaluation of all {len(models)} models...\")\n",
    "all_results = []\n",
    "\n",
    "for config_name in models.keys():\n",
    "    cbir = models[config_name]\n",
    "    metrics = evaluate_model(cbir, config_name)\n",
    "    all_results.append(metrics)\n",
    "    results_comparison[config_name].update(metrics)\n",
    "\n",
    "# Tìm best model dựa trên average mAP@1,5,10\n",
    "print(f\"\\n🔍 Finding best model based on average mAP@1,5,10...\")\n",
    "best_config = max(results_comparison.keys(), key=lambda x: results_comparison[x]['avg_mAP'])\n",
    "best_model = models[best_config]\n",
    "best_metrics = results_comparison[best_config]\n",
    "\n",
    "print(f\"\\n🏆 BEST MODEL: {best_config}\")\n",
    "print(f\"   Average mAP: {best_metrics['avg_mAP']:.4f}\")\n",
    "print(f\"   mAP@1: {best_metrics['mAP@1']:.4f}\")\n",
    "print(f\"   mAP@5: {best_metrics['mAP@5']:.4f}\")\n",
    "print(f\"   mAP@10: {best_metrics['mAP@10']:.4f}\")\n",
    "\n",
    "# Save best model\n",
    "best_model_path = 'out/best_color.pkl.gz'\n",
    "with gzip.open(best_model_path, 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "best_file_size = os.path.getsize(best_model_path) / 1024 / 1024\n",
    "print(f\"💾 Best model saved as: best_color.pkl.gz ({best_file_size:.2f} MB)\")\n",
    "\n",
    "# Save config của best model\n",
    "best_config_info = {\n",
    "    'config_name': best_config,\n",
    "    'n_bin': best_metrics['n_bin'],\n",
    "    'h_type': best_metrics['h_type'],\n",
    "    'metric': best_metrics['metric'],\n",
    "    'avg_mAP': best_metrics['avg_mAP'],\n",
    "    'mAP@1': best_metrics['mAP@1'],\n",
    "    'mAP@5': best_metrics['mAP@5'],\n",
    "    'mAP@10': best_metrics['mAP@10']\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('out/best_color_config.json', 'w') as f:\n",
    "    json.dump(best_config_info, f, indent=2)\n",
    "print(\"📋 Best model config saved as: best_color_config.json\")\n",
    "\n",
    "# So sánh tất cả kết quả\n",
    "print(f\"\\n📊 ALL RESULTS RANKING (by avg mAP)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Rank':<4} {'Config':<20} {'AvgmAP':<8} {'mAP@1':<8} {'mAP@5':<8} {'mAP@10':<8}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Sort by avg_mAP descending\n",
    "sorted_configs = sorted(results_comparison.items(), key=lambda x: x[1]['avg_mAP'], reverse=True)\n",
    "\n",
    "for rank, (config, data) in enumerate(sorted_configs, 1):\n",
    "    print(f\"{rank:<4} {config:<20} {data['avg_mAP']:<8.4f} {data['mAP@1']:<8.4f} {data['mAP@5']:<8.4f} {data['mAP@10']:<8.4f}\")\n",
    "\n",
    "# Save detailed results\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df = results_df.sort_values('avg_mAP', ascending=False)\n",
    "results_df.to_csv('out/all_color_combinations_results.csv', index=False)\n",
    "print(f\"\\n✅ Detailed results saved to: all_color_combinations_results.csv\")\n",
    "\n",
    "# Top 3 summary\n",
    "print(f\"\\n🥇 TOP 3 CONFIGURATIONS:\")\n",
    "for i, (config, data) in enumerate(sorted_configs[:3], 1):\n",
    "    emoji = [\"🥇\", \"🥈\", \"🥉\"][i-1]\n",
    "    print(f\"{emoji} {config}: avg_mAP={data['avg_mAP']:.4f} (n_bin={data['n_bin']}, h_type={data['h_type']}, metric={data['metric']})\")\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    torch.cuda.empty_cache()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Starting evaluation of all 12 models...\n",
      "\n",
      "📊 Evaluating 4BIN_GLOBAL_COSINE model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing (4bin_global_cosine):  17%|█▋        | 32/187 [00:15<01:13,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested 1000 images in 292.57s\n",
      "📈 Calculating metrics for k=[1, 5, 10]...\n",
      "   k=1: mAP=0.0025, Recall=0.0000, HR=0.0050\n",
      "   k=5: mAP=0.0067, Recall=0.0002, HR=0.0062\n",
      "   k=10: mAP=0.0086, Recall=0.0005, HR=0.0063\n",
      "\n",
      "📊 Evaluating 4BIN_GLOBAL_EUCLIDEAN model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing (4bin_global_euclidean):  17%|█▋        | 32/187 [00:09<00:44,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested 1000 images in 92.50s\n",
      "📈 Calculating metrics for k=[1, 5, 10]...\n",
      "   k=1: mAP=0.0030, Recall=0.0000, HR=0.0060\n",
      "   k=5: mAP=0.0062, Recall=0.0002, HR=0.0056\n",
      "   k=10: mAP=0.0077, Recall=0.0005, HR=0.0053\n",
      "\n",
      "📊 Evaluating 4BIN_REGION_COSINE model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing (4bin_region_cosine):  17%|█▋        | 32/187 [01:22<06:40,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested 1000 images in 162.85s\n",
      "📈 Calculating metrics for k=[1, 5, 10]...\n",
      "   k=1: mAP=0.0025, Recall=0.0001, HR=0.0050\n",
      "   k=5: mAP=0.0068, Recall=0.0003, HR=0.0064\n",
      "   k=10: mAP=0.0090, Recall=0.0005, HR=0.0064\n",
      "\n",
      "📊 Evaluating 4BIN_REGION_EUCLIDEAN model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing (4bin_region_euclidean):  17%|█▋        | 32/187 [00:13<01:04,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested 1000 images in 95.78s\n",
      "📈 Calculating metrics for k=[1, 5, 10]...\n",
      "   k=1: mAP=0.0025, Recall=0.0000, HR=0.0050\n",
      "   k=5: mAP=0.0059, Recall=0.0002, HR=0.0048\n",
      "   k=10: mAP=0.0075, Recall=0.0004, HR=0.0050\n",
      "\n",
      "📊 Evaluating 8BIN_GLOBAL_COSINE model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing (8bin_global_cosine):  17%|█▋        | 32/187 [00:44<03:33,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested 1000 images in 126.50s\n",
      "📈 Calculating metrics for k=[1, 5, 10]...\n",
      "   k=1: mAP=0.0030, Recall=0.0001, HR=0.0060\n",
      "   k=5: mAP=0.0065, Recall=0.0003, HR=0.0058\n",
      "   k=10: mAP=0.0085, Recall=0.0005, HR=0.0059\n",
      "\n",
      "📊 Evaluating 8BIN_GLOBAL_EUCLIDEAN model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing (8bin_global_euclidean):  17%|█▋        | 32/187 [00:25<02:04,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested 1000 images in 109.02s\n",
      "📈 Calculating metrics for k=[1, 5, 10]...\n",
      "   k=1: mAP=0.0000, Recall=0.0000, HR=0.0000\n",
      "   k=5: mAP=0.0033, Recall=0.0002, HR=0.0044\n",
      "   k=10: mAP=0.0051, Recall=0.0004, HR=0.0051\n",
      "\n",
      "📊 Evaluating 8BIN_REGION_COSINE model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing (8bin_region_cosine):  17%|█▋        | 32/187 [12:19<59:42, 23.12s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested 1000 images in 821.33s\n",
      "📈 Calculating metrics for k=[1, 5, 10]...\n",
      "   k=1: mAP=0.0015, Recall=0.0000, HR=0.0030\n",
      "   k=5: mAP=0.0055, Recall=0.0002, HR=0.0058\n",
      "   k=10: mAP=0.0074, Recall=0.0005, HR=0.0061\n",
      "\n",
      "📊 Evaluating 8BIN_REGION_EUCLIDEAN model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing (8bin_region_euclidean):  17%|█▋        | 32/187 [01:40<08:07,  3.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested 1000 images in 250.08s\n",
      "📈 Calculating metrics for k=[1, 5, 10]...\n",
      "   k=1: mAP=0.0025, Recall=0.0000, HR=0.0050\n",
      "   k=5: mAP=0.0076, Recall=0.0003, HR=0.0074\n",
      "   k=10: mAP=0.0090, Recall=0.0005, HR=0.0061\n",
      "\n",
      "📊 Evaluating 12BIN_GLOBAL_COSINE model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing (12bin_global_cosine):  17%|█▋        | 32/187 [05:12<25:13,  9.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested 1000 images in 522.97s\n",
      "📈 Calculating metrics for k=[1, 5, 10]...\n",
      "   k=1: mAP=0.0010, Recall=0.0000, HR=0.0020\n",
      "   k=5: mAP=0.0050, Recall=0.0002, HR=0.0050\n",
      "   k=10: mAP=0.0065, Recall=0.0004, HR=0.0047\n",
      "\n",
      "📊 Evaluating 12BIN_GLOBAL_EUCLIDEAN model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing (12bin_global_euclidean):  17%|█▋        | 32/187 [01:48<08:43,  3.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested 1000 images in 297.84s\n",
      "📈 Calculating metrics for k=[1, 5, 10]...\n",
      "   k=1: mAP=0.0025, Recall=0.0000, HR=0.0050\n",
      "   k=5: mAP=0.0055, Recall=0.0002, HR=0.0048\n",
      "   k=10: mAP=0.0078, Recall=0.0005, HR=0.0059\n",
      "\n",
      "📊 Evaluating 12BIN_REGION_COSINE model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing (12bin_region_cosine):  17%|█▋        | 32/187 [1:22:01<6:37:17, 153.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested 1000 images in 5126.45s\n",
      "📈 Calculating metrics for k=[1, 5, 10]...\n",
      "   k=1: mAP=0.0025, Recall=0.0000, HR=0.0050\n",
      "   k=5: mAP=0.0071, Recall=0.0002, HR=0.0068\n",
      "   k=10: mAP=0.0087, Recall=0.0004, HR=0.0058\n",
      "\n",
      "📊 Evaluating 12BIN_REGION_EUCLIDEAN model...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 95\u001B[0m\n\u001B[0;32m     93\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m config_name \u001B[38;5;129;01min\u001B[39;00m models\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[0;32m     94\u001B[0m     cbir \u001B[38;5;241m=\u001B[39m models[config_name]\n\u001B[1;32m---> 95\u001B[0m     metrics \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcbir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     96\u001B[0m     all_results\u001B[38;5;241m.\u001B[39mappend(metrics)\n\u001B[0;32m     97\u001B[0m     results_comparison[config_name]\u001B[38;5;241m.\u001B[39mupdate(metrics)\n",
      "Cell \u001B[1;32mIn[9], line 13\u001B[0m, in \u001B[0;36mevaluate_model\u001B[1;34m(cbir, config_name)\u001B[0m\n\u001B[0;32m     10\u001B[0m dataset_targets \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     11\u001B[0m indexed_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m23824\u001B[39m  \u001B[38;5;66;03m# Số lượng ảnh đã được index từ kết quả trước đó\u001B[39;00m\n\u001B[1;32m---> 13\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m images, labels, _ \u001B[38;5;129;01min\u001B[39;00m train_loader:\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(dataset_targets) \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m indexed_count:\n\u001B[0;32m     15\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    698\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    699\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    700\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 701\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    702\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    703\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    704\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable\n\u001B[0;32m    705\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    706\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called\n\u001B[0;32m    707\u001B[0m ):\n",
      "File \u001B[1;32m~\\PycharmProjects\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    755\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    756\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 757\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    758\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    759\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32m~\\PycharmProjects\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     50\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 52\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     54\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32m~\\PycharmProjects\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     50\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 52\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     54\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32mD:\\AI\\Food-CBIR\\src\\datasets\\caltech256.py:119\u001B[0m, in \u001B[0;36mCaltech256Dataset.__getitem__\u001B[1;34m(self, index)\u001B[0m\n\u001B[0;32m    116\u001B[0m class_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses[label]\n\u001B[0;32m    118\u001B[0m image \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mopen(image_path)\u001B[38;5;241m.\u001B[39mconvert(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRGB\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m--> 119\u001B[0m image \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    121\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m image, label, class_name\n",
      "File \u001B[1;32m~\\PycharmProjects\\.venv\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001B[0m, in \u001B[0;36mCompose.__call__\u001B[1;34m(self, img)\u001B[0m\n\u001B[0;32m     93\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, img):\n\u001B[0;32m     94\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransforms:\n\u001B[1;32m---> 95\u001B[0m         img \u001B[38;5;241m=\u001B[39m \u001B[43mt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     96\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
      "File \u001B[1;32m~\\PycharmProjects\\.venv\\lib\\site-packages\\torchvision\\transforms\\transforms.py:137\u001B[0m, in \u001B[0;36mToTensor.__call__\u001B[1;34m(self, pic)\u001B[0m\n\u001B[0;32m    129\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, pic):\n\u001B[0;32m    130\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    131\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m    132\u001B[0m \u001B[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    135\u001B[0m \u001B[38;5;124;03m        Tensor: Converted image.\u001B[39;00m\n\u001B[0;32m    136\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 137\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpic\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\.venv\\lib\\site-packages\\torchvision\\transforms\\functional.py:176\u001B[0m, in \u001B[0;36mto_tensor\u001B[1;34m(pic)\u001B[0m\n\u001B[0;32m    174\u001B[0m img \u001B[38;5;241m=\u001B[39m img\u001B[38;5;241m.\u001B[39mpermute((\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m))\u001B[38;5;241m.\u001B[39mcontiguous()\n\u001B[0;32m    175\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(img, torch\u001B[38;5;241m.\u001B[39mByteTensor):\n\u001B[1;32m--> 176\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mimg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdefault_float_dtype\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mdiv(\u001B[38;5;241m255\u001B[39m)\n\u001B[0;32m    177\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    178\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68a9e91f9651c47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
