{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T07:50:49.093628Z",
     "start_time": "2025-07-11T07:50:43.122004Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.datasets.caltech256 import Caltech256DataModule\n",
    "from src.featuring.rgb_histogram import RGBHistogram\n",
    "from src.storage.VectorDBStore import VectorDBStore\n",
    "from src.retrieval.KNN import KNNRetrieval\n",
    "from src.pipeline import CBIR\n",
    "from src.metrics import average_precision, recall, hit_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84c605e062ed5179",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T07:51:59.675756Z",
     "start_time": "2025-07-11T07:51:59.670234Z"
    }
   },
   "outputs": [],
   "source": [
    "os.makedirs('out', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c00ce3cb06df4f",
   "metadata": {},
   "source": [
    "# INDEXING"
   ]
  },
  {
   "cell_type": "code",
   "id": "1f730d283fee6a54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T18:23:01.896733Z",
     "start_time": "2025-07-11T15:59:32.007359Z"
    }
   },
   "source": [
    "TRAIN_SIZE = 24607  # S·ªë l∆∞·ª£ng ·∫£nh ƒë·ªÉ index\n",
    "TEST_SIZE = 1000   # Gi·∫£m test size ƒë·ªÉ test nhanh h∆°n v·ªõi nhi·ªÅu combinations\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Kh·ªüi t·∫°o dataset\n",
    "import os\n",
    "root_path = os.path.abspath('data/caltech-256/256_ObjectCategories')\n",
    "print(f\"üîç Dataset root: {root_path}\")\n",
    "print(f\"üîç Exists: {os.path.exists(root_path)}\")\n",
    "data_module = Caltech256DataModule(batch_size=32, root=root_path)\n",
    "data_module.setup()\n",
    "train_loader = data_module.train_dataloader()\n",
    "test_loader = data_module.test_dataloader()\n",
    "\n",
    "# T·∫•t c·∫£ combinations ƒë·ªÉ test\n",
    "n_bins = [4, 8, 12]\n",
    "h_types = [\"global\", \"region\"]\n",
    "metrics = [\"cosine\", \"euclidean\"]\n",
    "\n",
    "print(f\"üß™ Testing {len(n_bins)} bins √ó {len(h_types)} h_types √ó {len(metrics)} metrics = {len(n_bins)*len(h_types)*len(metrics)} combinations\")\n",
    "\n",
    "# H√†m ƒë·ªÉ test m·ªôt combination\n",
    "def test_combination(n_bin, h_type, metric):\n",
    "    config_name = f\"{n_bin}bin_{h_type}_{metric}\"\n",
    "    print(f\"\\nüî¨ Testing: n_bin={n_bin}, h_type={h_type}, metric={metric}\")\n",
    "    \n",
    "    # Kh·ªüi t·∫°o CBIR pipeline \n",
    "    feature_extractor = RGBHistogram(n_bin=n_bin, h_type=h_type)\n",
    "    retrieval = KNNRetrieval(metric=metric)\n",
    "    storage = VectorDBStore(retrieval)\n",
    "    cbir = CBIR(feature_extractor, storage)\n",
    "    \n",
    "    # Indexing\n",
    "    print(f\"Indexing {TRAIN_SIZE} images...\")\n",
    "    start = time()\n",
    "    indexed = 0\n",
    "    \n",
    "    for images, labels, _ in tqdm(train_loader, desc=f\"Indexing ({config_name})\"):\n",
    "        if indexed >= TRAIN_SIZE:\n",
    "            break\n",
    "    \n",
    "        if device.type == \"cuda\":\n",
    "            images = images.to(device)\n",
    "    \n",
    "        count = min(len(images), TRAIN_SIZE - indexed)\n",
    "        images = images[:count]\n",
    "        images = (images.cpu().numpy().transpose(0, 2, 3, 1) * 255).astype(np.uint8)\n",
    "    \n",
    "        cbir.add_images(images)\n",
    "        indexed += count\n",
    "    \n",
    "    indexing_time = time() - start\n",
    "    print(f\"Indexed {indexed} images in {indexing_time:.2f}s\")\n",
    "    \n",
    "    # Save model\n",
    "    model_path = f'out/caltech256_model_{config_name}.pkl.gz'\n",
    "    with gzip.open(model_path, 'wb') as f:\n",
    "        pickle.dump(cbir, f)\n",
    "    \n",
    "    file_size = os.path.getsize(model_path) / 1024 / 1024\n",
    "    print(f\"üíæ Model saved: {file_size:.2f} MB\")\n",
    "    \n",
    "    return cbir, indexing_time, file_size, indexed, config_name\n",
    "\n",
    "# Test t·∫•t c·∫£ combinations\n",
    "results_comparison = {}\n",
    "models = {}\n",
    "all_configs = []\n",
    "\n",
    "for n_bin in n_bins:\n",
    "    for h_type in h_types:\n",
    "        for metric in metrics:\n",
    "            config_name = f\"{n_bin}bin_{h_type}_{metric}\"\n",
    "            all_configs.append((n_bin, h_type, metric, config_name))\n",
    "            \n",
    "            cbir, indexing_time, file_size, indexed, _ = test_combination(n_bin, h_type, metric)\n",
    "            \n",
    "            models[config_name] = cbir\n",
    "            results_comparison[config_name] = {\n",
    "                'n_bin': n_bin,\n",
    "                'h_type': h_type, \n",
    "                'metric': metric,\n",
    "                'indexing_time': indexing_time,\n",
    "                'file_size': file_size,\n",
    "                'indexed_images': indexed\n",
    "            }\n",
    "\n",
    "print(f\"\\n‚úÖ Completed indexing for all {len(all_configs)} combinations!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Dataset root: D:\\AI\\Food-CBIR\\src\\evaluation\\data\\caltech-256\\256_ObjectCategories\n",
      "üîç Exists: True\n",
      "üìÇ Found 256 valid categories\n",
      "üìä Loaded 29780 total images from 256 classes\n",
      "üìã Train: 23824 images\n",
      "üìÇ Found 256 valid categories\n",
      "üìä Loaded 29780 total images from 256 classes\n",
      "üìã Test: 5956 images\n",
      "Train: 23824, Test: 5956\n",
      "üß™ Testing 3 bins √ó 2 h_types √ó 2 metrics = 12 combinations\n",
      "\n",
      "üî¨ Testing: n_bin=4, h_type=global, metric=cosine\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (4bin_global_cosine): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 745/745 [04:09<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 249.59s\n",
      "üíæ Model saved: 6.14 MB\n",
      "\n",
      "üî¨ Testing: n_bin=4, h_type=global, metric=euclidean\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (4bin_global_euclidean): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 745/745 [02:23<00:00,  5.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 143.44s\n",
      "üíæ Model saved: 6.14 MB\n",
      "\n",
      "üî¨ Testing: n_bin=4, h_type=region, metric=cosine\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (4bin_region_cosine): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 745/745 [05:22<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 322.25s\n",
      "üíæ Model saved: 39.16 MB\n",
      "\n",
      "üî¨ Testing: n_bin=4, h_type=region, metric=euclidean\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (4bin_region_euclidean): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 745/745 [05:15<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 315.50s\n",
      "üíæ Model saved: 39.17 MB\n",
      "\n",
      "üî¨ Testing: n_bin=8, h_type=global, metric=cosine\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (8bin_global_cosine): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 745/745 [02:15<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 135.52s\n",
      "üíæ Model saved: 32.44 MB\n",
      "\n",
      "üî¨ Testing: n_bin=8, h_type=global, metric=euclidean\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (8bin_global_euclidean): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 745/745 [03:48<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 228.55s\n",
      "üíæ Model saved: 32.44 MB\n",
      "\n",
      "üî¨ Testing: n_bin=8, h_type=region, metric=cosine\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (8bin_region_cosine): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 745/745 [04:43<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 283.92s\n",
      "üíæ Model saved: 163.37 MB\n",
      "\n",
      "üî¨ Testing: n_bin=8, h_type=region, metric=euclidean\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (8bin_region_euclidean): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 745/745 [04:53<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 293.81s\n",
      "üíæ Model saved: 163.35 MB\n",
      "\n",
      "üî¨ Testing: n_bin=12, h_type=global, metric=cosine\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (12bin_global_cosine): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 745/745 [05:40<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 340.83s\n",
      "üíæ Model saved: 77.95 MB\n",
      "\n",
      "üî¨ Testing: n_bin=12, h_type=global, metric=euclidean\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (12bin_global_euclidean): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 745/745 [06:20<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 380.95s\n",
      "üíæ Model saved: 77.96 MB\n",
      "\n",
      "üî¨ Testing: n_bin=12, h_type=region, metric=cosine\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (12bin_region_cosine): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 745/745 [12:58<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 778.45s\n",
      "üíæ Model saved: 342.13 MB\n",
      "\n",
      "üî¨ Testing: n_bin=12, h_type=region, metric=euclidean\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (12bin_region_euclidean): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 745/745 [13:07<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 787.76s\n",
      "üíæ Model saved: 342.10 MB\n",
      "\n",
      "‚úÖ Completed indexing for all 12 combinations!\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "5bbdf283e6cabd9f",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "id": "b0dc4951ac77839c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T18:36:01.442451Z",
     "start_time": "2025-07-11T18:23:02.408544Z"
    }
   },
   "source": [
    "# H√†m ƒë·ªÉ evaluate m·ªôt model\n",
    "def evaluate_model(cbir, metric_name):\n",
    "    print(f\"\\nüìä Evaluating {metric_name.upper()} model...\")\n",
    "    start = time()\n",
    "    results = []\n",
    "    ground_truth = []\n",
    "    tested = 0\n",
    "\n",
    "    # Get dataset targets for evaluation\n",
    "    dataset_targets = []\n",
    "    for images, labels, _ in train_loader:\n",
    "        if len(dataset_targets) >= indexed:\n",
    "            break\n",
    "        count = min(len(labels), indexed - len(dataset_targets))\n",
    "        dataset_targets.extend(labels[:count].numpy())\n",
    "    dataset_targets = np.array(dataset_targets)\n",
    "\n",
    "    # Query v·ªõi k=10 ƒë·ªÉ t√≠nh mAP@1,5,10\n",
    "    MAX_K = 10\n",
    "\n",
    "    for images, labels, _ in tqdm(test_loader, desc=f\"Testing ({config_name})\"):\n",
    "        if tested >= TEST_SIZE:\n",
    "            break\n",
    "\n",
    "        if device.type == \"cuda\":\n",
    "            images = images.to(device)\n",
    "\n",
    "        count = min(len(images), TEST_SIZE - tested)\n",
    "        images = images[:count]\n",
    "        labels = labels[:count]\n",
    "\n",
    "        images = (images.cpu().numpy().transpose(0, 2, 3, 1) * 255).astype(np.uint8)\n",
    "\n",
    "        for image in images:\n",
    "            if tested >= TEST_SIZE:\n",
    "                break\n",
    "            # Query v·ªõi k=10 ƒë·ªÉ t√≠nh mAP@1,5,10\n",
    "            result = cbir.query_similar_images(image, k=MAX_K)\n",
    "            results.append(result)\n",
    "            tested += 1\n",
    "\n",
    "        ground_truth.extend(labels.numpy())\n",
    "\n",
    "    retrieval_time = time() - start\n",
    "    print(f\"Tested {tested} images in {retrieval_time:.2f}s\")\n",
    "\n",
    "    # Calculate metrics cho k=1, k=5, k=10\n",
    "    k_values = [1, 5, 10]\n",
    "    metrics_data = {}\n",
    "\n",
    "    print(f\"üìà Calculating metrics for k={k_values}...\")\n",
    "\n",
    "    for k in k_values:\n",
    "        map_k, recall_k, hit_k = [], [], []\n",
    "\n",
    "        for r, gt in zip(results, ground_truth):\n",
    "            # L·∫•y top-k results\n",
    "            top_k_results = r[:k]\n",
    "            indices = [item.index for item in top_k_results]\n",
    "            preds = np.take(dataset_targets, indices)\n",
    "            relevant = np.where(dataset_targets == gt)[0]\n",
    "\n",
    "            map_k.append(average_precision(preds.tolist(), [gt], k))\n",
    "            recall_k.append(recall(indices, relevant, k))\n",
    "            hit_k.append(hit_rate(preds.tolist(), [gt], k))\n",
    "\n",
    "        # Store metrics\n",
    "        metrics_data[f'mAP@{k}'] = np.mean(map_k)\n",
    "        metrics_data[f'Recall@{k}'] = np.mean(recall_k)\n",
    "        metrics_data[f'HitRate@{k}'] = np.mean(hit_k)\n",
    "\n",
    "        print(f\"   k={k}: mAP={np.mean(map_k):.4f}, Recall={np.mean(recall_k):.4f}, HR={np.mean(hit_k):.4f}\")\n",
    "\n",
    "    # T√≠nh average mAP score cho ranking\n",
    "    avg_map = (metrics_data['mAP@1'] + metrics_data['mAP@5'] + metrics_data['mAP@10']) / 3\n",
    "    metrics_data['avg_mAP'] = avg_map\n",
    "\n",
    "    # Add config v√† timing metrics\n",
    "    metrics_data.update(results_comparison[config_name])\n",
    "    metrics_data['retrieval_time'] = retrieval_time\n",
    "    metrics_data['tested_images'] = tested\n",
    "    metrics_data['config_name'] = config_name\n",
    "\n",
    "    return metrics_data\n",
    "\n",
    "# Evaluate t·∫•t c·∫£ 12 models\n",
    "print(f\"\\nüöÄ Starting evaluation of all {len(models)} models...\")\n",
    "all_results = []\n",
    "\n",
    "for config_name in models.keys():\n",
    "    cbir = models[config_name]\n",
    "    metrics = evaluate_model(cbir, config_name)\n",
    "    all_results.append(metrics)\n",
    "    results_comparison[config_name].update(metrics)\n",
    "\n",
    "# T√¨m best model d·ª±a tr√™n average mAP@1,5,10\n",
    "print(f\"\\nüîç Finding best model based on average mAP@1,5,10...\")\n",
    "best_config = max(results_comparison.keys(), key=lambda x: results_comparison[x]['avg_mAP'])\n",
    "best_model = models[best_config]\n",
    "best_metrics = results_comparison[best_config]\n",
    "\n",
    "print(f\"\\nüèÜ BEST MODEL: {best_config}\")\n",
    "print(f\"   Average mAP: {best_metrics['avg_mAP']:.4f}\")\n",
    "print(f\"   mAP@1: {best_metrics['mAP@1']:.4f}\")\n",
    "print(f\"   mAP@5: {best_metrics['mAP@5']:.4f}\")\n",
    "print(f\"   mAP@10: {best_metrics['mAP@10']:.4f}\")\n",
    "\n",
    "# Save best model\n",
    "best_model_path = 'out/best_color.pkl.gz'\n",
    "with gzip.open(best_model_path, 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "best_file_size = os.path.getsize(best_model_path) / 1024 / 1024\n",
    "print(f\"üíæ Best model saved as: best_color.pkl.gz ({best_file_size:.2f} MB)\")\n",
    "\n",
    "# Save config c·ªßa best model\n",
    "best_config_info = {\n",
    "    'config_name': best_config,\n",
    "    'n_bin': best_metrics['n_bin'],\n",
    "    'h_type': best_metrics['h_type'],\n",
    "    'metric': best_metrics['metric'],\n",
    "    'avg_mAP': best_metrics['avg_mAP'],\n",
    "    'mAP@1': best_metrics['mAP@1'],\n",
    "    'mAP@5': best_metrics['mAP@5'],\n",
    "    'mAP@10': best_metrics['mAP@10']\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('out/best_color_config.json', 'w') as f:\n",
    "    json.dump(best_config_info, f, indent=2)\n",
    "print(\"üìã Best model config saved as: best_color_config.json\")\n",
    "\n",
    "# So s√°nh t·∫•t c·∫£ k·∫øt qu·∫£\n",
    "print(f\"\\nüìä ALL RESULTS RANKING (by avg mAP)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Rank':<4} {'Config':<20} {'AvgmAP':<8} {'mAP@1':<8} {'mAP@5':<8} {'mAP@10':<8}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Sort by avg_mAP descending\n",
    "sorted_configs = sorted(results_comparison.items(), key=lambda x: x[1]['avg_mAP'], reverse=True)\n",
    "\n",
    "for rank, (config, data) in enumerate(sorted_configs, 1):\n",
    "    print(f\"{rank:<4} {config:<20} {data['avg_mAP']:<8.4f} {data['mAP@1']:<8.4f} {data['mAP@5']:<8.4f} {data['mAP@10']:<8.4f}\")\n",
    "\n",
    "# Save detailed results\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df = results_df.sort_values('avg_mAP', ascending=False)\n",
    "results_df.to_csv('out/all_color_combinations_results.csv', index=False)\n",
    "print(f\"\\n‚úÖ Detailed results saved to: all_color_combinations_results.csv\")\n",
    "\n",
    "# Top 3 summary\n",
    "print(f\"\\nü•á TOP 3 CONFIGURATIONS:\")\n",
    "for i, (config, data) in enumerate(sorted_configs[:3], 1):\n",
    "    emoji = [\"ü•á\", \"ü•à\", \"ü•â\"][i-1]\n",
    "    print(f\"{emoji} {config}: avg_mAP={data['avg_mAP']:.4f} (n_bin={data['n_bin']}, h_type={data['h_type']}, metric={data['metric']})\")\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    torch.cuda.empty_cache()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Starting evaluation of all 12 models...\n",
      "\n",
      "üìä Evaluating 4BIN_GLOBAL_COSINE model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing (4bin_global_cosine):  13%|‚ñà‚ñé        | 25/187 [01:04<07:00,  2.59s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 92\u001B[0m\n\u001B[0;32m     90\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m config_name \u001B[38;5;129;01min\u001B[39;00m models\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[0;32m     91\u001B[0m     cbir \u001B[38;5;241m=\u001B[39m models[config_name]\n\u001B[1;32m---> 92\u001B[0m     metrics \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcbir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     93\u001B[0m     all_results\u001B[38;5;241m.\u001B[39mappend(metrics)\n\u001B[0;32m     94\u001B[0m     results_comparison[config_name]\u001B[38;5;241m.\u001B[39mupdate(metrics)\n",
      "Cell \u001B[1;32mIn[21], line 21\u001B[0m, in \u001B[0;36mevaluate_model\u001B[1;34m(cbir, metric_name)\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m# Query v·ªõi k=10 ƒë·ªÉ t√≠nh mAP@1,5,10\u001B[39;00m\n\u001B[0;32m     19\u001B[0m MAX_K \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10\u001B[39m\n\u001B[1;32m---> 21\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m images, labels, _ \u001B[38;5;129;01min\u001B[39;00m tqdm(test_loader, desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTesting (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m     22\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m tested \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m TEST_SIZE:\n\u001B[0;32m     23\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\.venv\\lib\\site-packages\\tqdm\\std.py:1181\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1178\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[0;32m   1180\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1181\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[0;32m   1182\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[0;32m   1183\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[0;32m   1184\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    698\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    699\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    700\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 701\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    702\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    703\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    704\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable\n\u001B[0;32m    705\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    706\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called\n\u001B[0;32m    707\u001B[0m ):\n",
      "File \u001B[1;32m~\\PycharmProjects\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    755\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    756\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 757\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    758\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    759\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32m~\\PycharmProjects\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     50\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 52\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     54\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32m~\\PycharmProjects\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     50\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 52\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     54\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32mD:\\AI\\Food-CBIR\\src\\datasets\\caltech256.py:118\u001B[0m, in \u001B[0;36mCaltech256Dataset.__getitem__\u001B[1;34m(self, index)\u001B[0m\n\u001B[0;32m    115\u001B[0m label \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlabels[index]\n\u001B[0;32m    116\u001B[0m class_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses[label]\n\u001B[1;32m--> 118\u001B[0m image \u001B[38;5;241m=\u001B[39m \u001B[43mImage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage_path\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mconvert(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRGB\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    119\u001B[0m image \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform(image)\n\u001B[0;32m    121\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m image, label, class_name\n",
      "File \u001B[1;32m~\\PycharmProjects\\.venv\\lib\\site-packages\\PIL\\Image.py:3469\u001B[0m, in \u001B[0;36mopen\u001B[1;34m(fp, mode, formats)\u001B[0m\n\u001B[0;32m   3466\u001B[0m     filename \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mrealpath(os\u001B[38;5;241m.\u001B[39mfspath(fp))\n\u001B[0;32m   3468\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m filename:\n\u001B[1;32m-> 3469\u001B[0m     fp \u001B[38;5;241m=\u001B[39m \u001B[43mbuiltins\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3470\u001B[0m     exclusive_fp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   3471\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68a9e91f9651c47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
