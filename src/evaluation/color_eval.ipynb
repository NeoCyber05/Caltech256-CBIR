{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T07:50:49.093628Z",
     "start_time": "2025-07-11T07:50:43.122004Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.datasets.caltech256 import Caltech256DataModule\n",
    "from src.featuring.rgb_histogram import RGBHistogram\n",
    "from src.storage.VectorDBStore import VectorDBStore\n",
    "from src.retrieval.KNN import KNNRetrieval\n",
    "from src.pipeline import CBIR\n",
    "from src.metrics import average_precision, recall, hit_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84c605e062ed5179",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T07:51:59.675756Z",
     "start_time": "2025-07-11T07:51:59.670234Z"
    }
   },
   "outputs": [],
   "source": [
    "os.makedirs('out', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c00ce3cb06df4f",
   "metadata": {},
   "source": [
    "# INDEXING"
   ]
  },
  {
   "cell_type": "code",
   "id": "1f730d283fee6a54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T18:23:01.896733Z",
     "start_time": "2025-07-11T15:59:32.007359Z"
    }
   },
   "source": [
    "TRAIN_SIZE = 24607  # Số lượng ảnh để index\n",
    "TEST_SIZE = 1000   # Giảm test size để test nhanh hơn với nhiều combinations\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Khởi tạo dataset\n",
    "import os\n",
    "root_path = os.path.abspath('data/caltech-256/256_ObjectCategories')\n",
    "print(f\"🔍 Dataset root: {root_path}\")\n",
    "print(f\"🔍 Exists: {os.path.exists(root_path)}\")\n",
    "data_module = Caltech256DataModule(batch_size=32, root=root_path)\n",
    "data_module.setup()\n",
    "train_loader = data_module.train_dataloader()\n",
    "test_loader = data_module.test_dataloader()\n",
    "\n",
    "# Tất cả combinations để test\n",
    "n_bins = [4, 8, 12]\n",
    "h_types = [\"global\", \"region\"]\n",
    "metrics = [\"cosine\", \"euclidean\"]\n",
    "\n",
    "print(f\"🧪 Testing {len(n_bins)} bins × {len(h_types)} h_types × {len(metrics)} metrics = {len(n_bins)*len(h_types)*len(metrics)} combinations\")\n",
    "\n",
    "# Hàm để test một combination\n",
    "def test_combination(n_bin, h_type, metric):\n",
    "    config_name = f\"{n_bin}bin_{h_type}_{metric}\"\n",
    "    print(f\"\\n🔬 Testing: n_bin={n_bin}, h_type={h_type}, metric={metric}\")\n",
    "    \n",
    "    # Khởi tạo CBIR pipeline \n",
    "    feature_extractor = RGBHistogram(n_bin=n_bin, h_type=h_type)\n",
    "    retrieval = KNNRetrieval(metric=metric)\n",
    "    storage = VectorDBStore(retrieval)\n",
    "    cbir = CBIR(feature_extractor, storage)\n",
    "    \n",
    "    # Indexing\n",
    "    print(f\"Indexing {TRAIN_SIZE} images...\")\n",
    "    start = time()\n",
    "    indexed = 0\n",
    "    \n",
    "    for images, labels, _ in tqdm(train_loader, desc=f\"Indexing ({config_name})\"):\n",
    "        if indexed >= TRAIN_SIZE:\n",
    "            break\n",
    "    \n",
    "        if device.type == \"cuda\":\n",
    "            images = images.to(device)\n",
    "    \n",
    "        count = min(len(images), TRAIN_SIZE - indexed)\n",
    "        images = images[:count]\n",
    "        images = (images.cpu().numpy().transpose(0, 2, 3, 1) * 255).astype(np.uint8)\n",
    "    \n",
    "        cbir.add_images(images)\n",
    "        indexed += count\n",
    "    \n",
    "    indexing_time = time() - start\n",
    "    print(f\"Indexed {indexed} images in {indexing_time:.2f}s\")\n",
    "    \n",
    "    # Save model\n",
    "    model_path = f'out/caltech256_model_{config_name}.pkl.gz'\n",
    "    with gzip.open(model_path, 'wb') as f:\n",
    "        pickle.dump(cbir, f)\n",
    "    \n",
    "    file_size = os.path.getsize(model_path) / 1024 / 1024\n",
    "    print(f\"💾 Model saved: {file_size:.2f} MB\")\n",
    "    \n",
    "    return cbir, indexing_time, file_size, indexed, config_name\n",
    "\n",
    "# Test tất cả combinations\n",
    "results_comparison = {}\n",
    "models = {}\n",
    "all_configs = []\n",
    "\n",
    "for n_bin in n_bins:\n",
    "    for h_type in h_types:\n",
    "        for metric in metrics:\n",
    "            config_name = f\"{n_bin}bin_{h_type}_{metric}\"\n",
    "            all_configs.append((n_bin, h_type, metric, config_name))\n",
    "            \n",
    "            cbir, indexing_time, file_size, indexed, _ = test_combination(n_bin, h_type, metric)\n",
    "            \n",
    "            models[config_name] = cbir\n",
    "            results_comparison[config_name] = {\n",
    "                'n_bin': n_bin,\n",
    "                'h_type': h_type, \n",
    "                'metric': metric,\n",
    "                'indexing_time': indexing_time,\n",
    "                'file_size': file_size,\n",
    "                'indexed_images': indexed\n",
    "            }\n",
    "\n",
    "print(f\"\\n✅ Completed indexing for all {len(all_configs)} combinations!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Dataset root: D:\\AI\\Food-CBIR\\src\\evaluation\\data\\caltech-256\\256_ObjectCategories\n",
      "🔍 Exists: True\n",
      "📂 Found 256 valid categories\n",
      "📊 Loaded 29780 total images from 256 classes\n",
      "📋 Train: 23824 images\n",
      "📂 Found 256 valid categories\n",
      "📊 Loaded 29780 total images from 256 classes\n",
      "📋 Test: 5956 images\n",
      "Train: 23824, Test: 5956\n",
      "🧪 Testing 3 bins × 2 h_types × 2 metrics = 12 combinations\n",
      "\n",
      "🔬 Testing: n_bin=4, h_type=global, metric=cosine\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (4bin_global_cosine): 100%|██████████| 745/745 [04:09<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 249.59s\n",
      "💾 Model saved: 6.14 MB\n",
      "\n",
      "🔬 Testing: n_bin=4, h_type=global, metric=euclidean\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (4bin_global_euclidean): 100%|██████████| 745/745 [02:23<00:00,  5.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 143.44s\n",
      "💾 Model saved: 6.14 MB\n",
      "\n",
      "🔬 Testing: n_bin=4, h_type=region, metric=cosine\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (4bin_region_cosine): 100%|██████████| 745/745 [05:22<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 322.25s\n",
      "💾 Model saved: 39.16 MB\n",
      "\n",
      "🔬 Testing: n_bin=4, h_type=region, metric=euclidean\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (4bin_region_euclidean): 100%|██████████| 745/745 [05:15<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 315.50s\n",
      "💾 Model saved: 39.17 MB\n",
      "\n",
      "🔬 Testing: n_bin=8, h_type=global, metric=cosine\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (8bin_global_cosine): 100%|██████████| 745/745 [02:15<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 135.52s\n",
      "💾 Model saved: 32.44 MB\n",
      "\n",
      "🔬 Testing: n_bin=8, h_type=global, metric=euclidean\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (8bin_global_euclidean): 100%|██████████| 745/745 [03:48<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 228.55s\n",
      "💾 Model saved: 32.44 MB\n",
      "\n",
      "🔬 Testing: n_bin=8, h_type=region, metric=cosine\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (8bin_region_cosine): 100%|██████████| 745/745 [04:43<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 283.92s\n",
      "💾 Model saved: 163.37 MB\n",
      "\n",
      "🔬 Testing: n_bin=8, h_type=region, metric=euclidean\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (8bin_region_euclidean): 100%|██████████| 745/745 [04:53<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 293.81s\n",
      "💾 Model saved: 163.35 MB\n",
      "\n",
      "🔬 Testing: n_bin=12, h_type=global, metric=cosine\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (12bin_global_cosine): 100%|██████████| 745/745 [05:40<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 340.83s\n",
      "💾 Model saved: 77.95 MB\n",
      "\n",
      "🔬 Testing: n_bin=12, h_type=global, metric=euclidean\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (12bin_global_euclidean): 100%|██████████| 745/745 [06:20<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 380.95s\n",
      "💾 Model saved: 77.96 MB\n",
      "\n",
      "🔬 Testing: n_bin=12, h_type=region, metric=cosine\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (12bin_region_cosine): 100%|██████████| 745/745 [12:58<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 778.45s\n",
      "💾 Model saved: 342.13 MB\n",
      "\n",
      "🔬 Testing: n_bin=12, h_type=region, metric=euclidean\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (12bin_region_euclidean): 100%|██████████| 745/745 [13:07<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 787.76s\n",
      "💾 Model saved: 342.10 MB\n",
      "\n",
      "✅ Completed indexing for all 12 combinations!\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "5bbdf283e6cabd9f",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "id": "b0dc4951ac77839c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T18:36:01.442451Z",
     "start_time": "2025-07-11T18:23:02.408544Z"
    }
   },
   "source": [
    "# Hàm để evaluate một model\n",
    "def evaluate_model(cbir, metric_name):\n",
    "    print(f\"\\n📊 Evaluating {metric_name.upper()} model...\")\n",
    "    start = time()\n",
    "    results = []\n",
    "    ground_truth = []\n",
    "    tested = 0\n",
    "\n",
    "    # Get dataset targets for evaluation\n",
    "    dataset_targets = []\n",
    "    for images, labels, _ in train_loader:\n",
    "        if len(dataset_targets) >= indexed:\n",
    "            break\n",
    "        count = min(len(labels), indexed - len(dataset_targets))\n",
    "        dataset_targets.extend(labels[:count].numpy())\n",
    "    dataset_targets = np.array(dataset_targets)\n",
    "\n",
    "    # Query với k=10 để tính mAP@1,5,10\n",
    "    MAX_K = 10\n",
    "\n",
    "    for images, labels, _ in tqdm(test_loader, desc=f\"Testing ({config_name})\"):\n",
    "        if tested >= TEST_SIZE:\n",
    "            break\n",
    "\n",
    "        if device.type == \"cuda\":\n",
    "            images = images.to(device)\n",
    "\n",
    "        count = min(len(images), TEST_SIZE - tested)\n",
    "        images = images[:count]\n",
    "        labels = labels[:count]\n",
    "\n",
    "        images = (images.cpu().numpy().transpose(0, 2, 3, 1) * 255).astype(np.uint8)\n",
    "\n",
    "        for image in images:\n",
    "            if tested >= TEST_SIZE:\n",
    "                break\n",
    "            # Query với k=10 để tính mAP@1,5,10\n",
    "            result = cbir.query_similar_images(image, k=MAX_K)\n",
    "            results.append(result)\n",
    "            tested += 1\n",
    "\n",
    "        ground_truth.extend(labels.numpy())\n",
    "\n",
    "    retrieval_time = time() - start\n",
    "    print(f\"Tested {tested} images in {retrieval_time:.2f}s\")\n",
    "\n",
    "    # Calculate metrics cho k=1, k=5, k=10\n",
    "    k_values = [1, 5, 10]\n",
    "    metrics_data = {}\n",
    "\n",
    "    print(f\"📈 Calculating metrics for k={k_values}...\")\n",
    "\n",
    "    for k in k_values:\n",
    "        map_k, recall_k, hit_k = [], [], []\n",
    "\n",
    "        for r, gt in zip(results, ground_truth):\n",
    "            # Lấy top-k results\n",
    "            top_k_results = r[:k]\n",
    "            indices = [item.index for item in top_k_results]\n",
    "            preds = np.take(dataset_targets, indices)\n",
    "            relevant = np.where(dataset_targets == gt)[0]\n",
    "\n",
    "            map_k.append(average_precision(preds.tolist(), [gt], k))\n",
    "            recall_k.append(recall(indices, relevant, k))\n",
    "            hit_k.append(hit_rate(preds.tolist(), [gt], k))\n",
    "\n",
    "        # Store metrics\n",
    "        metrics_data[f'mAP@{k}'] = np.mean(map_k)\n",
    "        metrics_data[f'Recall@{k}'] = np.mean(recall_k)\n",
    "        metrics_data[f'HitRate@{k}'] = np.mean(hit_k)\n",
    "\n",
    "        print(f\"   k={k}: mAP={np.mean(map_k):.4f}, Recall={np.mean(recall_k):.4f}, HR={np.mean(hit_k):.4f}\")\n",
    "\n",
    "    # Tính average mAP score cho ranking\n",
    "    avg_map = (metrics_data['mAP@1'] + metrics_data['mAP@5'] + metrics_data['mAP@10']) / 3\n",
    "    metrics_data['avg_mAP'] = avg_map\n",
    "\n",
    "    # Add config và timing metrics\n",
    "    metrics_data.update(results_comparison[config_name])\n",
    "    metrics_data['retrieval_time'] = retrieval_time\n",
    "    metrics_data['tested_images'] = tested\n",
    "    metrics_data['config_name'] = config_name\n",
    "\n",
    "    return metrics_data\n",
    "\n",
    "# Evaluate tất cả 12 models\n",
    "print(f\"\\n🚀 Starting evaluation of all {len(models)} models...\")\n",
    "all_results = []\n",
    "\n",
    "for config_name in models.keys():\n",
    "    cbir = models[config_name]\n",
    "    metrics = evaluate_model(cbir, config_name)\n",
    "    all_results.append(metrics)\n",
    "    results_comparison[config_name].update(metrics)\n",
    "\n",
    "# Tìm best model dựa trên average mAP@1,5,10\n",
    "print(f\"\\n🔍 Finding best model based on average mAP@1,5,10...\")\n",
    "best_config = max(results_comparison.keys(), key=lambda x: results_comparison[x]['avg_mAP'])\n",
    "best_model = models[best_config]\n",
    "best_metrics = results_comparison[best_config]\n",
    "\n",
    "print(f\"\\n🏆 BEST MODEL: {best_config}\")\n",
    "print(f\"   Average mAP: {best_metrics['avg_mAP']:.4f}\")\n",
    "print(f\"   mAP@1: {best_metrics['mAP@1']:.4f}\")\n",
    "print(f\"   mAP@5: {best_metrics['mAP@5']:.4f}\")\n",
    "print(f\"   mAP@10: {best_metrics['mAP@10']:.4f}\")\n",
    "\n",
    "# Save best model\n",
    "best_model_path = 'out/best_color.pkl.gz'\n",
    "with gzip.open(best_model_path, 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "best_file_size = os.path.getsize(best_model_path) / 1024 / 1024\n",
    "print(f\"💾 Best model saved as: best_color.pkl.gz ({best_file_size:.2f} MB)\")\n",
    "\n",
    "# Save config của best model\n",
    "best_config_info = {\n",
    "    'config_name': best_config,\n",
    "    'n_bin': best_metrics['n_bin'],\n",
    "    'h_type': best_metrics['h_type'],\n",
    "    'metric': best_metrics['metric'],\n",
    "    'avg_mAP': best_metrics['avg_mAP'],\n",
    "    'mAP@1': best_metrics['mAP@1'],\n",
    "    'mAP@5': best_metrics['mAP@5'],\n",
    "    'mAP@10': best_metrics['mAP@10']\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('out/best_color_config.json', 'w') as f:\n",
    "    json.dump(best_config_info, f, indent=2)\n",
    "print(\"📋 Best model config saved as: best_color_config.json\")\n",
    "\n",
    "# So sánh tất cả kết quả\n",
    "print(f\"\\n📊 ALL RESULTS RANKING (by avg mAP)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Rank':<4} {'Config':<20} {'AvgmAP':<8} {'mAP@1':<8} {'mAP@5':<8} {'mAP@10':<8}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Sort by avg_mAP descending\n",
    "sorted_configs = sorted(results_comparison.items(), key=lambda x: x[1]['avg_mAP'], reverse=True)\n",
    "\n",
    "for rank, (config, data) in enumerate(sorted_configs, 1):\n",
    "    print(f\"{rank:<4} {config:<20} {data['avg_mAP']:<8.4f} {data['mAP@1']:<8.4f} {data['mAP@5']:<8.4f} {data['mAP@10']:<8.4f}\")\n",
    "\n",
    "# Save detailed results\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df = results_df.sort_values('avg_mAP', ascending=False)\n",
    "results_df.to_csv('out/all_color_combinations_results.csv', index=False)\n",
    "print(f\"\\n✅ Detailed results saved to: all_color_combinations_results.csv\")\n",
    "\n",
    "# Top 3 summary\n",
    "print(f\"\\n🥇 TOP 3 CONFIGURATIONS:\")\n",
    "for i, (config, data) in enumerate(sorted_configs[:3], 1):\n",
    "    emoji = [\"🥇\", \"🥈\", \"🥉\"][i-1]\n",
    "    print(f\"{emoji} {config}: avg_mAP={data['avg_mAP']:.4f} (n_bin={data['n_bin']}, h_type={data['h_type']}, metric={data['metric']})\")\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    torch.cuda.empty_cache()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 Starting evaluation of all 12 models...\n",
      "\n",
      "📊 Evaluating 4BIN_GLOBAL_COSINE model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing (4bin_global_cosine):  13%|█▎        | 25/187 [01:04<07:00,  2.59s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 92\u001B[0m\n\u001B[0;32m     90\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m config_name \u001B[38;5;129;01min\u001B[39;00m models\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[0;32m     91\u001B[0m     cbir \u001B[38;5;241m=\u001B[39m models[config_name]\n\u001B[1;32m---> 92\u001B[0m     metrics \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcbir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     93\u001B[0m     all_results\u001B[38;5;241m.\u001B[39mappend(metrics)\n\u001B[0;32m     94\u001B[0m     results_comparison[config_name]\u001B[38;5;241m.\u001B[39mupdate(metrics)\n",
      "Cell \u001B[1;32mIn[21], line 21\u001B[0m, in \u001B[0;36mevaluate_model\u001B[1;34m(cbir, metric_name)\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;66;03m# Query với k=10 để tính mAP@1,5,10\u001B[39;00m\n\u001B[0;32m     19\u001B[0m MAX_K \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10\u001B[39m\n\u001B[1;32m---> 21\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m images, labels, _ \u001B[38;5;129;01min\u001B[39;00m tqdm(test_loader, desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTesting (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mconfig_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m     22\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m tested \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m TEST_SIZE:\n\u001B[0;32m     23\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\.venv\\lib\\site-packages\\tqdm\\std.py:1181\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1178\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[0;32m   1180\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1181\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[0;32m   1182\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[0;32m   1183\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[0;32m   1184\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    698\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    699\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    700\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 701\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    702\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    703\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    704\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable\n\u001B[0;32m    705\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    706\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called\n\u001B[0;32m    707\u001B[0m ):\n",
      "File \u001B[1;32m~\\PycharmProjects\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    755\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    756\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 757\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    758\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    759\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32m~\\PycharmProjects\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     50\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 52\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     54\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32m~\\PycharmProjects\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     50\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 52\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     54\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32mD:\\AI\\Food-CBIR\\src\\datasets\\caltech256.py:118\u001B[0m, in \u001B[0;36mCaltech256Dataset.__getitem__\u001B[1;34m(self, index)\u001B[0m\n\u001B[0;32m    115\u001B[0m label \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlabels[index]\n\u001B[0;32m    116\u001B[0m class_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses[label]\n\u001B[1;32m--> 118\u001B[0m image \u001B[38;5;241m=\u001B[39m \u001B[43mImage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage_path\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mconvert(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRGB\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m    119\u001B[0m image \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform(image)\n\u001B[0;32m    121\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m image, label, class_name\n",
      "File \u001B[1;32m~\\PycharmProjects\\.venv\\lib\\site-packages\\PIL\\Image.py:3469\u001B[0m, in \u001B[0;36mopen\u001B[1;34m(fp, mode, formats)\u001B[0m\n\u001B[0;32m   3466\u001B[0m     filename \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mrealpath(os\u001B[38;5;241m.\u001B[39mfspath(fp))\n\u001B[0;32m   3468\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m filename:\n\u001B[1;32m-> 3469\u001B[0m     fp \u001B[38;5;241m=\u001B[39m \u001B[43mbuiltins\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3470\u001B[0m     exclusive_fp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   3471\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68a9e91f9651c47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
