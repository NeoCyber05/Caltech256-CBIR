{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T04:18:26.070588Z",
     "start_time": "2025-07-12T04:18:18.901127Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.datasets.caltech256 import Caltech256DataModule\n",
    "from src.featuring.rgb_histogram import RGBHistogram\n",
    "from src.storage.VectorDBStore import VectorDBStore\n",
    "from src.retrieval.KNN import KNNRetrieval\n",
    "from src.pipeline import CBIR\n",
    "from src.metrics import average_precision, recall, hit_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84c605e062ed5179",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T04:18:30.921220Z",
     "start_time": "2025-07-12T04:18:30.910666Z"
    }
   },
   "outputs": [],
   "source": [
    "os.makedirs('out', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c00ce3cb06df4f",
   "metadata": {},
   "source": [
    "# INDEXING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f730d283fee6a54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-11T18:23:01.896733Z",
     "start_time": "2025-07-11T15:59:32.007359Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Dataset root: D:\\AI\\Food-CBIR\\src\\evaluation\\data\\caltech-256\\256_ObjectCategories\n",
      "üîç Exists: True\n",
      "üìÇ Found 256 valid categories\n",
      "üìä Loaded 29780 total images from 256 classes\n",
      "üìã Train: 23824 images\n",
      "üìÇ Found 256 valid categories\n",
      "üìä Loaded 29780 total images from 256 classes\n",
      "üìã Test: 5956 images\n",
      "Train: 23824, Test: 5956\n",
      "üß™ Testing 3 bins √ó 2 h_types √ó 2 metrics = 12 combinations\n",
      "\n",
      "üî¨ Testing: n_bin=4, h_type=global, metric=cosine\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (4bin_global_cosine): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 745/745 [04:09<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 249.59s\n",
      "üíæ Model saved: 6.14 MB\n",
      "\n",
      "üî¨ Testing: n_bin=4, h_type=global, metric=euclidean\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (4bin_global_euclidean): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 745/745 [02:23<00:00,  5.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 143.44s\n",
      "üíæ Model saved: 6.14 MB\n",
      "\n",
      "üî¨ Testing: n_bin=4, h_type=region, metric=cosine\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (4bin_region_cosine): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 745/745 [05:22<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 322.25s\n",
      "üíæ Model saved: 39.16 MB\n",
      "\n",
      "üî¨ Testing: n_bin=4, h_type=region, metric=euclidean\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (4bin_region_euclidean): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 745/745 [05:15<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 315.50s\n",
      "üíæ Model saved: 39.17 MB\n",
      "\n",
      "üî¨ Testing: n_bin=8, h_type=global, metric=cosine\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (8bin_global_cosine): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 745/745 [02:15<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 135.52s\n",
      "üíæ Model saved: 32.44 MB\n",
      "\n",
      "üî¨ Testing: n_bin=8, h_type=global, metric=euclidean\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (8bin_global_euclidean): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 745/745 [03:48<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 228.55s\n",
      "üíæ Model saved: 32.44 MB\n",
      "\n",
      "üî¨ Testing: n_bin=8, h_type=region, metric=cosine\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (8bin_region_cosine): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 745/745 [04:43<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 283.92s\n",
      "üíæ Model saved: 163.37 MB\n",
      "\n",
      "üî¨ Testing: n_bin=8, h_type=region, metric=euclidean\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (8bin_region_euclidean): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 745/745 [04:53<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 293.81s\n",
      "üíæ Model saved: 163.35 MB\n",
      "\n",
      "üî¨ Testing: n_bin=12, h_type=global, metric=cosine\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (12bin_global_cosine): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 745/745 [05:40<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 340.83s\n",
      "üíæ Model saved: 77.95 MB\n",
      "\n",
      "üî¨ Testing: n_bin=12, h_type=global, metric=euclidean\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (12bin_global_euclidean): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 745/745 [06:20<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 380.95s\n",
      "üíæ Model saved: 77.96 MB\n",
      "\n",
      "üî¨ Testing: n_bin=12, h_type=region, metric=cosine\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (12bin_region_cosine): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 745/745 [12:58<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 778.45s\n",
      "üíæ Model saved: 342.13 MB\n",
      "\n",
      "üî¨ Testing: n_bin=12, h_type=region, metric=euclidean\n",
      "Indexing 24607 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing (12bin_region_euclidean): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 745/745 [13:07<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 23824 images in 787.76s\n",
      "üíæ Model saved: 342.10 MB\n",
      "\n",
      "‚úÖ Completed indexing for all 12 combinations!\n"
     ]
    }
   ],
   "source": [
    "TRAIN_SIZE = 24607  # S·ªë l∆∞·ª£ng ·∫£nh ƒë·ªÉ index\n",
    "TEST_SIZE = 1000   # Gi·∫£m test size ƒë·ªÉ test nhanh h∆°n v·ªõi nhi·ªÅu combinations\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Kh·ªüi t·∫°o dataset\n",
    "import os\n",
    "root_path = os.path.abspath('data/caltech-256/256_ObjectCategories')\n",
    "print(f\"üîç Dataset root: {root_path}\")\n",
    "print(f\"üîç Exists: {os.path.exists(root_path)}\")\n",
    "data_module = Caltech256DataModule(batch_size=32, root=root_path)\n",
    "data_module.setup()\n",
    "train_loader = data_module.train_dataloader()\n",
    "test_loader = data_module.test_dataloader()\n",
    "\n",
    "# T·∫•t c·∫£ combinations ƒë·ªÉ test\n",
    "n_bins = [4, 8, 12]\n",
    "h_types = [\"global\", \"region\"]\n",
    "metrics = [\"cosine\", \"euclidean\"]\n",
    "\n",
    "print(f\"üß™ Testing {len(n_bins)} bins √ó {len(h_types)} h_types √ó {len(metrics)} metrics = {len(n_bins)*len(h_types)*len(metrics)} combinations\")\n",
    "\n",
    "# H√†m ƒë·ªÉ test m·ªôt combination\n",
    "def test_combination(n_bin, h_type, metric):\n",
    "    config_name = f\"{n_bin}bin_{h_type}_{metric}\"\n",
    "    print(f\"\\nüî¨ Testing: n_bin={n_bin}, h_type={h_type}, metric={metric}\")\n",
    "    \n",
    "    # Kh·ªüi t·∫°o CBIR pipeline \n",
    "    feature_extractor = RGBHistogram(n_bin=n_bin, h_type=h_type)\n",
    "    retrieval = KNNRetrieval(metric=metric)\n",
    "    storage = VectorDBStore(retrieval)\n",
    "    cbir = CBIR(feature_extractor, storage)\n",
    "    \n",
    "    # Indexing\n",
    "    print(f\"Indexing {TRAIN_SIZE} images...\")\n",
    "    start = time()\n",
    "    indexed = 0\n",
    "    \n",
    "    for images, labels, _ in tqdm(train_loader, desc=f\"Indexing ({config_name})\"):\n",
    "        if indexed >= TRAIN_SIZE:\n",
    "            break\n",
    "    \n",
    "        if device.type == \"cuda\":\n",
    "            images = images.to(device)\n",
    "    \n",
    "        count = min(len(images), TRAIN_SIZE - indexed)\n",
    "        images = images[:count]\n",
    "        images = (images.cpu().numpy().transpose(0, 2, 3, 1) * 255).astype(np.uint8)\n",
    "    \n",
    "        cbir.add_images(images)\n",
    "        indexed += count\n",
    "    \n",
    "    indexing_time = time() - start\n",
    "    print(f\"Indexed {indexed} images in {indexing_time:.2f}s\")\n",
    "    \n",
    "    # Save model\n",
    "    model_path = f'out/caltech256_model_{config_name}.pkl.gz'\n",
    "    with gzip.open(model_path, 'wb') as f:\n",
    "        pickle.dump(cbir, f)\n",
    "    \n",
    "    file_size = os.path.getsize(model_path) / 1024 / 1024\n",
    "    print(f\"üíæ Model saved: {file_size:.2f} MB\")\n",
    "    \n",
    "    return cbir, indexing_time, file_size, indexed, config_name\n",
    "\n",
    "# Test t·∫•t c·∫£ combinations\n",
    "results_comparison = {}\n",
    "models = {}\n",
    "all_configs = []\n",
    "\n",
    "for n_bin in n_bins:\n",
    "    for h_type in h_types:\n",
    "        for metric in metrics:\n",
    "            config_name = f\"{n_bin}bin_{h_type}_{metric}\"\n",
    "            all_configs.append((n_bin, h_type, metric, config_name))\n",
    "            \n",
    "            cbir, indexing_time, file_size, indexed, _ = test_combination(n_bin, h_type, metric)\n",
    "            \n",
    "            models[config_name] = cbir\n",
    "            results_comparison[config_name] = {\n",
    "                'n_bin': n_bin,\n",
    "                'h_type': h_type, \n",
    "                'metric': metric,\n",
    "                'indexing_time': indexing_time,\n",
    "                'file_size': file_size,\n",
    "                'indexed_images': indexed\n",
    "            }\n",
    "\n",
    "print(f\"\\n‚úÖ Completed indexing for all {len(all_configs)} combinations!\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "08e904c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T05:04:58.049757Z",
     "start_time": "2025-07-12T05:03:32.566585Z"
    }
   },
   "source": [
    "# Load l·∫°i t·∫•t c·∫£ models t·ª´ file ƒë√£ t·∫°o tr∆∞·ªõc ƒë√≥\n",
    "TRAIN_SIZE = 24607\n",
    "TEST_SIZE = 1000\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Kh·ªüi t·∫°o dataset\n",
    "root_path = os.path.abspath('data/caltech-256/256_ObjectCategories')\n",
    "print(f\"üîç Dataset root: {root_path}\")\n",
    "data_module = Caltech256DataModule(batch_size=32, root=root_path)\n",
    "data_module.setup()\n",
    "train_loader = data_module.train_dataloader()\n",
    "test_loader = data_module.test_dataloader()\n",
    "\n",
    "# T·∫•t c·∫£ combinations ƒë·ªÉ test\n",
    "n_bins = [4, 8, 12]\n",
    "h_types = [\"global\", \"region\"]\n",
    "metrics = [\"cosine\", \"euclidean\"]\n",
    "\n",
    "print(f\"üß™ Testing {len(n_bins)} bins √ó {len(h_types)} h_types √ó {len(metrics)} metrics = {len(n_bins)*len(h_types)*len(metrics)} combinations\")\n",
    "\n",
    "# T·∫°o l·∫°i bi·∫øn models v√† results_comparison\n",
    "models = {}\n",
    "results_comparison = {}\n",
    "\n",
    "# Load t·∫•t c·∫£ models t·ª´ th∆∞ m·ª•c evaluation/out\n",
    "print(\"üîÑ Loading existing models...\")\n",
    "model_files = []\n",
    "for n_bin in n_bins:\n",
    "    for h_type in h_types:\n",
    "        for metric in metrics:\n",
    "            config_name = f\"{n_bin}bin_{h_type}_{metric}\"\n",
    "            model_path = f'out/caltech256_model_{config_name}.pkl.gz'\n",
    "            if os.path.exists(model_path):\n",
    "                print(f\"‚úÖ Found existing model: {config_name}\")\n",
    "                try:\n",
    "                    with gzip.open(model_path, 'rb') as f:\n",
    "                        cbir = pickle.load(f)\n",
    "                    models[config_name] = cbir\n",
    "                    file_size = os.path.getsize(model_path) / 1024 / 1024\n",
    "                    results_comparison[config_name] = {\n",
    "                        'n_bin': n_bin,\n",
    "                        'h_type': h_type,\n",
    "                        'metric': metric,\n",
    "                        'file_size': file_size,\n",
    "                        'indexed_images': 23824  # T·ª´ k·∫øt qu·∫£ indexing tr∆∞·ªõc ƒë√≥\n",
    "                    }\n",
    "                    model_files.append(config_name)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Error loading model {config_name}: {e}\")\n",
    "            else:\n",
    "                print(f\"‚ùå Model file not found: {config_name}\")\n",
    "\n",
    "print(f\"\\nüìä Loaded {len(models)} models successfully\")\n",
    "print(f\"Model configs: {list(models.keys())}\")\n",
    "\n",
    "# Ki·ªÉm tra xem c√≥ ƒë·ªß models kh√¥ng\n",
    "if len(models) == 12:\n",
    "    print(\"üéâ All 12 models loaded successfully!\")\n",
    "elif len(models) > 0:\n",
    "    print(f\"‚ö†Ô∏è  Loaded {len(models)}/12 models, proceeding with available models\")\n",
    "else:\n",
    "    print(\"‚ùå No models found! Please check file paths\")\n",
    "\n",
    "print(f\"\\nüéØ Ready for evaluation with {len(models)} model(s)\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Dataset root: D:\\AI\\Food-CBIR\\src\\evaluation\\data\\caltech-256\\256_ObjectCategories\n",
      "üìÇ Found 256 valid categories\n",
      "üìä Loaded 29780 total images from 256 classes\n",
      "üìã Train: 23824 images\n",
      "üìÇ Found 256 valid categories\n",
      "üìä Loaded 29780 total images from 256 classes\n",
      "üìã Test: 5956 images\n",
      "Train: 23824, Test: 5956\n",
      "üß™ Testing 3 bins √ó 2 h_types √ó 2 metrics = 12 combinations\n",
      "üîÑ Loading existing models...\n",
      "‚úÖ Found existing model: 4bin_global_cosine\n",
      "‚úÖ Found existing model: 4bin_global_euclidean\n",
      "‚úÖ Found existing model: 4bin_region_cosine\n",
      "‚úÖ Found existing model: 4bin_region_euclidean\n",
      "‚úÖ Found existing model: 8bin_global_cosine\n",
      "‚úÖ Found existing model: 8bin_global_euclidean\n",
      "‚úÖ Found existing model: 8bin_region_cosine\n",
      "‚úÖ Found existing model: 8bin_region_euclidean\n",
      "‚úÖ Found existing model: 12bin_global_cosine\n",
      "‚úÖ Found existing model: 12bin_global_euclidean\n",
      "‚úÖ Found existing model: 12bin_region_cosine\n",
      "‚úÖ Found existing model: 12bin_region_euclidean\n",
      "\n",
      "üìä Loaded 12 models successfully\n",
      "Model configs: ['4bin_global_cosine', '4bin_global_euclidean', '4bin_region_cosine', '4bin_region_euclidean', '8bin_global_cosine', '8bin_global_euclidean', '8bin_region_cosine', '8bin_region_euclidean', '12bin_global_cosine', '12bin_global_euclidean', '12bin_region_cosine', '12bin_region_euclidean']\n",
      "üéâ All 12 models loaded successfully!\n",
      "\n",
      "üéØ Ready for evaluation with 12 model(s)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "5bbdf283e6cabd9f",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "id": "b0dc4951ac77839c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T07:18:11.646133Z",
     "start_time": "2025-07-12T05:05:11.924827Z"
    }
   },
   "source": [
    "# H√†m ƒë·ªÉ evaluate m·ªôt model\n",
    "def evaluate_model(cbir, config_name):\n",
    "    print(f\"\\nüìä Evaluating {config_name.upper()} model...\")\n",
    "    start = time()\n",
    "    results = []\n",
    "    ground_truth = []\n",
    "    tested = 0\n",
    "\n",
    "    # Get dataset targets for evaluation - s·ª≠ d·ª•ng s·ªë l∆∞·ª£ng images ƒë√£ indexed\n",
    "    dataset_targets = []\n",
    "    indexed_count = 23824  # S·ªë l∆∞·ª£ng ·∫£nh ƒë√£ ƒë∆∞·ª£c index t·ª´ k·∫øt qu·∫£ tr∆∞·ªõc ƒë√≥\n",
    "    \n",
    "    for images, labels, _ in train_loader:\n",
    "        if len(dataset_targets) >= indexed_count:\n",
    "            break\n",
    "        count = min(len(labels), indexed_count - len(dataset_targets))\n",
    "        dataset_targets.extend(labels[:count].numpy())\n",
    "    dataset_targets = np.array(dataset_targets)\n",
    "\n",
    "    # Query v·ªõi k=10 ƒë·ªÉ t√≠nh mAP@1,5,10\n",
    "    MAX_K = 10\n",
    "\n",
    "    for images, labels, _ in tqdm(test_loader, desc=f\"Testing ({config_name})\"):\n",
    "        if tested >= TEST_SIZE:\n",
    "            break\n",
    "\n",
    "        if device.type == \"cuda\":\n",
    "            images = images.to(device)\n",
    "\n",
    "        count = min(len(images), TEST_SIZE - tested)\n",
    "        images = images[:count]\n",
    "        labels = labels[:count]\n",
    "\n",
    "        images = (images.cpu().numpy().transpose(0, 2, 3, 1) * 255).astype(np.uint8)\n",
    "\n",
    "        for image in images:\n",
    "            if tested >= TEST_SIZE:\n",
    "                break\n",
    "            # Query v·ªõi k=10 ƒë·ªÉ t√≠nh mAP@1,5,10\n",
    "            result = cbir.query_similar_images(image, k=MAX_K)\n",
    "            results.append(result)\n",
    "            tested += 1\n",
    "\n",
    "        ground_truth.extend(labels.numpy())\n",
    "\n",
    "    retrieval_time = time() - start\n",
    "    print(f\"Tested {tested} images in {retrieval_time:.2f}s\")\n",
    "\n",
    "    # Calculate metrics cho k=1, k=5, k=10\n",
    "    k_values = [1, 5, 10]\n",
    "    metrics_data = {}\n",
    "\n",
    "    print(f\"üìà Calculating metrics for k={k_values}...\")\n",
    "\n",
    "    for k in k_values:\n",
    "        map_k, recall_k, hit_k = [], [], []\n",
    "\n",
    "        for r, gt in zip(results, ground_truth):\n",
    "            # L·∫•y top-k results\n",
    "            top_k_results = r[:k]\n",
    "            indices = [item.index for item in top_k_results]\n",
    "            preds = np.take(dataset_targets, indices)\n",
    "            relevant = np.where(dataset_targets == gt)[0]\n",
    "\n",
    "            map_k.append(average_precision(preds.tolist(), [gt], k))\n",
    "            recall_k.append(recall(indices, relevant, k))\n",
    "            hit_k.append(hit_rate(preds.tolist(), [gt], k))\n",
    "\n",
    "        # Store metrics\n",
    "        metrics_data[f'mAP@{k}'] = np.mean(map_k)\n",
    "        metrics_data[f'Recall@{k}'] = np.mean(recall_k)\n",
    "        metrics_data[f'HitRate@{k}'] = np.mean(hit_k)\n",
    "\n",
    "        print(f\"   k={k}: mAP={np.mean(map_k):.4f}, Recall={np.mean(recall_k):.4f}, HR={np.mean(hit_k):.4f}\")\n",
    "\n",
    "    # T√≠nh average mAP score cho ranking\n",
    "    avg_map = (metrics_data['mAP@1'] + metrics_data['mAP@5'] + metrics_data['mAP@10']) / 3\n",
    "    metrics_data['avg_mAP'] = avg_map\n",
    "\n",
    "    # Add config v√† timing metrics\n",
    "    if config_name in results_comparison:\n",
    "        metrics_data.update(results_comparison[config_name])\n",
    "    metrics_data['retrieval_time'] = retrieval_time\n",
    "    metrics_data['tested_images'] = tested\n",
    "    metrics_data['config_name'] = config_name\n",
    "\n",
    "    return metrics_data\n",
    "\n",
    "# Evaluate t·∫•t c·∫£ 12 models\n",
    "print(f\"\\nüöÄ Starting evaluation of all {len(models)} models...\")\n",
    "all_results = []\n",
    "\n",
    "for config_name in models.keys():\n",
    "    cbir = models[config_name]\n",
    "    metrics = evaluate_model(cbir, config_name)\n",
    "    all_results.append(metrics)\n",
    "    results_comparison[config_name].update(metrics)\n",
    "\n",
    "# T√¨m best model d·ª±a tr√™n average mAP@1,5,10\n",
    "print(f\"\\nüîç Finding best model based on average mAP@1,5,10...\")\n",
    "best_config = max(results_comparison.keys(), key=lambda x: results_comparison[x]['avg_mAP'])\n",
    "best_model = models[best_config]\n",
    "best_metrics = results_comparison[best_config]\n",
    "\n",
    "print(f\"\\nüèÜ BEST MODEL: {best_config}\")\n",
    "print(f\"   Average mAP: {best_metrics['avg_mAP']:.4f}\")\n",
    "print(f\"   mAP@1: {best_metrics['mAP@1']:.4f}\")\n",
    "print(f\"   mAP@5: {best_metrics['mAP@5']:.4f}\")\n",
    "print(f\"   mAP@10: {best_metrics['mAP@10']:.4f}\")\n",
    "\n",
    "# Save best model\n",
    "best_model_path = 'out/best_color.pkl.gz'\n",
    "with gzip.open(best_model_path, 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "best_file_size = os.path.getsize(best_model_path) / 1024 / 1024\n",
    "print(f\"üíæ Best model saved as: best_color.pkl.gz ({best_file_size:.2f} MB)\")\n",
    "\n",
    "# Save config c·ªßa best model\n",
    "best_config_info = {\n",
    "    'config_name': best_config,\n",
    "    'n_bin': best_metrics['n_bin'],\n",
    "    'h_type': best_metrics['h_type'],\n",
    "    'metric': best_metrics['metric'],\n",
    "    'avg_mAP': best_metrics['avg_mAP'],\n",
    "    'mAP@1': best_metrics['mAP@1'],\n",
    "    'mAP@5': best_metrics['mAP@5'],\n",
    "    'mAP@10': best_metrics['mAP@10']\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('out/best_color_config.json', 'w') as f:\n",
    "    json.dump(best_config_info, f, indent=2)\n",
    "print(\"üìã Best model config saved as: best_color_config.json\")\n",
    "\n",
    "# So s√°nh t·∫•t c·∫£ k·∫øt qu·∫£\n",
    "print(f\"\\nüìä ALL RESULTS RANKING (by avg mAP)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Rank':<4} {'Config':<20} {'AvgmAP':<8} {'mAP@1':<8} {'mAP@5':<8} {'mAP@10':<8}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Sort by avg_mAP descending\n",
    "sorted_configs = sorted(results_comparison.items(), key=lambda x: x[1]['avg_mAP'], reverse=True)\n",
    "\n",
    "for rank, (config, data) in enumerate(sorted_configs, 1):\n",
    "    print(f\"{rank:<4} {config:<20} {data['avg_mAP']:<8.4f} {data['mAP@1']:<8.4f} {data['mAP@5']:<8.4f} {data['mAP@10']:<8.4f}\")\n",
    "\n",
    "# Save detailed results\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df = results_df.sort_values('avg_mAP', ascending=False)\n",
    "results_df.to_csv('out/all_color_combinations_results.csv', index=False)\n",
    "print(f\"\\n‚úÖ Detailed results saved to: all_color_combinations_results.csv\")\n",
    "\n",
    "# Top 3 summary\n",
    "print(f\"\\nü•á TOP 3 CONFIGURATIONS:\")\n",
    "for i, (config, data) in enumerate(sorted_configs[:3], 1):\n",
    "    emoji = [\"ü•á\", \"ü•à\", \"ü•â\"][i-1]\n",
    "    print(f\"{emoji} {config}: avg_mAP={data['avg_mAP']:.4f} (n_bin={data['n_bin']}, h_type={data['h_type']}, metric={data['metric']})\")\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    torch.cuda.empty_cache()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ Starting evaluation of all 12 models...\n",
      "\n",
      "üìä Evaluating 4BIN_GLOBAL_COSINE model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing (4bin_global_cosine):  17%|‚ñà‚ñã        | 32/187 [00:15<01:13,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested 1000 images in 292.57s\n",
      "üìà Calculating metrics for k=[1, 5, 10]...\n",
      "   k=1: mAP=0.0025, Recall=0.0000, HR=0.0050\n",
      "   k=5: mAP=0.0067, Recall=0.0002, HR=0.0062\n",
      "   k=10: mAP=0.0086, Recall=0.0005, HR=0.0063\n",
      "\n",
      "üìä Evaluating 4BIN_GLOBAL_EUCLIDEAN model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing (4bin_global_euclidean):  17%|‚ñà‚ñã        | 32/187 [00:09<00:44,  3.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested 1000 images in 92.50s\n",
      "üìà Calculating metrics for k=[1, 5, 10]...\n",
      "   k=1: mAP=0.0030, Recall=0.0000, HR=0.0060\n",
      "   k=5: mAP=0.0062, Recall=0.0002, HR=0.0056\n",
      "   k=10: mAP=0.0077, Recall=0.0005, HR=0.0053\n",
      "\n",
      "üìä Evaluating 4BIN_REGION_COSINE model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing (4bin_region_cosine):  17%|‚ñà‚ñã        | 32/187 [01:22<06:40,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested 1000 images in 162.85s\n",
      "üìà Calculating metrics for k=[1, 5, 10]...\n",
      "   k=1: mAP=0.0025, Recall=0.0001, HR=0.0050\n",
      "   k=5: mAP=0.0068, Recall=0.0003, HR=0.0064\n",
      "   k=10: mAP=0.0090, Recall=0.0005, HR=0.0064\n",
      "\n",
      "üìä Evaluating 4BIN_REGION_EUCLIDEAN model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing (4bin_region_euclidean):  17%|‚ñà‚ñã        | 32/187 [00:13<01:04,  2.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested 1000 images in 95.78s\n",
      "üìà Calculating metrics for k=[1, 5, 10]...\n",
      "   k=1: mAP=0.0025, Recall=0.0000, HR=0.0050\n",
      "   k=5: mAP=0.0059, Recall=0.0002, HR=0.0048\n",
      "   k=10: mAP=0.0075, Recall=0.0004, HR=0.0050\n",
      "\n",
      "üìä Evaluating 8BIN_GLOBAL_COSINE model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing (8bin_global_cosine):  17%|‚ñà‚ñã        | 32/187 [00:44<03:33,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested 1000 images in 126.50s\n",
      "üìà Calculating metrics for k=[1, 5, 10]...\n",
      "   k=1: mAP=0.0030, Recall=0.0001, HR=0.0060\n",
      "   k=5: mAP=0.0065, Recall=0.0003, HR=0.0058\n",
      "   k=10: mAP=0.0085, Recall=0.0005, HR=0.0059\n",
      "\n",
      "üìä Evaluating 8BIN_GLOBAL_EUCLIDEAN model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing (8bin_global_euclidean):  17%|‚ñà‚ñã        | 32/187 [00:25<02:04,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested 1000 images in 109.02s\n",
      "üìà Calculating metrics for k=[1, 5, 10]...\n",
      "   k=1: mAP=0.0000, Recall=0.0000, HR=0.0000\n",
      "   k=5: mAP=0.0033, Recall=0.0002, HR=0.0044\n",
      "   k=10: mAP=0.0051, Recall=0.0004, HR=0.0051\n",
      "\n",
      "üìä Evaluating 8BIN_REGION_COSINE model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing (8bin_region_cosine):  17%|‚ñà‚ñã        | 32/187 [12:19<59:42, 23.12s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested 1000 images in 821.33s\n",
      "üìà Calculating metrics for k=[1, 5, 10]...\n",
      "   k=1: mAP=0.0015, Recall=0.0000, HR=0.0030\n",
      "   k=5: mAP=0.0055, Recall=0.0002, HR=0.0058\n",
      "   k=10: mAP=0.0074, Recall=0.0005, HR=0.0061\n",
      "\n",
      "üìä Evaluating 8BIN_REGION_EUCLIDEAN model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing (8bin_region_euclidean):  17%|‚ñà‚ñã        | 32/187 [01:40<08:07,  3.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested 1000 images in 250.08s\n",
      "üìà Calculating metrics for k=[1, 5, 10]...\n",
      "   k=1: mAP=0.0025, Recall=0.0000, HR=0.0050\n",
      "   k=5: mAP=0.0076, Recall=0.0003, HR=0.0074\n",
      "   k=10: mAP=0.0090, Recall=0.0005, HR=0.0061\n",
      "\n",
      "üìä Evaluating 12BIN_GLOBAL_COSINE model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing (12bin_global_cosine):  17%|‚ñà‚ñã        | 32/187 [05:12<25:13,  9.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested 1000 images in 522.97s\n",
      "üìà Calculating metrics for k=[1, 5, 10]...\n",
      "   k=1: mAP=0.0010, Recall=0.0000, HR=0.0020\n",
      "   k=5: mAP=0.0050, Recall=0.0002, HR=0.0050\n",
      "   k=10: mAP=0.0065, Recall=0.0004, HR=0.0047\n",
      "\n",
      "üìä Evaluating 12BIN_GLOBAL_EUCLIDEAN model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing (12bin_global_euclidean):  17%|‚ñà‚ñã        | 32/187 [01:48<08:43,  3.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested 1000 images in 297.84s\n",
      "üìà Calculating metrics for k=[1, 5, 10]...\n",
      "   k=1: mAP=0.0025, Recall=0.0000, HR=0.0050\n",
      "   k=5: mAP=0.0055, Recall=0.0002, HR=0.0048\n",
      "   k=10: mAP=0.0078, Recall=0.0005, HR=0.0059\n",
      "\n",
      "üìä Evaluating 12BIN_REGION_COSINE model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing (12bin_region_cosine):  17%|‚ñà‚ñã        | 32/187 [1:22:01<6:37:17, 153.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested 1000 images in 5126.45s\n",
      "üìà Calculating metrics for k=[1, 5, 10]...\n",
      "   k=1: mAP=0.0025, Recall=0.0000, HR=0.0050\n",
      "   k=5: mAP=0.0071, Recall=0.0002, HR=0.0068\n",
      "   k=10: mAP=0.0087, Recall=0.0004, HR=0.0058\n",
      "\n",
      "üìä Evaluating 12BIN_REGION_EUCLIDEAN model...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 95\u001B[0m\n\u001B[0;32m     93\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m config_name \u001B[38;5;129;01min\u001B[39;00m models\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[0;32m     94\u001B[0m     cbir \u001B[38;5;241m=\u001B[39m models[config_name]\n\u001B[1;32m---> 95\u001B[0m     metrics \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcbir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     96\u001B[0m     all_results\u001B[38;5;241m.\u001B[39mappend(metrics)\n\u001B[0;32m     97\u001B[0m     results_comparison[config_name]\u001B[38;5;241m.\u001B[39mupdate(metrics)\n",
      "Cell \u001B[1;32mIn[9], line 13\u001B[0m, in \u001B[0;36mevaluate_model\u001B[1;34m(cbir, config_name)\u001B[0m\n\u001B[0;32m     10\u001B[0m dataset_targets \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m     11\u001B[0m indexed_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m23824\u001B[39m  \u001B[38;5;66;03m# S·ªë l∆∞·ª£ng ·∫£nh ƒë√£ ƒë∆∞·ª£c index t·ª´ k·∫øt qu·∫£ tr∆∞·ªõc ƒë√≥\u001B[39;00m\n\u001B[1;32m---> 13\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m images, labels, _ \u001B[38;5;129;01min\u001B[39;00m train_loader:\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(dataset_targets) \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m indexed_count:\n\u001B[0;32m     15\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    698\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    699\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    700\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 701\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    702\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    703\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    704\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable\n\u001B[0;32m    705\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    706\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called\n\u001B[0;32m    707\u001B[0m ):\n",
      "File \u001B[1;32m~\\PycharmProjects\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    755\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    756\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 757\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    758\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    759\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32m~\\PycharmProjects\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     50\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 52\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     54\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32m~\\PycharmProjects\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     50\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 52\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     54\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32mD:\\AI\\Food-CBIR\\src\\datasets\\caltech256.py:119\u001B[0m, in \u001B[0;36mCaltech256Dataset.__getitem__\u001B[1;34m(self, index)\u001B[0m\n\u001B[0;32m    116\u001B[0m class_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses[label]\n\u001B[0;32m    118\u001B[0m image \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mopen(image_path)\u001B[38;5;241m.\u001B[39mconvert(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRGB\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m--> 119\u001B[0m image \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    121\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m image, label, class_name\n",
      "File \u001B[1;32m~\\PycharmProjects\\.venv\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001B[0m, in \u001B[0;36mCompose.__call__\u001B[1;34m(self, img)\u001B[0m\n\u001B[0;32m     93\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, img):\n\u001B[0;32m     94\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransforms:\n\u001B[1;32m---> 95\u001B[0m         img \u001B[38;5;241m=\u001B[39m \u001B[43mt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     96\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
      "File \u001B[1;32m~\\PycharmProjects\\.venv\\lib\\site-packages\\torchvision\\transforms\\transforms.py:137\u001B[0m, in \u001B[0;36mToTensor.__call__\u001B[1;34m(self, pic)\u001B[0m\n\u001B[0;32m    129\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, pic):\n\u001B[0;32m    130\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    131\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m    132\u001B[0m \u001B[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    135\u001B[0m \u001B[38;5;124;03m        Tensor: Converted image.\u001B[39;00m\n\u001B[0;32m    136\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 137\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpic\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\.venv\\lib\\site-packages\\torchvision\\transforms\\functional.py:176\u001B[0m, in \u001B[0;36mto_tensor\u001B[1;34m(pic)\u001B[0m\n\u001B[0;32m    174\u001B[0m img \u001B[38;5;241m=\u001B[39m img\u001B[38;5;241m.\u001B[39mpermute((\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m))\u001B[38;5;241m.\u001B[39mcontiguous()\n\u001B[0;32m    175\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(img, torch\u001B[38;5;241m.\u001B[39mByteTensor):\n\u001B[1;32m--> 176\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mimg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdefault_float_dtype\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mdiv(\u001B[38;5;241m255\u001B[39m)\n\u001B[0;32m    177\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    178\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68a9e91f9651c47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
