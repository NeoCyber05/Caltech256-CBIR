{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# RGB Histogram Evaluation v·ªõi ChromaDB\n",
    "\n",
    "Notebook n√†y t√°ch ri√™ng qu√° tr√¨nh indexing v√† evaluation ƒë·ªÉ ki·ªÉm so√°t t·ªët h∆°n:\n",
    "1. **Setup**: Import libraries v√† c·∫•u h√¨nh\n",
    "2. **Indexing**: Extract features v√† l∆∞u v√†o ChromaDB\n",
    "3. **Evaluation**: Ch·∫°y evaluation tr√™n data ƒë√£ c√≥\n",
    "\n",
    "## Dataset Split: 80% Training / 20% Testing\n",
    "- Training: 23,824 samples (80%)\n",
    "- Testing: 5,956 samples (20%)\n",
    "- Total: 29,780 samples\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 1. Setup v√† C·∫•u h√¨nh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T08:23:18.114365Z",
     "start_time": "2025-07-12T08:23:13.115912Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports ho√†n t·∫•t!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "from src.datasets.caltech256 import Caltech256DataModule\n",
    "from src.featuring.rgb_histogram import RGBHistogram\n",
    "from src.metrics import average_precision, recall, hit_rate\n",
    "\n",
    "# T·∫°o th∆∞ m·ª•c output\n",
    "os.makedirs('out', exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Imports ho√†n t·∫•t!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T08:24:43.456081Z",
     "start_time": "2025-07-12T08:24:43.435853Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã T·ªïng c·∫•u h√¨nh ƒë·ªÉ test: 8\n",
      "üìä Test size: 5956\n",
      "üíæ ChromaDB storage: chroma_storage\n",
      "üéØ Evaluation k-values: [1, 5, 10]\n"
     ]
    }
   ],
   "source": [
    "# ======================== CONFIGURATIONS ========================\n",
    "CONFIGS = [\n",
    "    # (n_bin, h_type, metric)\n",
    "    (4, 'global', 'cosine'),\n",
    "    (4, 'global', 'l2'),\n",
    "    (4, 'region', 'cosine'), \n",
    "    (4, 'region', 'l2'),\n",
    "    (8, 'global', 'cosine'),\n",
    "    (8, 'global', 'l2'),\n",
    "    (8, 'region', 'cosine'),\n",
    "    (8, 'region', 'l2'),\n",
    "]\n",
    "\n",
    "# C·∫•u h√¨nh evaluation\n",
    "TEST_SIZE = 5956     # S·ªë l∆∞·ª£ng test samples ƒë·ªÉ evaluation\n",
    "N_SLICE = 3          # S·ªë slice cho region histogram\n",
    "K_VALUES = [1, 5, 10]  # Top-k cho evaluation\n",
    "\n",
    "# ChromaDB settings\n",
    "CHROMA_DIR = \"chroma_storage\"\n",
    "COLLECTION_PREFIX = \"rgb_hist\"\n",
    "\n",
    "print(f\"üìã T·ªïng c·∫•u h√¨nh ƒë·ªÉ test: {len(CONFIGS)}\")\n",
    "print(f\"üìä Test size: {TEST_SIZE}\")\n",
    "print(f\"üíæ ChromaDB storage: {CHROMA_DIR}\")\n",
    "print(f\"üéØ Evaluation k-values: {K_VALUES}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T08:24:46.412907Z",
     "start_time": "2025-07-12T08:24:45.767786Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Dataset path: D:\\AI\\Food-CBIR\\src\\evaluation\\data\\caltech-256\\256_ObjectCategories\n",
      "üìÇ Exists: True\n",
      "üìÇ Found 256 valid categories\n",
      "üìä Loaded 29780 total images from 256 classes\n",
      "üìã Train: 23824 images\n",
      "üìÇ Found 256 valid categories\n",
      "üìä Loaded 29780 total images from 256 classes\n",
      "üìã Test: 5956 images\n",
      "Train: 23824, Test: 5956\n",
      "‚úÖ Dataset loaded th√†nh c√¥ng!\n",
      "üìä Training: 23824 samples (80.0%)\n",
      "üìä Testing: 5956 samples (20.0%)\n",
      "üìä Total: 29780 samples\n"
     ]
    }
   ],
   "source": [
    "# Setup dataset\n",
    "dataset_root = os.path.abspath('data/caltech-256/256_ObjectCategories')\n",
    "print(f\"üìÇ Dataset path: {dataset_root}\")\n",
    "print(f\"üìÇ Exists: {os.path.exists(dataset_root)}\")\n",
    "\n",
    "if os.path.exists(dataset_root):\n",
    "    data_module = Caltech256DataModule(batch_size=32, root=dataset_root)\n",
    "    data_module.setup()\n",
    "    train_loader = data_module.train_dataloader()\n",
    "    test_loader = data_module.test_dataloader()\n",
    "    \n",
    "    train_size = len(train_loader.dataset)\n",
    "    test_size = len(test_loader.dataset)\n",
    "    total_size = train_size + test_size\n",
    "    \n",
    "    print(f\"‚úÖ Dataset loaded th√†nh c√¥ng!\")\n",
    "    print(f\"üìä Training: {train_size} samples ({train_size/total_size*100:.1f}%)\")\n",
    "    print(f\"üìä Testing: {test_size} samples ({test_size/total_size*100:.1f}%)\")\n",
    "    print(f\"üìä Total: {total_size} samples\")\n",
    "else:\n",
    "    print(\"‚ùå Dataset kh√¥ng t√¨m th·∫•y!\")\n",
    "    print(\"Vui l√≤ng ƒë·∫£m b·∫£o dataset ·ªü ƒë∆∞·ªùng d·∫´n ƒë√∫ng.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T08:27:21.727978Z",
     "start_time": "2025-07-12T08:27:21.709633Z"
    }
   },
   "source": [
    "# Setup GPU/CPU device\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"üöÄ Device: {device}\")\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    print(f\"üì± GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "    print(f\"üî• CUDA Version: {torch.version.cuda}\")\n",
    "    # Clear any existing GPU cache\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    print(\"üíª Using CPU (GPU not available)\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Device: cuda\n",
      "üì± GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "üíæ GPU Memory: 8.0 GB\n",
      "üî• CUDA Version: 12.1\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T08:27:30.074569Z",
     "start_time": "2025-07-12T08:27:30.047826Z"
    }
   },
   "source": [
    "# Setup ChromaDB\n",
    "os.makedirs(CHROMA_DIR, exist_ok=True)\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(\n",
    "    path=CHROMA_DIR,\n",
    "    settings=Settings(\n",
    "        anonymized_telemetry=False,\n",
    "        allow_reset=True\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ ChromaDB initialized t·∫°i: {CHROMA_DIR}\")\n",
    "print(f\"üìä Existing collections: {len(chroma_client.list_collections())}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ChromaDB initialized t·∫°i: chroma_storage\n",
      "üìä Existing collections: 1\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 2. Indexing - Extract Features v√† L∆∞u v√†o ChromaDB\n",
    "\n",
    "**B∆∞·ªõc n√†y s·∫Ω m·∫•t th·ªùi gian nh∆∞ng ch·ªâ c·∫ßn ch·∫°y m·ªôt l·∫ßn!**\n",
    "\n",
    "N√≥ s·∫Ω extract features cho t·∫•t c·∫£ 23,824 ·∫£nh training v√† l∆∞u v√†o ChromaDB ƒë·ªÉ t√°i s·ª≠ d·ª•ng.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T08:27:36.679847Z",
     "start_time": "2025-07-12T08:27:36.655076Z"
    }
   },
   "source": [
    "def get_collection_name(n_bin, h_type, metric):\n",
    "    \"\"\"Generate collection name for configuration\"\"\"\n",
    "    return f\"{COLLECTION_PREFIX}_{n_bin}bin_{h_type}_{metric}\"\n",
    "\n",
    "def extract_and_store_features(n_bin, h_type, metric, force_reindex=False):\n",
    "    \"\"\"Extract features v√† store v√†o ChromaDB\"\"\"\n",
    "    collection_name = get_collection_name(n_bin, h_type, metric)\n",
    "    \n",
    "    # Ki·ªÉm tra xem collection ƒë√£ t·ªìn t·∫°i ch∆∞a\n",
    "    try:\n",
    "        collection = chroma_client.get_collection(collection_name)\n",
    "        count = collection.count()\n",
    "        if count > 0 and not force_reindex:\n",
    "            print(f\"üìÇ S·ª≠ d·ª•ng collection c√≥ s·∫µn: {collection_name} ({count} vectors)\")\n",
    "            return collection, count\n",
    "    except:\n",
    "        pass  # Collection ch∆∞a t·ªìn t·∫°i\n",
    "    \n",
    "    print(f\"üîß T·∫°o collection m·ªõi: {collection_name}\")\n",
    "    print(f\"   C·∫•u h√¨nh: n_bin={n_bin}, h_type={h_type}, metric={metric}\")\n",
    "    \n",
    "    # X√≥a collection c≈© n·∫øu c√≥\n",
    "    try:\n",
    "        chroma_client.delete_collection(collection_name)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # T·∫°o collection m·ªõi\n",
    "    chroma_metric = \"cosine\" if metric == \"cosine\" else \"l2\"\n",
    "    collection = chroma_client.create_collection(\n",
    "        name=collection_name,\n",
    "        metadata={\"n_bin\": n_bin, \"h_type\": h_type, \"metric\": metric},\n",
    "        embedding_function=None\n",
    "    )\n",
    "    \n",
    "    # Extract features\n",
    "    feature_extractor = RGBHistogram(n_bin=n_bin, h_type=h_type, n_slice=N_SLICE)\n",
    "    \n",
    "    print(\"üìä Extracting features t·ª´ training set...\")\n",
    "    stored_count = 0\n",
    "    train_labels_map = {}\n",
    "    \n",
    "    start_time = time()\n",
    "    \n",
    "    for batch_idx, (images, labels, _) in enumerate(tqdm(train_loader, desc=\"Indexing\")):\n",
    "        # Move to GPU if available\n",
    "        if device.type == \"cuda\":\n",
    "            images = images.to(device)\n",
    "        \n",
    "        # Convert to numpy\n",
    "        images_np = (images.cpu().numpy().transpose(0, 2, 3, 1) * 255).astype(np.uint8)\n",
    "        \n",
    "        # Extract features cho batch\n",
    "        batch_features = []\n",
    "        batch_ids = []\n",
    "        batch_metadatas = []\n",
    "        \n",
    "        for i, (img, label) in enumerate(zip(images_np, labels)):\n",
    "            feature = feature_extractor(img)\n",
    "            \n",
    "            vector_id = f\"train_{stored_count + i}\"\n",
    "            \n",
    "            batch_features.append(feature.tolist())\n",
    "            batch_ids.append(vector_id)\n",
    "            batch_metadatas.append({\n",
    "                \"type\": \"train\",\n",
    "                \"label\": int(label),\n",
    "                \"index\": stored_count + i\n",
    "            })\n",
    "            \n",
    "            train_labels_map[vector_id] = int(label)\n",
    "        \n",
    "        # L∆∞u batch v√†o ChromaDB\n",
    "        if batch_features:\n",
    "            collection.add(\n",
    "                embeddings=batch_features,\n",
    "                ids=batch_ids,\n",
    "                metadatas=batch_metadatas\n",
    "            )\n",
    "        \n",
    "        stored_count += len(batch_features)\n",
    "    \n",
    "    indexing_time = time() - start_time\n",
    "    \n",
    "    # L∆∞u labels mapping\n",
    "    try:\n",
    "        labels_json = json.dumps(train_labels_map)\n",
    "        collection.add(\n",
    "            embeddings=[[0.0] * len(batch_features[0])],\n",
    "            ids=[\"_labels_map_\"],\n",
    "            metadatas=[{\"type\": \"labels_map\"}],\n",
    "            documents=[labels_json]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Kh√¥ng th·ªÉ l∆∞u labels mapping: {e}\")\n",
    "    \n",
    "    print(f\"‚úÖ Ho√†n th√†nh indexing: {stored_count} vectors trong {indexing_time:.2f}s\")\n",
    "    print(f\"‚ö° T·ªëc ƒë·ªô: {stored_count/indexing_time:.1f} vectors/s\")\n",
    "    \n",
    "    return collection, stored_count\n",
    "\n",
    "print(\"üìã H√†m indexing ƒë√£ s·∫µn s√†ng!\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã H√†m indexing ƒë√£ s·∫µn s√†ng!\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T09:04:43.875889Z",
     "start_time": "2025-07-12T08:27:39.704660Z"
    }
   },
   "source": [
    "# CH·∫†Y INDEXING CHO T·∫§T C·∫¢ C·∫§U H√åNH\n",
    "print(f\"üöÄ B·∫Øt ƒë·∫ßu indexing cho {len(CONFIGS)} c·∫•u h√¨nh...\")\n",
    "print(f\"üìä S·∫Ω index {train_size} training samples cho m·ªói c·∫•u h√¨nh\")\n",
    "print(\"‚è≥ Qu√° tr√¨nh n√†y c√≥ th·ªÉ m·∫•t v√†i ph√∫t...\")\n",
    "\n",
    "indexing_results = []\n",
    "\n",
    "for i, (n_bin, h_type, metric) in enumerate(CONFIGS, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Indexing {i}/{len(CONFIGS)}: {n_bin}bin_{h_type}_{metric}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    try:\n",
    "        start_time = time()\n",
    "        collection, count = extract_and_store_features(n_bin, h_type, metric)\n",
    "        end_time = time()\n",
    "        \n",
    "        result = {\n",
    "            'config': f\"{n_bin}bin_{h_type}_{metric}\",\n",
    "            'n_bin': n_bin,\n",
    "            'h_type': h_type,\n",
    "            'metric': metric,\n",
    "            'vectors_count': count,\n",
    "            'indexing_time': end_time - start_time\n",
    "        }\n",
    "        indexing_results.append(result)\n",
    "        \n",
    "        print(f\"‚úÖ Ho√†n th√†nh: {count} vectors\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå L·ªói khi indexing {n_bin}bin_{h_type}_{metric}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(f\"\\nüéâ Ho√†n th√†nh indexing cho t·∫•t c·∫£ {len(indexing_results)} c·∫•u h√¨nh!\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ B·∫Øt ƒë·∫ßu indexing cho 8 c·∫•u h√¨nh...\n",
      "üìä S·∫Ω index 23824 training samples cho m·ªói c·∫•u h√¨nh\n",
      "‚è≥ Qu√° tr√¨nh n√†y c√≥ th·ªÉ m·∫•t v√†i ph√∫t...\n",
      "\n",
      "============================================================\n",
      "Indexing 1/8: 4bin_global_cosine\n",
      "============================================================\n",
      "üìÇ S·ª≠ d·ª•ng collection c√≥ s·∫µn: rgb_hist_4bin_global_cosine (1632 vectors)\n",
      "‚úÖ Ho√†n th√†nh: 1632 vectors\n",
      "\n",
      "============================================================\n",
      "Indexing 2/8: 4bin_global_l2\n",
      "============================================================\n",
      "üîß T·∫°o collection m·ªõi: rgb_hist_4bin_global_l2\n",
      "   C·∫•u h√¨nh: n_bin=4, h_type=global, metric=l2\n",
      "üìä Extracting features t·ª´ training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 745/745 [04:50<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ho√†n th√†nh indexing: 23824 vectors trong 290.03s\n",
      "‚ö° T·ªëc ƒë·ªô: 82.1 vectors/s\n",
      "‚úÖ Ho√†n th√†nh: 23824 vectors\n",
      "\n",
      "============================================================\n",
      "Indexing 3/8: 4bin_region_cosine\n",
      "============================================================\n",
      "üîß T·∫°o collection m·ªõi: rgb_hist_4bin_region_cosine\n",
      "   C·∫•u h√¨nh: n_bin=4, h_type=region, metric=cosine\n",
      "üìä Extracting features t·ª´ training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 745/745 [06:18<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ho√†n th√†nh indexing: 23824 vectors trong 378.93s\n",
      "‚ö° T·ªëc ƒë·ªô: 62.9 vectors/s\n",
      "‚úÖ Ho√†n th√†nh: 23824 vectors\n",
      "\n",
      "============================================================\n",
      "Indexing 4/8: 4bin_region_l2\n",
      "============================================================\n",
      "üîß T·∫°o collection m·ªõi: rgb_hist_4bin_region_l2\n",
      "   C·∫•u h√¨nh: n_bin=4, h_type=region, metric=l2\n",
      "üìä Extracting features t·ª´ training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 745/745 [06:17<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ho√†n th√†nh indexing: 23824 vectors trong 377.54s\n",
      "‚ö° T·ªëc ƒë·ªô: 63.1 vectors/s\n",
      "‚úÖ Ho√†n th√†nh: 23824 vectors\n",
      "\n",
      "============================================================\n",
      "Indexing 5/8: 8bin_global_cosine\n",
      "============================================================\n",
      "üîß T·∫°o collection m·ªõi: rgb_hist_8bin_global_cosine\n",
      "   C·∫•u h√¨nh: n_bin=8, h_type=global, metric=cosine\n",
      "üìä Extracting features t·ª´ training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 745/745 [05:27<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ho√†n th√†nh indexing: 23824 vectors trong 327.30s\n",
      "‚ö° T·ªëc ƒë·ªô: 72.8 vectors/s\n",
      "‚úÖ Ho√†n th√†nh: 23824 vectors\n",
      "\n",
      "============================================================\n",
      "Indexing 6/8: 8bin_global_l2\n",
      "============================================================\n",
      "üîß T·∫°o collection m·ªõi: rgb_hist_8bin_global_l2\n",
      "   C·∫•u h√¨nh: n_bin=8, h_type=global, metric=l2\n",
      "üìä Extracting features t·ª´ training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 745/745 [03:05<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ho√†n th√†nh indexing: 23824 vectors trong 185.58s\n",
      "‚ö° T·ªëc ƒë·ªô: 128.4 vectors/s\n",
      "‚úÖ Ho√†n th√†nh: 23824 vectors\n",
      "\n",
      "============================================================\n",
      "Indexing 7/8: 8bin_region_cosine\n",
      "============================================================\n",
      "üîß T·∫°o collection m·ªõi: rgb_hist_8bin_region_cosine\n",
      "   C·∫•u h√¨nh: n_bin=8, h_type=region, metric=cosine\n",
      "üìä Extracting features t·ª´ training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 745/745 [05:30<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ho√†n th√†nh indexing: 23824 vectors trong 330.44s\n",
      "‚ö° T·ªëc ƒë·ªô: 72.1 vectors/s\n",
      "‚úÖ Ho√†n th√†nh: 23824 vectors\n",
      "\n",
      "============================================================\n",
      "Indexing 8/8: 8bin_region_l2\n",
      "============================================================\n",
      "üîß T·∫°o collection m·ªõi: rgb_hist_8bin_region_l2\n",
      "   C·∫•u h√¨nh: n_bin=8, h_type=region, metric=l2\n",
      "üìä Extracting features t·ª´ training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 745/745 [05:33<00:00,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ho√†n th√†nh indexing: 23824 vectors trong 333.03s\n",
      "‚ö° T·ªëc ƒë·ªô: 71.5 vectors/s\n",
      "‚úÖ Ho√†n th√†nh: 23824 vectors\n",
      "\n",
      "üéâ Ho√†n th√†nh indexing cho t·∫•t c·∫£ 8 c·∫•u h√¨nh!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T09:06:24.654168Z",
     "start_time": "2025-07-12T09:06:24.620241Z"
    }
   },
   "source": [
    "# HI·ªÇN TH·ªä K·∫æT QU·∫¢ INDEXING\n",
    "if indexing_results:\n",
    "    print(\"\\nüìä INDEXING SUMMARY:\")\n",
    "    print(\"-\" * 60)\n",
    "    for result in indexing_results:\n",
    "        print(f\"{result['config']:<20} | {result['vectors_count']:>6} vectors | {result['indexing_time']:>6.1f}s\")\n",
    "    \n",
    "    # L∆∞u k·∫øt qu·∫£\n",
    "    indexing_df = pd.DataFrame(indexing_results)\n",
    "    indexing_df.to_csv('out/indexing_results.csv', index=False)\n",
    "    print(f\"\\nüíæ K·∫øt qu·∫£ indexing l∆∞u t·∫°i: out/indexing_results.csv\")\n",
    "    \n",
    "    print(f\"\\nüìä T·ªïng k·∫øt:\")\n",
    "    print(f\"   - T·ªïng collections: {len(chroma_client.list_collections())}\")\n",
    "    print(f\"   - T·ªïng vectors: {sum(r['vectors_count'] for r in indexing_results):,}\")\n",
    "    print(f\"   - T·ªïng th·ªùi gian: {sum(r['indexing_time'] for r in indexing_results):.1f}s\")\n",
    "else:\n",
    "    print(\"Kh√¥ng c√≥ k·∫øt qu·∫£ indexing n√†o!\")\n",
    "\n",
    "# GPU memory cleanup after indexing\n",
    "if device.type == \"cuda\":\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"üßπ GPU memory cleaned up after indexing\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä INDEXING SUMMARY:\n",
      "------------------------------------------------------------\n",
      "4bin_global_cosine   |   1632 vectors |    0.0s\n",
      "4bin_global_l2       |  23824 vectors |  290.1s\n",
      "4bin_region_cosine   |  23824 vectors |  379.1s\n",
      "4bin_region_l2       |  23824 vectors |  378.0s\n",
      "8bin_global_cosine   |  23824 vectors |  327.4s\n",
      "8bin_global_l2       |  23824 vectors |  185.7s\n",
      "8bin_region_cosine   |  23824 vectors |  330.6s\n",
      "8bin_region_l2       |  23824 vectors |  333.2s\n",
      "\n",
      "üíæ K·∫øt qu·∫£ indexing l∆∞u t·∫°i: out/indexing_results.csv\n",
      "\n",
      "üìä T·ªïng k·∫øt:\n",
      "   - T·ªïng collections: 8\n",
      "   - T·ªïng vectors: 168,400\n",
      "   - T·ªïng th·ªùi gian: 2224.2s\n",
      "üßπ GPU memory cleaned up after indexing\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 3. Evaluation - Ch·∫°y ƒê√°nh Gi√° tr√™n Data ƒê√£ C√≥\n",
    "\n",
    "**B∆∞·ªõc n√†y s·∫Ω nhanh h∆°n nhi·ªÅu v√¨ ƒë√£ c√≥ features trong ChromaDB!**\n",
    "\n",
    "S·∫Ω test tr√™n 1000 samples t·ª´ test set v√† t√≠nh mAP@1, mAP@5, mAP@10.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T09:06:35.707019Z",
     "start_time": "2025-07-12T09:06:35.688808Z"
    }
   },
   "source": [
    "def get_train_labels(collection):\n",
    "    \"\"\"L·∫•y labels mapping t·ª´ collection\"\"\"\n",
    "    try:\n",
    "        # Th·ª≠ l·∫•y t·ª´ labels map\n",
    "        result = collection.get(ids=[\"_labels_map_\"])\n",
    "        if result['documents'] and len(result['documents']) > 0:\n",
    "            return json.loads(result['documents'][0])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Fallback: l·∫•y t·ª´ metadata\n",
    "    all_data = collection.get(where={\"type\": \"train\"})\n",
    "    labels_map = {}\n",
    "    for id, metadata in zip(all_data['ids'], all_data['metadatas']):\n",
    "        if 'label' in metadata:\n",
    "            labels_map[id] = metadata['label']\n",
    "    \n",
    "    return labels_map\n",
    "\n",
    "def evaluate_configuration(n_bin, h_type, metric):\n",
    "    \"\"\"Evaluate m·ªôt c·∫•u h√¨nh\"\"\"\n",
    "    collection_name = get_collection_name(n_bin, h_type, metric)\n",
    "    \n",
    "    try:\n",
    "        collection = chroma_client.get_collection(collection_name)\n",
    "        train_labels_map = get_train_labels(collection)\n",
    "        \n",
    "        print(f\"üìä Found {len(train_labels_map)} training vectors\")\n",
    "        \n",
    "        if len(train_labels_map) == 0:\n",
    "            print(\"‚ùå Kh√¥ng c√≥ training data! Vui l√≤ng ch·∫°y indexing tr∆∞·ªõc.\")\n",
    "            return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Kh√¥ng t√¨m th·∫•y collection {collection_name}: {e}\")\n",
    "        print(\"Vui l√≤ng ch·∫°y indexing tr∆∞·ªõc!\")\n",
    "        return None\n",
    "    \n",
    "    # Extract test features v√† evaluate\n",
    "    feature_extractor = RGBHistogram(n_bin=n_bin, h_type=h_type, n_slice=N_SLICE)\n",
    "    \n",
    "    all_results = []\n",
    "    test_labels = []\n",
    "    tested_count = 0\n",
    "    \n",
    "    start_time = time()\n",
    "    \n",
    "    for images, labels, _ in tqdm(test_loader, desc=\"Testing\"):\n",
    "        if tested_count >= TEST_SIZE:\n",
    "            break\n",
    "        \n",
    "        count = min(len(images), TEST_SIZE - tested_count)\n",
    "        batch_images = images[:count]\n",
    "        batch_labels = labels[:count]\n",
    "        \n",
    "        # Move to GPU if available\n",
    "        if device.type == \"cuda\":\n",
    "            batch_images = batch_images.to(device)\n",
    "        \n",
    "        # Convert to numpy\n",
    "        images_np = (batch_images.cpu().numpy().transpose(0, 2, 3, 1) * 255).astype(np.uint8)\n",
    "        \n",
    "        for img, label in zip(images_np, batch_labels):\n",
    "            if tested_count >= TEST_SIZE:\n",
    "                break\n",
    "            \n",
    "            # Extract test feature\n",
    "            test_feature = feature_extractor(img)\n",
    "            \n",
    "            # Query ChromaDB\n",
    "            results = collection.query(\n",
    "                query_embeddings=[test_feature.tolist()],\n",
    "                n_results=max(K_VALUES),\n",
    "                where={\"type\": \"train\"}\n",
    "            )\n",
    "            \n",
    "            # L·∫•y labels c·ªßa k·∫øt qu·∫£\n",
    "            if results['ids'] and len(results['ids'][0]) > 0:\n",
    "                retrieved_ids = results['ids'][0]\n",
    "                retrieved_labels = [train_labels_map.get(id, -1) for id in retrieved_ids]\n",
    "                all_results.append(retrieved_labels)\n",
    "            else:\n",
    "                all_results.append([])\n",
    "            \n",
    "            test_labels.append(int(label))\n",
    "            tested_count += 1\n",
    "    \n",
    "    retrieval_time = time() - start_time\n",
    "    \n",
    "    # T√≠nh metrics\n",
    "    metrics_data = {}\n",
    "    \n",
    "    for k in K_VALUES:\n",
    "        map_scores = []\n",
    "        recall_scores = []\n",
    "        hit_scores = []\n",
    "        \n",
    "        for retrieved_labels, gt_label in zip(all_results, test_labels):\n",
    "            if len(retrieved_labels) == 0:\n",
    "                map_scores.append(0.0)\n",
    "                recall_scores.append(0.0)\n",
    "                hit_scores.append(0.0)\n",
    "                continue\n",
    "            \n",
    "            # Top-k results\n",
    "            top_k_labels = retrieved_labels[:k]\n",
    "            \n",
    "            # T√≠nh metrics\n",
    "            ap = average_precision(top_k_labels, [gt_label], k)\n",
    "            relevant_indices = [i for i, label in enumerate(train_labels_map.values()) if label == gt_label]\n",
    "            rec = recall(list(range(len(top_k_labels))), relevant_indices, k)\n",
    "            hr = hit_rate(top_k_labels, [gt_label], k)\n",
    "            \n",
    "            map_scores.append(ap)\n",
    "            recall_scores.append(rec)\n",
    "            hit_scores.append(hr)\n",
    "        \n",
    "        # L∆∞u metrics\n",
    "        metrics_data[f'mAP@{k}'] = np.mean(map_scores)\n",
    "        metrics_data[f'Recall@{k}'] = np.mean(recall_scores)\n",
    "        metrics_data[f'HitRate@{k}'] = np.mean(hit_scores)\n",
    "        \n",
    "        print(f\"   k={k}: mAP={np.mean(map_scores):.4f}, Recall={np.mean(recall_scores):.4f}, HR={np.mean(hit_scores):.4f}\")\n",
    "    \n",
    "    # T√≠nh average mAP\n",
    "    avg_map = np.mean([metrics_data[f'mAP@{k}'] for k in K_VALUES])\n",
    "    metrics_data['avg_mAP'] = avg_map\n",
    "    \n",
    "    # Th√™m th√¥ng tin c·∫•u h√¨nh\n",
    "    metrics_data.update({\n",
    "        'n_bin': n_bin,\n",
    "        'h_type': h_type,\n",
    "        'metric': metric,\n",
    "        'config_name': f\"{n_bin}bin_{h_type}_{metric}\",\n",
    "        'retrieval_time': retrieval_time,\n",
    "        'tested_samples': tested_count,\n",
    "        'train_samples': len(train_labels_map)\n",
    "    })\n",
    "    \n",
    "    return metrics_data\n",
    "\n",
    "print(\"üìã H√†m evaluation ƒë√£ s·∫µn s√†ng!\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã H√†m evaluation ƒë√£ s·∫µn s√†ng!\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T11:19:36.897828Z",
     "start_time": "2025-07-12T09:06:42.253565Z"
    }
   },
   "source": [
    "# CH·∫†Y EVALUATION CHO T·∫§T C·∫¢ C·∫§U H√åNH\n",
    "print(f\"üöÄ B·∫Øt ƒë·∫ßu evaluation cho {len(CONFIGS)} c·∫•u h√¨nh...\")\n",
    "print(f\"üìä S·∫Ω test tr√™n {TEST_SIZE} samples\")\n",
    "print(f\"üéØ Metrics: mAP@{K_VALUES}\")\n",
    "\n",
    "evaluation_results = []\n",
    "\n",
    "for i, (n_bin, h_type, metric) in enumerate(CONFIGS, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Evaluation {i}/{len(CONFIGS)}: {n_bin}bin_{h_type}_{metric}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    try:\n",
    "        result = evaluate_configuration(n_bin, h_type, metric)\n",
    "        if result:\n",
    "            evaluation_results.append(result)\n",
    "            print(f\"‚úÖ Ho√†n th√†nh: avg_mAP = {result['avg_mAP']:.4f}\")\n",
    "        else:\n",
    "            print(f\"‚ùå Th·∫•t b·∫°i: {n_bin}bin_{h_type}_{metric}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå L·ªói khi evaluate {n_bin}bin_{h_type}_{metric}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(f\"\\nüéâ Ho√†n th√†nh evaluation cho {len(evaluation_results)} c·∫•u h√¨nh!\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ B·∫Øt ƒë·∫ßu evaluation cho 8 c·∫•u h√¨nh...\n",
      "üìä S·∫Ω test tr√™n 5956 samples\n",
      "üéØ Metrics: mAP@[1, 5, 10]\n",
      "\n",
      "============================================================\n",
      "Evaluation 1/8: 4bin_global_cosine\n",
      "============================================================\n",
      "üìä Found 1632 training vectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 187/187 [13:02<00:00,  4.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   k=1: mAP=0.0155, Recall=0.0004, HR=0.0311\n",
      "   k=5: mAP=0.0276, Recall=0.0034, HR=0.0229\n",
      "   k=10: mAP=0.0306, Recall=0.0063, HR=0.0199\n",
      "‚úÖ Ho√†n th√†nh: avg_mAP = 0.0246\n",
      "\n",
      "============================================================\n",
      "Evaluation 2/8: 4bin_global_l2\n",
      "============================================================\n",
      "üìä Found 23824 training vectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 187/187 [16:06<00:00,  5.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   k=1: mAP=0.0314, Recall=0.0000, HR=0.0628\n",
      "   k=5: mAP=0.0492, Recall=0.0002, HR=0.0417\n",
      "   k=10: mAP=0.0536, Recall=0.0004, HR=0.0362\n",
      "‚úÖ Ho√†n th√†nh: avg_mAP = 0.0447\n",
      "\n",
      "============================================================\n",
      "Evaluation 3/8: 4bin_region_cosine\n",
      "============================================================\n",
      "üìä Found 23824 training vectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 187/187 [18:07<00:00,  5.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   k=1: mAP=0.0468, Recall=0.0000, HR=0.0937\n",
      "   k=5: mAP=0.0751, Recall=0.0002, HR=0.0698\n",
      "   k=10: mAP=0.0799, Recall=0.0004, HR=0.0600\n",
      "‚úÖ Ho√†n th√†nh: avg_mAP = 0.0673\n",
      "\n",
      "============================================================\n",
      "Evaluation 4/8: 4bin_region_l2\n",
      "============================================================\n",
      "üìä Found 23824 training vectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 187/187 [16:13<00:00,  5.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   k=1: mAP=0.0464, Recall=0.0000, HR=0.0928\n",
      "   k=5: mAP=0.0734, Recall=0.0002, HR=0.0680\n",
      "   k=10: mAP=0.0789, Recall=0.0004, HR=0.0600\n",
      "‚úÖ Ho√†n th√†nh: avg_mAP = 0.0662\n",
      "\n",
      "============================================================\n",
      "Evaluation 5/8: 8bin_global_cosine\n",
      "============================================================\n",
      "üìä Found 23824 training vectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 187/187 [16:11<00:00,  5.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   k=1: mAP=0.0339, Recall=0.0000, HR=0.0678\n",
      "   k=5: mAP=0.0539, Recall=0.0002, HR=0.0476\n",
      "   k=10: mAP=0.0583, Recall=0.0004, HR=0.0409\n",
      "‚úÖ Ho√†n th√†nh: avg_mAP = 0.0487\n",
      "\n",
      "============================================================\n",
      "Evaluation 6/8: 8bin_global_l2\n",
      "============================================================\n",
      "üìä Found 23824 training vectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 187/187 [20:02<00:00,  6.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   k=1: mAP=0.0343, Recall=0.0000, HR=0.0687\n",
      "   k=5: mAP=0.0544, Recall=0.0002, HR=0.0478\n",
      "   k=10: mAP=0.0587, Recall=0.0004, HR=0.0408\n",
      "‚úÖ Ho√†n th√†nh: avg_mAP = 0.0491\n",
      "\n",
      "============================================================\n",
      "Evaluation 7/8: 8bin_region_cosine\n",
      "============================================================\n",
      "üìä Found 23824 training vectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 187/187 [15:41<00:00,  5.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   k=1: mAP=0.0410, Recall=0.0000, HR=0.0819\n",
      "   k=5: mAP=0.0662, Recall=0.0002, HR=0.0631\n",
      "   k=10: mAP=0.0711, Recall=0.0004, HR=0.0562\n",
      "‚úÖ Ho√†n th√†nh: avg_mAP = 0.0594\n",
      "\n",
      "============================================================\n",
      "Evaluation 8/8: 8bin_region_l2\n",
      "============================================================\n",
      "üìä Found 23824 training vectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 187/187 [15:41<00:00,  5.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   k=1: mAP=0.0427, Recall=0.0000, HR=0.0855\n",
      "   k=5: mAP=0.0682, Recall=0.0002, HR=0.0645\n",
      "   k=10: mAP=0.0727, Recall=0.0004, HR=0.0566\n",
      "‚úÖ Ho√†n th√†nh: avg_mAP = 0.0612\n",
      "\n",
      "üéâ Ho√†n th√†nh evaluation cho 8 c·∫•u h√¨nh!\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T11:21:33.123479Z",
     "start_time": "2025-07-12T11:21:33.096123Z"
    }
   },
   "source": [
    "# PH√ÇN T√çCH K·∫æT QU·∫¢\n",
    "if evaluation_results:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"üìä K·∫æT QU·∫¢ ƒê√ÅNH GI√Å TO√ÄN B·ªò - DATASET 80/20\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # S·∫Øp x·∫øp theo avg_mAP\n",
    "    sorted_results = sorted(evaluation_results, key=lambda x: x['avg_mAP'], reverse=True)\n",
    "    \n",
    "    # Hi·ªÉn th·ªã ranking\n",
    "    print(f\"\\nüèÜ X·∫æP H·∫†NG THEO AVERAGE mAP\")\n",
    "    print(\"-\" * 85)\n",
    "    print(f\"{'Rank':<4} {'Configuration':<20} {'Avg mAP':<10} {'mAP@1':<8} {'mAP@5':<8} {'mAP@10':<8} {'Time(s)':<8}\")\n",
    "    print(\"-\" * 85)\n",
    "    \n",
    "    for i, result in enumerate(sorted_results, 1):\n",
    "        print(f\"{i:<4} {result['config_name']:<20} {result['avg_mAP']:<10.4f} \"\n",
    "              f\"{result['mAP@1']:<8.4f} {result['mAP@5']:<8.4f} {result['mAP@10']:<8.4f} \"\n",
    "              f\"{result['retrieval_time']:<8.1f}\")\n",
    "    \n",
    "    # C·∫•u h√¨nh t·ªët nh·∫•t\n",
    "    best = sorted_results[0]\n",
    "    print(f\"\\nü•á C·∫§U H√åNH T·ªêT NH·∫§T: {best['config_name']}\")\n",
    "    print(f\"   Average mAP: {best['avg_mAP']:.4f}\")\n",
    "    print(f\"   Training samples: {best['train_samples']}\")\n",
    "    print(f\"   Test samples: {best['tested_samples']}\")\n",
    "    print(f\"   Retrieval time: {best['retrieval_time']:.2f}s\")\n",
    "    for k in K_VALUES:\n",
    "        print(f\"   mAP@{k}: {best[f'mAP@{k}']:.4f}\")\n",
    "    \n",
    "    # L∆∞u k·∫øt qu·∫£\n",
    "    df = pd.DataFrame(sorted_results)\n",
    "    csv_path = 'out/evaluation_results_chromadb.csv'\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"\\nüíæ K·∫øt qu·∫£ chi ti·∫øt l∆∞u t·∫°i: {csv_path}\")\n",
    "    \n",
    "    # L∆∞u c·∫•u h√¨nh t·ªët nh·∫•t\n",
    "    best_config = {\n",
    "        'config_name': best['config_name'],\n",
    "        'n_bin': best['n_bin'],\n",
    "        'h_type': best['h_type'],\n",
    "        'metric': best['metric'],\n",
    "        'avg_mAP': best['avg_mAP'],\n",
    "        'train_samples': best['train_samples'],\n",
    "        'test_samples': best['tested_samples'],\n",
    "        **{f'mAP@{k}': best[f'mAP@{k}'] for k in K_VALUES}\n",
    "    }\n",
    "    \n",
    "    with open('out/best_config_chromadb.json', 'w') as f:\n",
    "        json.dump(best_config, f, indent=2)\n",
    "    print(\"üìã C·∫•u h√¨nh t·ªët nh·∫•t l∆∞u t·∫°i: out/best_config_chromadb.json\")\n",
    "    \n",
    "    # Top 3 summary\n",
    "    print(f\"\\nüèÖ TOP 3 C·∫§U H√åNH:\")\n",
    "    emojis = [\"ü•á\", \"ü•à\", \"ü•â\"]\n",
    "    for i, result in enumerate(sorted_results[:3]):\n",
    "        emoji = emojis[i] if i < len(emojis) else \"üèÖ\"\n",
    "        print(f\"{emoji} {result['config_name']}: avg_mAP={result['avg_mAP']:.4f} \"\n",
    "              f\"(n_bin={result['n_bin']}, h_type={result['h_type']}, metric={result['metric']})\")\n",
    "    \n",
    "    print(f\"\\nüíæ ChromaDB Storage: {CHROMA_DIR}\")\n",
    "    print(\"üîç Vector collections ƒë∆∞·ª£c l∆∞u tr·ªØ ƒë·ªÉ t√°i s·ª≠ d·ª•ng\")\n",
    "    print(\"‚ôªÔ∏è  L·∫ßn ch·∫°y ti·∫øp theo s·∫Ω nhanh h∆°n nh·ªù cache\")\n",
    "    print(\"\\nüéâ Ho√†n th√†nh to√†n b·ªô qu√° tr√¨nh evaluation!\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Kh√¥ng c√≥ k·∫øt qu·∫£ evaluation n√†o!\")\n",
    "    print(\"Vui l√≤ng ƒë·∫£m b·∫£o ƒë√£ ch·∫°y indexing th√†nh c√¥ng tr∆∞·ªõc.\")\n",
    "\n",
    "# GPU memory cleanup\n",
    "if device.type == \"cuda\":\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"üßπ GPU memory cleaned up\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üìä K·∫æT QU·∫¢ ƒê√ÅNH GI√Å TO√ÄN B·ªò - DATASET 80/20\n",
      "================================================================================\n",
      "\n",
      "üèÜ X·∫æP H·∫†NG THEO AVERAGE mAP\n",
      "-------------------------------------------------------------------------------------\n",
      "Rank Configuration        Avg mAP    mAP@1    mAP@5    mAP@10   Time(s) \n",
      "-------------------------------------------------------------------------------------\n",
      "1    4bin_region_cosine   0.0673     0.0468   0.0751   0.0799   1087.6  \n",
      "2    4bin_region_l2       0.0662     0.0464   0.0734   0.0789   973.1   \n",
      "3    8bin_region_l2       0.0612     0.0427   0.0682   0.0727   941.8   \n",
      "4    8bin_region_cosine   0.0594     0.0410   0.0662   0.0711   941.9   \n",
      "5    8bin_global_l2       0.0491     0.0343   0.0544   0.0587   1202.2  \n",
      "6    8bin_global_cosine   0.0487     0.0339   0.0539   0.0583   971.9   \n",
      "7    4bin_global_l2       0.0447     0.0314   0.0492   0.0536   966.5   \n",
      "8    4bin_global_cosine   0.0246     0.0155   0.0276   0.0306   782.3   \n",
      "\n",
      "ü•á C·∫§U H√åNH T·ªêT NH·∫§T: 4bin_region_cosine\n",
      "   Average mAP: 0.0673\n",
      "   Training samples: 23824\n",
      "   Test samples: 5956\n",
      "   Retrieval time: 1087.57s\n",
      "   mAP@1: 0.0468\n",
      "   mAP@5: 0.0751\n",
      "   mAP@10: 0.0799\n",
      "\n",
      "üíæ K·∫øt qu·∫£ chi ti·∫øt l∆∞u t·∫°i: out/evaluation_results_chromadb.csv\n",
      "üìã C·∫•u h√¨nh t·ªët nh·∫•t l∆∞u t·∫°i: out/best_config_chromadb.json\n",
      "\n",
      "üèÖ TOP 3 C·∫§U H√åNH:\n",
      "ü•á 4bin_region_cosine: avg_mAP=0.0673 (n_bin=4, h_type=region, metric=cosine)\n",
      "ü•à 4bin_region_l2: avg_mAP=0.0662 (n_bin=4, h_type=region, metric=l2)\n",
      "ü•â 8bin_region_l2: avg_mAP=0.0612 (n_bin=8, h_type=region, metric=l2)\n",
      "\n",
      "üíæ ChromaDB Storage: chroma_storage\n",
      "üîç Vector collections ƒë∆∞·ª£c l∆∞u tr·ªØ ƒë·ªÉ t√°i s·ª≠ d·ª•ng\n",
      "‚ôªÔ∏è  L·∫ßn ch·∫°y ti·∫øp theo s·∫Ω nhanh h∆°n nh·ªù cache\n",
      "\n",
      "üéâ Ho√†n th√†nh to√†n b·ªô qu√° tr√¨nh evaluation!\n",
      "üßπ GPU memory cleaned up\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## H∆∞·ªõng D·∫´n S·ª≠ D·ª•ng\n",
    "\n",
    "### üìã Quy Tr√¨nh S·ª≠ D·ª•ng:\n",
    "\n",
    "1. **Ch·∫°y Cell 1-5**: Setup v√† c·∫•u h√¨nh\n",
    "2. **Ch·∫°y Cell 6-9**: Indexing (m·∫•t th·ªùi gian, ch·ªâ c·∫ßn ch·∫°y 1 l·∫ßn)\n",
    "3. **Ch·∫°y Cell 10-13**: Evaluation (nhanh, c√≥ th·ªÉ ch·∫°y nhi·ªÅu l·∫ßn)\n",
    "\n",
    "### üéØ K·∫øt Qu·∫£ Mong ƒê·ª£i:\n",
    "\n",
    "- **Dataset**: 80% training (23,824 samples) / 20% testing (5,956 samples)\n",
    "- **Configurations**: 8 t·ªï h·ª£p (n_bin √ó h_type √ó metric)\n",
    "- **Metrics**: mAP@1, mAP@5, mAP@10, Recall, Hit Rate\n",
    "- **Storage**: ChromaDB v·ªõi ~200MB (thay v√¨ >1GB pkl files)\n",
    "- **GPU Support**: T·ª± ƒë·ªông detect v√† s·ª≠ d·ª•ng GPU n·∫øu c√≥ s·∫µn\n",
    "\n",
    "### üíæ Output Files:\n",
    "\n",
    "- `out/indexing_results.csv`: K·∫øt qu·∫£ indexing\n",
    "- `out/evaluation_results_chromadb.csv`: K·∫øt qu·∫£ evaluation chi ti·∫øt\n",
    "- `out/best_config_chromadb.json`: C·∫•u h√¨nh t·ªët nh·∫•t\n",
    "- `chroma_storage/`: Vector database storage\n",
    "\n",
    "### üîÑ L·∫ßn Ch·∫°y Ti·∫øp Theo:\n",
    "\n",
    "Khi ch·∫°y l·∫°i, indexing s·∫Ω **t·ª± ƒë·ªông s·ª≠ d·ª•ng cache** t·ª´ ChromaDB, ch·ªâ c·∫ßn ch·∫°y evaluation!\n",
    "\n",
    "### ‚ö° Performance Notes:\n",
    "\n",
    "- **GPU**: T·ª± ƒë·ªông s·ª≠ d·ª•ng CUDA n·∫øu c√≥, tƒÉng t·ªëc ~3-5x\n",
    "- **Memory**: T·ª± ƒë·ªông cleanup GPU memory sau m·ªói b∆∞·ªõc\n",
    "- **Caching**: ChromaDB l∆∞u tr·ªØ persistent, kh√¥ng c·∫ßn recompute features\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
