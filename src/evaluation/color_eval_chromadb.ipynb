{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T03:09:37.264158Z",
     "start_time": "2025-07-13T03:09:32.106781Z"
    }
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "from src.datasets.caltech256 import Caltech256DataModule\n",
    "from src.featuring.rgb_histogram import RGBHistogram\n",
    "from src.metrics import average_precision\n",
    "\n",
    "# Tạo thư mục output\n",
    "os.makedirs('out', exist_ok=True)\n",
    "\n",
    "print(\"✅ Imports hoàn tất!\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Imports hoàn tất!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T03:09:39.519817Z",
     "start_time": "2025-07-13T03:09:39.502415Z"
    }
   },
   "source": [
    "# ======================== CONFIGURATIONS ========================\n",
    "CONFIGS = [\n",
    "    # (n_bin, h_type, metric)\n",
    "    (4, 'global', 'cosine'),\n",
    "    (4, 'global', 'l2'),\n",
    "    (4, 'region', 'cosine'), \n",
    "    (4, 'region', 'l2'),\n",
    "    (8, 'global', 'cosine'),\n",
    "    (8, 'global', 'l2'),\n",
    "    (8, 'region', 'cosine'),\n",
    "    (8, 'region', 'l2'),\n",
    "]\n",
    "\n",
    "# Cấu hình evaluation\n",
    "TEST_SIZE = 5956     # Số lượng test samples để evaluation\n",
    "N_SLICE = 3          # Số slice cho region histogram\n",
    "MAP_K_VALUES = [1, 5, 10]  # Top-k cho mAP evaluation\n",
    "RECALL_K_VALUES = [10, 100, 1000]  # Top-k cho Recall evaluation\n",
    "\n",
    "# ChromaDB settings\n",
    "CHROMA_DIR = \"chroma_storage\"\n",
    "COLLECTION_PREFIX = \"rgb_hist\"\n",
    "\n",
    "print(f\"📋 Tổng cấu hình để test: {len(CONFIGS)}\")\n",
    "print(f\"📊 Test size: {TEST_SIZE}\")\n",
    "print(f\"💾 ChromaDB storage: {CHROMA_DIR}\")\n",
    "print(f\"🎯 mAP k-values: {MAP_K_VALUES}\")\n",
    "print(f\"🎯 Recall k-values: {RECALL_K_VALUES}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 Tổng cấu hình để test: 8\n",
      "📊 Test size: 5956\n",
      "💾 ChromaDB storage: chroma_storage\n",
      "🎯 mAP k-values: [1, 5, 10]\n",
      "🎯 Recall k-values: [10, 100, 1000]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T03:09:42.933827Z",
     "start_time": "2025-07-13T03:09:42.297576Z"
    }
   },
   "source": [
    "# Setup dataset\n",
    "dataset_root = os.path.abspath('data/caltech-256/256_ObjectCategories')\n",
    "print(f\"📂 Dataset path: {dataset_root}\")\n",
    "print(f\"📂 Exists: {os.path.exists(dataset_root)}\")\n",
    "\n",
    "if os.path.exists(dataset_root):\n",
    "    data_module = Caltech256DataModule(batch_size=32, root=dataset_root)\n",
    "    data_module.setup()\n",
    "    train_loader = data_module.train_dataloader()\n",
    "    test_loader = data_module.test_dataloader()\n",
    "    \n",
    "    train_size = len(train_loader.dataset)\n",
    "    test_size = len(test_loader.dataset)\n",
    "    total_size = train_size + test_size\n",
    "    \n",
    "    print(f\"✅ Dataset loaded thành công!\")\n",
    "    print(f\"📊 Training: {train_size} samples ({train_size/total_size*100:.1f}%)\")\n",
    "    print(f\"📊 Testing: {test_size} samples ({test_size/total_size*100:.1f}%)\")\n",
    "    print(f\"📊 Total: {total_size} samples\")\n",
    "else:\n",
    "    print(\"❌ Dataset không tìm thấy!\")\n",
    "    print(\"Vui lòng đảm bảo dataset ở đường dẫn đúng.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Dataset path: D:\\AI\\Food-CBIR\\src\\evaluation\\data\\caltech-256\\256_ObjectCategories\n",
      "📂 Exists: True\n",
      "📂 Found 256 valid categories\n",
      "📊 Loaded 29780 total images from 256 classes\n",
      "📋 Train: 23824 images\n",
      "📂 Found 256 valid categories\n",
      "📊 Loaded 29780 total images from 256 classes\n",
      "📋 Test: 5956 images\n",
      "Train: 23824, Test: 5956\n",
      "✅ Dataset loaded thành công!\n",
      "📊 Training: 23824 samples (80.0%)\n",
      "📊 Testing: 5956 samples (20.0%)\n",
      "📊 Total: 29780 samples\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T03:09:44.628304Z",
     "start_time": "2025-07-13T03:09:44.508238Z"
    }
   },
   "source": [
    "# Setup GPU/CPU device\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"🚀 Device: {device}\")\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    print(f\"📱 GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"💾 GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "    print(f\"🔥 CUDA Version: {torch.version.cuda}\")\n",
    "    # Clear any existing GPU cache\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    print(\"💻 Using CPU (GPU not available)\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Device: cuda\n",
      "📱 GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "💾 GPU Memory: 8.0 GB\n",
      "🔥 CUDA Version: 12.1\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T03:09:46.626896Z",
     "start_time": "2025-07-13T03:09:46.472264Z"
    }
   },
   "source": [
    "# Setup ChromaDB\n",
    "os.makedirs(CHROMA_DIR, exist_ok=True)\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(\n",
    "    path=CHROMA_DIR,\n",
    "    settings=Settings(\n",
    "        anonymized_telemetry=False,\n",
    "        allow_reset=True\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"✅ ChromaDB initialized tại: {CHROMA_DIR}\")\n",
    "print(f\"📊 Existing collections: {len(chroma_client.list_collections())}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ChromaDB initialized tại: chroma_storage\n",
      "📊 Existing collections: 8\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T03:09:48.997980Z",
     "start_time": "2025-07-13T03:09:48.973239Z"
    }
   },
   "source": [
    "def get_collection_name(n_bin, h_type, metric):\n",
    "    \"\"\"Generate collection name for configuration\"\"\"\n",
    "    return f\"{COLLECTION_PREFIX}_{n_bin}bin_{h_type}_{metric}\"\n",
    "\n",
    "def extract_and_store_features(n_bin, h_type, metric, force_reindex=False):\n",
    "    \"\"\"Extract features và store vào ChromaDB\"\"\"\n",
    "    collection_name = get_collection_name(n_bin, h_type, metric)\n",
    "    \n",
    "    # Kiểm tra xem collection đã tồn tại chưa\n",
    "    try:\n",
    "        collection = chroma_client.get_collection(collection_name)\n",
    "        count = collection.count()\n",
    "        if count > 0 and not force_reindex:\n",
    "            print(f\"📂 Sử dụng collection có sẵn: {collection_name} ({count} vectors)\")\n",
    "            return collection, count\n",
    "    except:\n",
    "        pass  # Collection chưa tồn tại\n",
    "    \n",
    "    print(f\"🔧 Tạo collection mới: {collection_name}\")\n",
    "    print(f\"   Cấu hình: n_bin={n_bin}, h_type={h_type}, metric={metric}\")\n",
    "    \n",
    "    # Xóa collection cũ nếu có\n",
    "    try:\n",
    "        chroma_client.delete_collection(collection_name)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Tạo collection mới\n",
    "    chroma_metric = \"cosine\" if metric == \"cosine\" else \"l2\"\n",
    "    collection = chroma_client.create_collection(\n",
    "        name=collection_name,\n",
    "        metadata={\"n_bin\": n_bin, \"h_type\": h_type, \"metric\": metric},\n",
    "        embedding_function=None\n",
    "    )\n",
    "    \n",
    "    # Extract features\n",
    "    feature_extractor = RGBHistogram(n_bin=n_bin, h_type=h_type, n_slice=N_SLICE)\n",
    "    \n",
    "    print(\"📊 Extracting features từ training set...\")\n",
    "    stored_count = 0\n",
    "    train_labels_map = {}\n",
    "    \n",
    "    start_time = time()\n",
    "    \n",
    "    for batch_idx, (images, labels, _) in enumerate(tqdm(train_loader, desc=\"Indexing\")):\n",
    "        # Move to GPU if available\n",
    "        if device.type == \"cuda\":\n",
    "            images = images.to(device)\n",
    "        \n",
    "        # Convert to numpy\n",
    "        images_np = (images.cpu().numpy().transpose(0, 2, 3, 1) * 255).astype(np.uint8)\n",
    "        \n",
    "        # Extract features cho batch\n",
    "        batch_features = []\n",
    "        batch_ids = []\n",
    "        batch_metadatas = []\n",
    "        \n",
    "        for i, (img, label) in enumerate(zip(images_np, labels)):\n",
    "            feature = feature_extractor(img)\n",
    "            \n",
    "            vector_id = f\"train_{stored_count + i}\"\n",
    "            \n",
    "            batch_features.append(feature.tolist())\n",
    "            batch_ids.append(vector_id)\n",
    "            batch_metadatas.append({\n",
    "                \"type\": \"train\",\n",
    "                \"label\": int(label),\n",
    "                \"index\": stored_count + i\n",
    "            })\n",
    "            \n",
    "            train_labels_map[vector_id] = int(label)\n",
    "        \n",
    "        # Lưu batch vào ChromaDB\n",
    "        if batch_features:\n",
    "            collection.add(\n",
    "                embeddings=batch_features,\n",
    "                ids=batch_ids,\n",
    "                metadatas=batch_metadatas\n",
    "            )\n",
    "        \n",
    "        stored_count += len(batch_features)\n",
    "    \n",
    "    indexing_time = time() - start_time\n",
    "    \n",
    "    # Lưu labels mapping\n",
    "    try:\n",
    "        labels_json = json.dumps(train_labels_map)\n",
    "        collection.add(\n",
    "            embeddings=[[0.0] * len(batch_features[0])],\n",
    "            ids=[\"_labels_map_\"],\n",
    "            metadatas=[{\"type\": \"labels_map\"}],\n",
    "            documents=[labels_json]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️  Không thể lưu labels mapping: {e}\")\n",
    "    \n",
    "    print(f\"✅ Hoàn thành indexing: {stored_count} vectors trong {indexing_time:.2f}s\")\n",
    "    print(f\"⚡ Tốc độ: {stored_count/indexing_time:.1f} vectors/s\")\n",
    "    \n",
    "    return collection, stored_count\n",
    "\n",
    "print(\"📋 Hàm indexing đã sẵn sàng!\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 Hàm indexing đã sẵn sàng!\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T09:04:43.875889Z",
     "start_time": "2025-07-12T08:27:39.704660Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Bắt đầu indexing cho 8 cấu hình...\n",
      "📊 Sẽ index 23824 training samples cho mỗi cấu hình\n",
      "⏳ Quá trình này có thể mất vài phút...\n",
      "\n",
      "============================================================\n",
      "Indexing 1/8: 4bin_global_cosine\n",
      "============================================================\n",
      "📂 Sử dụng collection có sẵn: rgb_hist_4bin_global_cosine (1632 vectors)\n",
      "✅ Hoàn thành: 1632 vectors\n",
      "\n",
      "============================================================\n",
      "Indexing 2/8: 4bin_global_l2\n",
      "============================================================\n",
      "🔧 Tạo collection mới: rgb_hist_4bin_global_l2\n",
      "   Cấu hình: n_bin=4, h_type=global, metric=l2\n",
      "📊 Extracting features từ training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing: 100%|██████████| 745/745 [04:50<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Hoàn thành indexing: 23824 vectors trong 290.03s\n",
      "⚡ Tốc độ: 82.1 vectors/s\n",
      "✅ Hoàn thành: 23824 vectors\n",
      "\n",
      "============================================================\n",
      "Indexing 3/8: 4bin_region_cosine\n",
      "============================================================\n",
      "🔧 Tạo collection mới: rgb_hist_4bin_region_cosine\n",
      "   Cấu hình: n_bin=4, h_type=region, metric=cosine\n",
      "📊 Extracting features từ training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing: 100%|██████████| 745/745 [06:18<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Hoàn thành indexing: 23824 vectors trong 378.93s\n",
      "⚡ Tốc độ: 62.9 vectors/s\n",
      "✅ Hoàn thành: 23824 vectors\n",
      "\n",
      "============================================================\n",
      "Indexing 4/8: 4bin_region_l2\n",
      "============================================================\n",
      "🔧 Tạo collection mới: rgb_hist_4bin_region_l2\n",
      "   Cấu hình: n_bin=4, h_type=region, metric=l2\n",
      "📊 Extracting features từ training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing: 100%|██████████| 745/745 [06:17<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Hoàn thành indexing: 23824 vectors trong 377.54s\n",
      "⚡ Tốc độ: 63.1 vectors/s\n",
      "✅ Hoàn thành: 23824 vectors\n",
      "\n",
      "============================================================\n",
      "Indexing 5/8: 8bin_global_cosine\n",
      "============================================================\n",
      "🔧 Tạo collection mới: rgb_hist_8bin_global_cosine\n",
      "   Cấu hình: n_bin=8, h_type=global, metric=cosine\n",
      "📊 Extracting features từ training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing: 100%|██████████| 745/745 [05:27<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Hoàn thành indexing: 23824 vectors trong 327.30s\n",
      "⚡ Tốc độ: 72.8 vectors/s\n",
      "✅ Hoàn thành: 23824 vectors\n",
      "\n",
      "============================================================\n",
      "Indexing 6/8: 8bin_global_l2\n",
      "============================================================\n",
      "🔧 Tạo collection mới: rgb_hist_8bin_global_l2\n",
      "   Cấu hình: n_bin=8, h_type=global, metric=l2\n",
      "📊 Extracting features từ training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing: 100%|██████████| 745/745 [03:05<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Hoàn thành indexing: 23824 vectors trong 185.58s\n",
      "⚡ Tốc độ: 128.4 vectors/s\n",
      "✅ Hoàn thành: 23824 vectors\n",
      "\n",
      "============================================================\n",
      "Indexing 7/8: 8bin_region_cosine\n",
      "============================================================\n",
      "🔧 Tạo collection mới: rgb_hist_8bin_region_cosine\n",
      "   Cấu hình: n_bin=8, h_type=region, metric=cosine\n",
      "📊 Extracting features từ training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing: 100%|██████████| 745/745 [05:30<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Hoàn thành indexing: 23824 vectors trong 330.44s\n",
      "⚡ Tốc độ: 72.1 vectors/s\n",
      "✅ Hoàn thành: 23824 vectors\n",
      "\n",
      "============================================================\n",
      "Indexing 8/8: 8bin_region_l2\n",
      "============================================================\n",
      "🔧 Tạo collection mới: rgb_hist_8bin_region_l2\n",
      "   Cấu hình: n_bin=8, h_type=region, metric=l2\n",
      "📊 Extracting features từ training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing: 100%|██████████| 745/745 [05:33<00:00,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Hoàn thành indexing: 23824 vectors trong 333.03s\n",
      "⚡ Tốc độ: 71.5 vectors/s\n",
      "✅ Hoàn thành: 23824 vectors\n",
      "\n",
      "🎉 Hoàn thành indexing cho tất cả 8 cấu hình!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# CHẠY INDEXING CHO TẤT CẢ CẤU HÌNH\n",
    "print(f\"🚀 Bắt đầu indexing cho {len(CONFIGS)} cấu hình...\")\n",
    "print(f\"📊 Sẽ index {train_size} training samples cho mỗi cấu hình\")\n",
    "print(\"⏳ Quá trình này có thể mất vài phút...\")\n",
    "\n",
    "indexing_results = []\n",
    "\n",
    "for i, (n_bin, h_type, metric) in enumerate(CONFIGS, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Indexing {i}/{len(CONFIGS)}: {n_bin}bin_{h_type}_{metric}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    try:\n",
    "        start_time = time()\n",
    "        collection, count = extract_and_store_features(n_bin, h_type, metric)\n",
    "        end_time = time()\n",
    "        \n",
    "        result = {\n",
    "            'config': f\"{n_bin}bin_{h_type}_{metric}\",\n",
    "            'n_bin': n_bin,\n",
    "            'h_type': h_type,\n",
    "            'metric': metric,\n",
    "            'vectors_count': count,\n",
    "            'indexing_time': end_time - start_time\n",
    "        }\n",
    "        indexing_results.append(result)\n",
    "        \n",
    "        print(f\"✅ Hoàn thành: {count} vectors\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Lỗi khi indexing {n_bin}bin_{h_type}_{metric}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(f\"\\n🎉 Hoàn thành indexing cho tất cả {len(indexing_results)} cấu hình!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T03:09:52.858217Z",
     "start_time": "2025-07-13T03:09:52.836043Z"
    }
   },
   "source": [
    "def get_train_labels(collection):\n",
    "    \"\"\"Lấy labels mapping từ collection\"\"\"\n",
    "    try:\n",
    "        # Thử lấy từ labels map\n",
    "        result = collection.get(ids=[\"_labels_map_\"])\n",
    "        if result['documents'] and len(result['documents']) > 0:\n",
    "            return json.loads(result['documents'][0])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Fallback: lấy từ metadata\n",
    "    all_data = collection.get(where={\"type\": \"train\"})\n",
    "    labels_map = {}\n",
    "    for id, metadata in zip(all_data['ids'], all_data['metadatas']):\n",
    "        if 'label' in metadata:\n",
    "            labels_map[id] = metadata['label']\n",
    "    \n",
    "    return labels_map\n",
    "\n",
    "def evaluate_configuration_v2(n_bin, h_type, metric):\n",
    "    \"\"\"Evaluate một cấu hình với metrics mới\"\"\"\n",
    "    collection_name = get_collection_name(n_bin, h_type, metric)\n",
    "    \n",
    "    try:\n",
    "        collection = chroma_client.get_collection(collection_name)\n",
    "        train_labels_map = get_train_labels(collection)\n",
    "        \n",
    "        print(f\"📊 Found {len(train_labels_map)} training vectors\")\n",
    "        \n",
    "        if len(train_labels_map) == 0:\n",
    "            print(\"❌ Không có training data! Vui lòng chạy indexing trước.\")\n",
    "            return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Không tìm thấy collection {collection_name}: {e}\")\n",
    "        print(\"Vui lòng chạy indexing trước!\")\n",
    "        return None\n",
    "    \n",
    "    # Extract test features và evaluate\n",
    "    feature_extractor = RGBHistogram(n_bin=n_bin, h_type=h_type, n_slice=N_SLICE)\n",
    "    \n",
    "    all_results = []\n",
    "    test_labels = []\n",
    "    tested_count = 0\n",
    "    \n",
    "    start_time = time()\n",
    "    \n",
    "    for images, labels, _ in tqdm(test_loader, desc=\"Testing\"):\n",
    "        if tested_count >= TEST_SIZE:\n",
    "            break\n",
    "        \n",
    "        count = min(len(images), TEST_SIZE - tested_count)\n",
    "        batch_images = images[:count]\n",
    "        batch_labels = labels[:count]\n",
    "        \n",
    "        # Convert to numpy directly (RGBHistogram only works on CPU)\n",
    "        # No need to move to GPU since feature extraction is CPU-only\n",
    "        images_np = (batch_images.numpy().transpose(0, 2, 3, 1) * 255).astype(np.uint8)\n",
    "        \n",
    "        for img, label in zip(images_np, batch_labels):\n",
    "            if tested_count >= TEST_SIZE:\n",
    "                break\n",
    "            \n",
    "            # Extract test feature\n",
    "            test_feature = feature_extractor(img)\n",
    "            \n",
    "            # Query ChromaDB\n",
    "            results = collection.query(\n",
    "                query_embeddings=[test_feature.tolist()],\n",
    "                n_results=max(max(MAP_K_VALUES), max(RECALL_K_VALUES)),\n",
    "                where={\"type\": \"train\"}\n",
    "            )\n",
    "            \n",
    "            # Lấy labels của kết quả\n",
    "            if results['ids'] and len(results['ids'][0]) > 0:\n",
    "                retrieved_ids = results['ids'][0]\n",
    "                retrieved_labels = [train_labels_map.get(id, -1) for id in retrieved_ids]\n",
    "                all_results.append(retrieved_labels)\n",
    "            else:\n",
    "                all_results.append([])\n",
    "            \n",
    "            test_labels.append(int(label))\n",
    "            tested_count += 1\n",
    "    \n",
    "    retrieval_time = time() - start_time\n",
    "    \n",
    "    # Tính metrics\n",
    "    metrics_data = {}\n",
    "    \n",
    "    # Tính mAP với MAP_K_VALUES\n",
    "    for k in MAP_K_VALUES:\n",
    "        map_scores = []\n",
    "        \n",
    "        for retrieved_labels, gt_label in zip(all_results, test_labels):\n",
    "            if len(retrieved_labels) == 0:\n",
    "                map_scores.append(0.0)\n",
    "                continue\n",
    "            \n",
    "            # Top-k results\n",
    "            top_k_labels = retrieved_labels[:k]\n",
    "            \n",
    "            # Tính mAP\n",
    "            ap = average_precision(top_k_labels, [gt_label], k)\n",
    "            map_scores.append(ap)\n",
    "        \n",
    "        # Lưu mAP\n",
    "        metrics_data[f'mAP@{k}'] = np.mean(map_scores)\n",
    "    \n",
    "    # Tính Recall với RECALL_K_VALUES\n",
    "    for k in RECALL_K_VALUES:\n",
    "        recall_scores = []\n",
    "        \n",
    "        for retrieved_labels, gt_label in zip(all_results, test_labels):\n",
    "            if len(retrieved_labels) == 0:\n",
    "                recall_scores.append(0.0)\n",
    "                continue\n",
    "            \n",
    "            # Top-k results\n",
    "            top_k_labels = retrieved_labels[:k]\n",
    "            \n",
    "            # Tính Recall\n",
    "            relevant_in_topk = sum(1 for label in top_k_labels if label == gt_label)\n",
    "            # Tổng số relevant items trong toàn bộ training set\n",
    "            total_relevant = sum(1 for label in train_labels_map.values() if label == gt_label)\n",
    "            \n",
    "            if total_relevant > 0:\n",
    "                rec = relevant_in_topk / total_relevant\n",
    "            else:\n",
    "                rec = 0.0\n",
    "            \n",
    "            recall_scores.append(rec)\n",
    "        \n",
    "        # Lưu Recall\n",
    "        metrics_data[f'Recall@{k}'] = np.mean(recall_scores)\n",
    "    \n",
    "    # Tính average mAP\n",
    "    avg_map = np.mean([metrics_data[f'mAP@{k}'] for k in MAP_K_VALUES])\n",
    "    metrics_data['avg_mAP'] = avg_map\n",
    "    \n",
    "    # Hiển thị kết quả\n",
    "    print(\"📊 Evaluation results:\")\n",
    "    for k in MAP_K_VALUES:\n",
    "        print(f\"   mAP@{k}: {metrics_data[f'mAP@{k}']:.4f}\")\n",
    "    for k in RECALL_K_VALUES:\n",
    "        print(f\"   Recall@{k}: {metrics_data[f'Recall@{k}']:.4f}\")\n",
    "    print(f\"   Average mAP: {avg_map:.4f}\")\n",
    "    \n",
    "    # Thêm thông tin cấu hình với average time\n",
    "    metrics_data.update({\n",
    "        'n_bin': n_bin,\n",
    "        'h_type': h_type,\n",
    "        'metric': metric,\n",
    "        'config_name': f\"{n_bin}bin_{h_type}_{metric}\",\n",
    "        'avg_retrieval_time': retrieval_time / tested_count,\n",
    "        'avg_retrieval_time_ms': (retrieval_time / tested_count) * 1000,\n",
    "        'tested_samples': tested_count,\n",
    "        'train_samples': len(train_labels_map)\n",
    "    })\n",
    "    \n",
    "    return metrics_data\n",
    "\n",
    "print(\"📋 Hàm evaluation  đã sẵn sàng!\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 Hàm evaluation  đã sẵn sàng!\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T05:45:59.488870Z",
     "start_time": "2025-07-13T03:09:59.723151Z"
    }
   },
   "source": [
    "print(f\"Evaluation cho {len(CONFIGS)} trường hợp...\")\n",
    "print(f\"Test trên {TEST_SIZE} samples\")\n",
    "\n",
    "evaluation_results = []\n",
    "\n",
    "for i, (n_bin, h_type, metric) in enumerate(CONFIGS, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Evaluation {i}/{len(CONFIGS)}: {n_bin}bin_{h_type}_{metric}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    try:\n",
    "        result = evaluate_configuration_v2(n_bin, h_type, metric)\n",
    "        if result:\n",
    "            evaluation_results.append(result)\n",
    "            print(f\"Complete: avg_mAP = {result['avg_mAP']:.4f}\")\n",
    "            print(f\"Avg retrieval time: {result['avg_retrieval_time']:.4f}s ({result['avg_retrieval_time_ms']:.1f}ms)\")\n",
    "        else:\n",
    "            print(f\"Fail: {n_bin}bin_{h_type}_{metric}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error when evaluating {n_bin}bin_{h_type}_{metric}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(f\"Complete .\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation cho 8 trường hợp...\n",
      "Test trên 5956 samples\n",
      "\n",
      "============================================================\n",
      "Evaluation 1/8: 4bin_global_cosine\n",
      "============================================================\n",
      "📊 Found 1632 training vectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 187/187 [14:41<00:00,  4.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Evaluation results:\n",
      "   mAP@1: 0.0155\n",
      "   mAP@5: 0.0276\n",
      "   mAP@10: 0.0307\n",
      "   Recall@10: 0.0194\n",
      "   Recall@100: 0.1201\n",
      "   Recall@1000: 0.6853\n",
      "   Average mAP: 0.0246\n",
      "Complete: avg_mAP = 0.0246\n",
      "Avg retrieval time: 0.1480s (148.0ms)\n",
      "\n",
      "============================================================\n",
      "Evaluation 2/8: 4bin_global_l2\n",
      "============================================================\n",
      "📊 Found 23824 training vectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 187/187 [40:06<00:00, 12.87s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Evaluation results:\n",
      "   mAP@1: 0.0315\n",
      "   mAP@5: 0.0493\n",
      "   mAP@10: 0.0537\n",
      "   Recall@10: 0.0024\n",
      "   Recall@100: 0.0147\n",
      "   Recall@1000: 0.0876\n",
      "   Average mAP: 0.0448\n",
      "Complete: avg_mAP = 0.0448\n",
      "Avg retrieval time: 0.4041s (404.1ms)\n",
      "\n",
      "============================================================\n",
      "Evaluation 3/8: 4bin_region_cosine\n",
      "============================================================\n",
      "📊 Found 23824 training vectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 187/187 [16:05<00:00,  5.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Evaluation results:\n",
      "   mAP@1: 0.0468\n",
      "   mAP@5: 0.0753\n",
      "   mAP@10: 0.0801\n",
      "   Recall@10: 0.0042\n",
      "   Recall@100: 0.0203\n",
      "   Recall@1000: 0.0930\n",
      "   Average mAP: 0.0674\n",
      "Complete: avg_mAP = 0.0674\n",
      "Avg retrieval time: 0.1621s (162.1ms)\n",
      "\n",
      "============================================================\n",
      "Evaluation 4/8: 4bin_region_l2\n",
      "============================================================\n",
      "📊 Found 23824 training vectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 187/187 [16:03<00:00,  5.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Evaluation results:\n",
      "   mAP@1: 0.0473\n",
      "   mAP@5: 0.0745\n",
      "   mAP@10: 0.0800\n",
      "   Recall@10: 0.0043\n",
      "   Recall@100: 0.0204\n",
      "   Recall@1000: 0.0928\n",
      "   Average mAP: 0.0673\n",
      "Complete: avg_mAP = 0.0673\n",
      "Avg retrieval time: 0.1618s (161.8ms)\n",
      "\n",
      "============================================================\n",
      "Evaluation 5/8: 8bin_global_cosine\n",
      "============================================================\n",
      "📊 Found 23824 training vectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 187/187 [16:13<00:00,  5.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Evaluation results:\n",
      "   mAP@1: 0.0345\n",
      "   mAP@5: 0.0547\n",
      "   mAP@10: 0.0591\n",
      "   Recall@10: 0.0027\n",
      "   Recall@100: 0.0152\n",
      "   Recall@1000: 0.0860\n",
      "   Average mAP: 0.0494\n",
      "Complete: avg_mAP = 0.0494\n",
      "Avg retrieval time: 0.1635s (163.5ms)\n",
      "\n",
      "============================================================\n",
      "Evaluation 6/8: 8bin_global_l2\n",
      "============================================================\n",
      "📊 Found 23824 training vectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 187/187 [16:44<00:00,  5.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Evaluation results:\n",
      "   mAP@1: 0.0344\n",
      "   mAP@5: 0.0547\n",
      "   mAP@10: 0.0591\n",
      "   Recall@10: 0.0027\n",
      "   Recall@100: 0.0152\n",
      "   Recall@1000: 0.0861\n",
      "   Average mAP: 0.0494\n",
      "Complete: avg_mAP = 0.0494\n",
      "Avg retrieval time: 0.1686s (168.6ms)\n",
      "\n",
      "============================================================\n",
      "Evaluation 7/8: 8bin_region_cosine\n",
      "============================================================\n",
      "📊 Found 23824 training vectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 187/187 [17:45<00:00,  5.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Evaluation results:\n",
      "   mAP@1: 0.0426\n",
      "   mAP@5: 0.0682\n",
      "   mAP@10: 0.0732\n",
      "   Recall@10: 0.0037\n",
      "   Recall@100: 0.0187\n",
      "   Recall@1000: 0.0859\n",
      "   Average mAP: 0.0613\n",
      "Complete: avg_mAP = 0.0613\n",
      "Avg retrieval time: 0.1790s (179.0ms)\n",
      "\n",
      "============================================================\n",
      "Evaluation 8/8: 8bin_region_l2\n",
      "============================================================\n",
      "📊 Found 23824 training vectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 187/187 [17:14<00:00,  5.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Evaluation results:\n",
      "   mAP@1: 0.0441\n",
      "   mAP@5: 0.0696\n",
      "   mAP@10: 0.0741\n",
      "   Recall@10: 0.0036\n",
      "   Recall@100: 0.0188\n",
      "   Recall@1000: 0.0862\n",
      "   Average mAP: 0.0626\n",
      "Complete: avg_mAP = 0.0626\n",
      "Avg retrieval time: 0.1737s (173.7ms)\n",
      "Complete .\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T08:56:06.798342Z",
     "start_time": "2025-07-13T08:56:06.774633Z"
    }
   },
   "source": [
    "if evaluation_results:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Hien thi ket qua theo thu tu cau hinh\n",
    "    print(f\"\\nResults:\")\n",
    "    print(\"-\" * 120)\n",
    "    print(f\"{'STT':<4} {'Configuration':<20} {'Avg mAP':<10} {'mAP@1':<8} {'mAP@5':<8} {'mAP@10':<8} {'R@10':<8} {'R@100':<8} {'R@1000':<8} {'Avg Time(ms)':<12}\")\n",
    "    print(\"-\" * 120)\n",
    "    \n",
    "    for i, result in enumerate(evaluation_results, 1):\n",
    "        print(f\"{i:<4} {result['config_name']:<20} {result['avg_mAP']:<10.4f} \"\n",
    "              f\"{result['mAP@1']:<8.4f} {result['mAP@5']:<8.4f} {result['mAP@10']:<8.4f} \"\n",
    "              f\"{result['Recall@10']:<8.4f} {result['Recall@100']:<8.4f} {result['Recall@1000']:<8.4f} \"\n",
    "              f\"{result['avg_retrieval_time_ms']:<12.1f}\")\n",
    "    \n",
    "    # Luu ket qua\n",
    "    df = pd.DataFrame(evaluation_results)\n",
    "    csv_path = 'out/evaluation_results_v2.csv'\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"\\nKet qua chi tiet luu tai: {csv_path}\")\n",
    "    \n",
    "    # Thong ke tong quan\n",
    "    print(f\"- Số trường hợp đã test: {len(evaluation_results)}\")\n",
    "    print(f\"- Test samples: {evaluation_results[0]['tested_samples']}\")\n",
    "    print(f\"- Training samples: {evaluation_results[0]['train_samples']}\")\n",
    "    \n",
    "    avg_times = [r['avg_retrieval_time_ms'] for r in evaluation_results]\n",
    "    avg_maps = [r['avg_mAP'] for r in evaluation_results]\n",
    "    \n",
    "    print(f\"- Avg time: {np.mean(avg_times):.1f}ms (min: {np.min(avg_times):.1f}ms, max: {np.max(avg_times):.1f}ms)\")\n",
    "else:\n",
    "    print(\"Empty !!\")\n",
    "    print(\"Hãy indexing trước!.\")\n",
    "\n",
    "# GPU memory cleanup\n",
    "if device.type == \"cuda\":\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"\\nGPU memory cleaned up\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "================================================================================\n",
      "\n",
      "Results:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "STT  Configuration        Avg mAP    mAP@1    mAP@5    mAP@10   R@10     R@100    R@1000   Avg Time(ms)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "1    4bin_global_cosine   0.0246     0.0155   0.0276   0.0307   0.0194   0.1201   0.6853   148.0       \n",
      "2    4bin_global_l2       0.0448     0.0315   0.0493   0.0537   0.0024   0.0147   0.0876   404.1       \n",
      "3    4bin_region_cosine   0.0674     0.0468   0.0753   0.0801   0.0042   0.0203   0.0930   162.1       \n",
      "4    4bin_region_l2       0.0673     0.0473   0.0745   0.0800   0.0043   0.0204   0.0928   161.8       \n",
      "5    8bin_global_cosine   0.0494     0.0345   0.0547   0.0591   0.0027   0.0152   0.0860   163.5       \n",
      "6    8bin_global_l2       0.0494     0.0344   0.0547   0.0591   0.0027   0.0152   0.0861   168.6       \n",
      "7    8bin_region_cosine   0.0613     0.0426   0.0682   0.0732   0.0037   0.0187   0.0859   179.0       \n",
      "8    8bin_region_l2       0.0626     0.0441   0.0696   0.0741   0.0036   0.0188   0.0862   173.7       \n",
      "\n",
      "Ket qua chi tiet luu tai: out/evaluation_results_v2.csv\n",
      "- Số trường hợp đã test: 8\n",
      "- Test samples: 5956\n",
      "- Training samples: 1632\n",
      "- Avg time: 195.1ms (min: 148.0ms, max: 404.1ms)\n",
      "\n",
      "GPU memory cleaned up\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
