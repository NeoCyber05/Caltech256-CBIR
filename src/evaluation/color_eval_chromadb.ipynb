{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T03:09:37.264158Z",
     "start_time": "2025-07-13T03:09:32.106781Z"
    }
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "from src.datasets.caltech256 import Caltech256DataModule\n",
    "from src.featuring.rgb_histogram import RGBHistogram\n",
    "from src.metrics import average_precision\n",
    "\n",
    "# T·∫°o th∆∞ m·ª•c output\n",
    "os.makedirs('out', exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Imports ho√†n t·∫•t!\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports ho√†n t·∫•t!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T03:09:39.519817Z",
     "start_time": "2025-07-13T03:09:39.502415Z"
    }
   },
   "source": [
    "# ======================== CONFIGURATIONS ========================\n",
    "CONFIGS = [\n",
    "    # (n_bin, h_type, metric)\n",
    "    (4, 'global', 'cosine'),\n",
    "    (4, 'global', 'l2'),\n",
    "    (4, 'region', 'cosine'), \n",
    "    (4, 'region', 'l2'),\n",
    "    (8, 'global', 'cosine'),\n",
    "    (8, 'global', 'l2'),\n",
    "    (8, 'region', 'cosine'),\n",
    "    (8, 'region', 'l2'),\n",
    "]\n",
    "\n",
    "# C·∫•u h√¨nh evaluation\n",
    "TEST_SIZE = 5956     # S·ªë l∆∞·ª£ng test samples ƒë·ªÉ evaluation\n",
    "N_SLICE = 3          # S·ªë slice cho region histogram\n",
    "MAP_K_VALUES = [1, 5, 10]  # Top-k cho mAP evaluation\n",
    "RECALL_K_VALUES = [10, 100, 1000]  # Top-k cho Recall evaluation\n",
    "\n",
    "# ChromaDB settings\n",
    "CHROMA_DIR = \"chroma_storage\"\n",
    "COLLECTION_PREFIX = \"rgb_hist\"\n",
    "\n",
    "print(f\"üìã T·ªïng c·∫•u h√¨nh ƒë·ªÉ test: {len(CONFIGS)}\")\n",
    "print(f\"üìä Test size: {TEST_SIZE}\")\n",
    "print(f\"üíæ ChromaDB storage: {CHROMA_DIR}\")\n",
    "print(f\"üéØ mAP k-values: {MAP_K_VALUES}\")\n",
    "print(f\"üéØ Recall k-values: {RECALL_K_VALUES}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã T·ªïng c·∫•u h√¨nh ƒë·ªÉ test: 8\n",
      "üìä Test size: 5956\n",
      "üíæ ChromaDB storage: chroma_storage\n",
      "üéØ mAP k-values: [1, 5, 10]\n",
      "üéØ Recall k-values: [10, 100, 1000]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T03:09:42.933827Z",
     "start_time": "2025-07-13T03:09:42.297576Z"
    }
   },
   "source": [
    "# Setup dataset\n",
    "dataset_root = os.path.abspath('data/caltech-256/256_ObjectCategories')\n",
    "print(f\"üìÇ Dataset path: {dataset_root}\")\n",
    "print(f\"üìÇ Exists: {os.path.exists(dataset_root)}\")\n",
    "\n",
    "if os.path.exists(dataset_root):\n",
    "    data_module = Caltech256DataModule(batch_size=32, root=dataset_root)\n",
    "    data_module.setup()\n",
    "    train_loader = data_module.train_dataloader()\n",
    "    test_loader = data_module.test_dataloader()\n",
    "    \n",
    "    train_size = len(train_loader.dataset)\n",
    "    test_size = len(test_loader.dataset)\n",
    "    total_size = train_size + test_size\n",
    "    \n",
    "    print(f\"‚úÖ Dataset loaded th√†nh c√¥ng!\")\n",
    "    print(f\"üìä Training: {train_size} samples ({train_size/total_size*100:.1f}%)\")\n",
    "    print(f\"üìä Testing: {test_size} samples ({test_size/total_size*100:.1f}%)\")\n",
    "    print(f\"üìä Total: {total_size} samples\")\n",
    "else:\n",
    "    print(\"‚ùå Dataset kh√¥ng t√¨m th·∫•y!\")\n",
    "    print(\"Vui l√≤ng ƒë·∫£m b·∫£o dataset ·ªü ƒë∆∞·ªùng d·∫´n ƒë√∫ng.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Dataset path: D:\\AI\\Food-CBIR\\src\\evaluation\\data\\caltech-256\\256_ObjectCategories\n",
      "üìÇ Exists: True\n",
      "üìÇ Found 256 valid categories\n",
      "üìä Loaded 29780 total images from 256 classes\n",
      "üìã Train: 23824 images\n",
      "üìÇ Found 256 valid categories\n",
      "üìä Loaded 29780 total images from 256 classes\n",
      "üìã Test: 5956 images\n",
      "Train: 23824, Test: 5956\n",
      "‚úÖ Dataset loaded th√†nh c√¥ng!\n",
      "üìä Training: 23824 samples (80.0%)\n",
      "üìä Testing: 5956 samples (20.0%)\n",
      "üìä Total: 29780 samples\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T03:09:44.628304Z",
     "start_time": "2025-07-13T03:09:44.508238Z"
    }
   },
   "source": [
    "# Setup GPU/CPU device\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"üöÄ Device: {device}\")\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    print(f\"üì± GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "    print(f\"üî• CUDA Version: {torch.version.cuda}\")\n",
    "    # Clear any existing GPU cache\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    print(\"üíª Using CPU (GPU not available)\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Device: cuda\n",
      "üì± GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "üíæ GPU Memory: 8.0 GB\n",
      "üî• CUDA Version: 12.1\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T03:09:46.626896Z",
     "start_time": "2025-07-13T03:09:46.472264Z"
    }
   },
   "source": [
    "# Setup ChromaDB\n",
    "os.makedirs(CHROMA_DIR, exist_ok=True)\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(\n",
    "    path=CHROMA_DIR,\n",
    "    settings=Settings(\n",
    "        anonymized_telemetry=False,\n",
    "        allow_reset=True\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ ChromaDB initialized t·∫°i: {CHROMA_DIR}\")\n",
    "print(f\"üìä Existing collections: {len(chroma_client.list_collections())}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ChromaDB initialized t·∫°i: chroma_storage\n",
      "üìä Existing collections: 8\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T03:09:48.997980Z",
     "start_time": "2025-07-13T03:09:48.973239Z"
    }
   },
   "source": [
    "def get_collection_name(n_bin, h_type, metric):\n",
    "    \"\"\"Generate collection name for configuration\"\"\"\n",
    "    return f\"{COLLECTION_PREFIX}_{n_bin}bin_{h_type}_{metric}\"\n",
    "\n",
    "def extract_and_store_features(n_bin, h_type, metric, force_reindex=False):\n",
    "    \"\"\"Extract features v√† store v√†o ChromaDB\"\"\"\n",
    "    collection_name = get_collection_name(n_bin, h_type, metric)\n",
    "    \n",
    "    # Ki·ªÉm tra xem collection ƒë√£ t·ªìn t·∫°i ch∆∞a\n",
    "    try:\n",
    "        collection = chroma_client.get_collection(collection_name)\n",
    "        count = collection.count()\n",
    "        if count > 0 and not force_reindex:\n",
    "            print(f\"üìÇ S·ª≠ d·ª•ng collection c√≥ s·∫µn: {collection_name} ({count} vectors)\")\n",
    "            return collection, count\n",
    "    except:\n",
    "        pass  # Collection ch∆∞a t·ªìn t·∫°i\n",
    "    \n",
    "    print(f\"üîß T·∫°o collection m·ªõi: {collection_name}\")\n",
    "    print(f\"   C·∫•u h√¨nh: n_bin={n_bin}, h_type={h_type}, metric={metric}\")\n",
    "    \n",
    "    # X√≥a collection c≈© n·∫øu c√≥\n",
    "    try:\n",
    "        chroma_client.delete_collection(collection_name)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # T·∫°o collection m·ªõi\n",
    "    chroma_metric = \"cosine\" if metric == \"cosine\" else \"l2\"\n",
    "    collection = chroma_client.create_collection(\n",
    "        name=collection_name,\n",
    "        metadata={\"n_bin\": n_bin, \"h_type\": h_type, \"metric\": metric},\n",
    "        embedding_function=None\n",
    "    )\n",
    "    \n",
    "    # Extract features\n",
    "    feature_extractor = RGBHistogram(n_bin=n_bin, h_type=h_type, n_slice=N_SLICE)\n",
    "    \n",
    "    print(\"üìä Extracting features t·ª´ training set...\")\n",
    "    stored_count = 0\n",
    "    train_labels_map = {}\n",
    "    \n",
    "    start_time = time()\n",
    "    \n",
    "    for batch_idx, (images, labels, _) in enumerate(tqdm(train_loader, desc=\"Indexing\")):\n",
    "        # Move to GPU if available\n",
    "        if device.type == \"cuda\":\n",
    "            images = images.to(device)\n",
    "        \n",
    "        # Convert to numpy\n",
    "        images_np = (images.cpu().numpy().transpose(0, 2, 3, 1) * 255).astype(np.uint8)\n",
    "        \n",
    "        # Extract features cho batch\n",
    "        batch_features = []\n",
    "        batch_ids = []\n",
    "        batch_metadatas = []\n",
    "        \n",
    "        for i, (img, label) in enumerate(zip(images_np, labels)):\n",
    "            feature = feature_extractor(img)\n",
    "            \n",
    "            vector_id = f\"train_{stored_count + i}\"\n",
    "            \n",
    "            batch_features.append(feature.tolist())\n",
    "            batch_ids.append(vector_id)\n",
    "            batch_metadatas.append({\n",
    "                \"type\": \"train\",\n",
    "                \"label\": int(label),\n",
    "                \"index\": stored_count + i\n",
    "            })\n",
    "            \n",
    "            train_labels_map[vector_id] = int(label)\n",
    "        \n",
    "        # L∆∞u batch v√†o ChromaDB\n",
    "        if batch_features:\n",
    "            collection.add(\n",
    "                embeddings=batch_features,\n",
    "                ids=batch_ids,\n",
    "                metadatas=batch_metadatas\n",
    "            )\n",
    "        \n",
    "        stored_count += len(batch_features)\n",
    "    \n",
    "    indexing_time = time() - start_time\n",
    "    \n",
    "    # L∆∞u labels mapping\n",
    "    try:\n",
    "        labels_json = json.dumps(train_labels_map)\n",
    "        collection.add(\n",
    "            embeddings=[[0.0] * len(batch_features[0])],\n",
    "            ids=[\"_labels_map_\"],\n",
    "            metadatas=[{\"type\": \"labels_map\"}],\n",
    "            documents=[labels_json]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Kh√¥ng th·ªÉ l∆∞u labels mapping: {e}\")\n",
    "    \n",
    "    print(f\"‚úÖ Ho√†n th√†nh indexing: {stored_count} vectors trong {indexing_time:.2f}s\")\n",
    "    print(f\"‚ö° T·ªëc ƒë·ªô: {stored_count/indexing_time:.1f} vectors/s\")\n",
    "    \n",
    "    return collection, stored_count\n",
    "\n",
    "print(\"üìã H√†m indexing ƒë√£ s·∫µn s√†ng!\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã H√†m indexing ƒë√£ s·∫µn s√†ng!\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T09:04:43.875889Z",
     "start_time": "2025-07-12T08:27:39.704660Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ B·∫Øt ƒë·∫ßu indexing cho 8 c·∫•u h√¨nh...\n",
      "üìä S·∫Ω index 23824 training samples cho m·ªói c·∫•u h√¨nh\n",
      "‚è≥ Qu√° tr√¨nh n√†y c√≥ th·ªÉ m·∫•t v√†i ph√∫t...\n",
      "\n",
      "============================================================\n",
      "Indexing 1/8: 4bin_global_cosine\n",
      "============================================================\n",
      "üìÇ S·ª≠ d·ª•ng collection c√≥ s·∫µn: rgb_hist_4bin_global_cosine (1632 vectors)\n",
      "‚úÖ Ho√†n th√†nh: 1632 vectors\n",
      "\n",
      "============================================================\n",
      "Indexing 2/8: 4bin_global_l2\n",
      "============================================================\n",
      "üîß T·∫°o collection m·ªõi: rgb_hist_4bin_global_l2\n",
      "   C·∫•u h√¨nh: n_bin=4, h_type=global, metric=l2\n",
      "üìä Extracting features t·ª´ training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 745/745 [04:50<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ho√†n th√†nh indexing: 23824 vectors trong 290.03s\n",
      "‚ö° T·ªëc ƒë·ªô: 82.1 vectors/s\n",
      "‚úÖ Ho√†n th√†nh: 23824 vectors\n",
      "\n",
      "============================================================\n",
      "Indexing 3/8: 4bin_region_cosine\n",
      "============================================================\n",
      "üîß T·∫°o collection m·ªõi: rgb_hist_4bin_region_cosine\n",
      "   C·∫•u h√¨nh: n_bin=4, h_type=region, metric=cosine\n",
      "üìä Extracting features t·ª´ training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 745/745 [06:18<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ho√†n th√†nh indexing: 23824 vectors trong 378.93s\n",
      "‚ö° T·ªëc ƒë·ªô: 62.9 vectors/s\n",
      "‚úÖ Ho√†n th√†nh: 23824 vectors\n",
      "\n",
      "============================================================\n",
      "Indexing 4/8: 4bin_region_l2\n",
      "============================================================\n",
      "üîß T·∫°o collection m·ªõi: rgb_hist_4bin_region_l2\n",
      "   C·∫•u h√¨nh: n_bin=4, h_type=region, metric=l2\n",
      "üìä Extracting features t·ª´ training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 745/745 [06:17<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ho√†n th√†nh indexing: 23824 vectors trong 377.54s\n",
      "‚ö° T·ªëc ƒë·ªô: 63.1 vectors/s\n",
      "‚úÖ Ho√†n th√†nh: 23824 vectors\n",
      "\n",
      "============================================================\n",
      "Indexing 5/8: 8bin_global_cosine\n",
      "============================================================\n",
      "üîß T·∫°o collection m·ªõi: rgb_hist_8bin_global_cosine\n",
      "   C·∫•u h√¨nh: n_bin=8, h_type=global, metric=cosine\n",
      "üìä Extracting features t·ª´ training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 745/745 [05:27<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ho√†n th√†nh indexing: 23824 vectors trong 327.30s\n",
      "‚ö° T·ªëc ƒë·ªô: 72.8 vectors/s\n",
      "‚úÖ Ho√†n th√†nh: 23824 vectors\n",
      "\n",
      "============================================================\n",
      "Indexing 6/8: 8bin_global_l2\n",
      "============================================================\n",
      "üîß T·∫°o collection m·ªõi: rgb_hist_8bin_global_l2\n",
      "   C·∫•u h√¨nh: n_bin=8, h_type=global, metric=l2\n",
      "üìä Extracting features t·ª´ training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 745/745 [03:05<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ho√†n th√†nh indexing: 23824 vectors trong 185.58s\n",
      "‚ö° T·ªëc ƒë·ªô: 128.4 vectors/s\n",
      "‚úÖ Ho√†n th√†nh: 23824 vectors\n",
      "\n",
      "============================================================\n",
      "Indexing 7/8: 8bin_region_cosine\n",
      "============================================================\n",
      "üîß T·∫°o collection m·ªõi: rgb_hist_8bin_region_cosine\n",
      "   C·∫•u h√¨nh: n_bin=8, h_type=region, metric=cosine\n",
      "üìä Extracting features t·ª´ training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 745/745 [05:30<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ho√†n th√†nh indexing: 23824 vectors trong 330.44s\n",
      "‚ö° T·ªëc ƒë·ªô: 72.1 vectors/s\n",
      "‚úÖ Ho√†n th√†nh: 23824 vectors\n",
      "\n",
      "============================================================\n",
      "Indexing 8/8: 8bin_region_l2\n",
      "============================================================\n",
      "üîß T·∫°o collection m·ªõi: rgb_hist_8bin_region_l2\n",
      "   C·∫•u h√¨nh: n_bin=8, h_type=region, metric=l2\n",
      "üìä Extracting features t·ª´ training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 745/745 [05:33<00:00,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ho√†n th√†nh indexing: 23824 vectors trong 333.03s\n",
      "‚ö° T·ªëc ƒë·ªô: 71.5 vectors/s\n",
      "‚úÖ Ho√†n th√†nh: 23824 vectors\n",
      "\n",
      "üéâ Ho√†n th√†nh indexing cho t·∫•t c·∫£ 8 c·∫•u h√¨nh!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# CH·∫†Y INDEXING CHO T·∫§T C·∫¢ C·∫§U H√åNH\n",
    "print(f\"üöÄ B·∫Øt ƒë·∫ßu indexing cho {len(CONFIGS)} c·∫•u h√¨nh...\")\n",
    "print(f\"üìä S·∫Ω index {train_size} training samples cho m·ªói c·∫•u h√¨nh\")\n",
    "print(\"‚è≥ Qu√° tr√¨nh n√†y c√≥ th·ªÉ m·∫•t v√†i ph√∫t...\")\n",
    "\n",
    "indexing_results = []\n",
    "\n",
    "for i, (n_bin, h_type, metric) in enumerate(CONFIGS, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Indexing {i}/{len(CONFIGS)}: {n_bin}bin_{h_type}_{metric}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    try:\n",
    "        start_time = time()\n",
    "        collection, count = extract_and_store_features(n_bin, h_type, metric)\n",
    "        end_time = time()\n",
    "        \n",
    "        result = {\n",
    "            'config': f\"{n_bin}bin_{h_type}_{metric}\",\n",
    "            'n_bin': n_bin,\n",
    "            'h_type': h_type,\n",
    "            'metric': metric,\n",
    "            'vectors_count': count,\n",
    "            'indexing_time': end_time - start_time\n",
    "        }\n",
    "        indexing_results.append(result)\n",
    "        \n",
    "        print(f\"‚úÖ Ho√†n th√†nh: {count} vectors\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå L·ªói khi indexing {n_bin}bin_{h_type}_{metric}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(f\"\\nüéâ Ho√†n th√†nh indexing cho t·∫•t c·∫£ {len(indexing_results)} c·∫•u h√¨nh!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T03:09:52.858217Z",
     "start_time": "2025-07-13T03:09:52.836043Z"
    }
   },
   "source": [
    "def get_train_labels(collection):\n",
    "    \"\"\"L·∫•y labels mapping t·ª´ collection\"\"\"\n",
    "    try:\n",
    "        # Th·ª≠ l·∫•y t·ª´ labels map\n",
    "        result = collection.get(ids=[\"_labels_map_\"])\n",
    "        if result['documents'] and len(result['documents']) > 0:\n",
    "            return json.loads(result['documents'][0])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Fallback: l·∫•y t·ª´ metadata\n",
    "    all_data = collection.get(where={\"type\": \"train\"})\n",
    "    labels_map = {}\n",
    "    for id, metadata in zip(all_data['ids'], all_data['metadatas']):\n",
    "        if 'label' in metadata:\n",
    "            labels_map[id] = metadata['label']\n",
    "    \n",
    "    return labels_map\n",
    "\n",
    "def evaluate_configuration_v2(n_bin, h_type, metric):\n",
    "    \"\"\"Evaluate m·ªôt c·∫•u h√¨nh v·ªõi metrics m·ªõi\"\"\"\n",
    "    collection_name = get_collection_name(n_bin, h_type, metric)\n",
    "    \n",
    "    try:\n",
    "        collection = chroma_client.get_collection(collection_name)\n",
    "        train_labels_map = get_train_labels(collection)\n",
    "        \n",
    "        print(f\"üìä Found {len(train_labels_map)} training vectors\")\n",
    "        \n",
    "        if len(train_labels_map) == 0:\n",
    "            print(\"‚ùå Kh√¥ng c√≥ training data! Vui l√≤ng ch·∫°y indexing tr∆∞·ªõc.\")\n",
    "            return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Kh√¥ng t√¨m th·∫•y collection {collection_name}: {e}\")\n",
    "        print(\"Vui l√≤ng ch·∫°y indexing tr∆∞·ªõc!\")\n",
    "        return None\n",
    "    \n",
    "    # Extract test features v√† evaluate\n",
    "    feature_extractor = RGBHistogram(n_bin=n_bin, h_type=h_type, n_slice=N_SLICE)\n",
    "    \n",
    "    all_results = []\n",
    "    test_labels = []\n",
    "    tested_count = 0\n",
    "    \n",
    "    start_time = time()\n",
    "    \n",
    "    for images, labels, _ in tqdm(test_loader, desc=\"Testing\"):\n",
    "        if tested_count >= TEST_SIZE:\n",
    "            break\n",
    "        \n",
    "        count = min(len(images), TEST_SIZE - tested_count)\n",
    "        batch_images = images[:count]\n",
    "        batch_labels = labels[:count]\n",
    "        \n",
    "        # Convert to numpy directly (RGBHistogram only works on CPU)\n",
    "        # No need to move to GPU since feature extraction is CPU-only\n",
    "        images_np = (batch_images.numpy().transpose(0, 2, 3, 1) * 255).astype(np.uint8)\n",
    "        \n",
    "        for img, label in zip(images_np, batch_labels):\n",
    "            if tested_count >= TEST_SIZE:\n",
    "                break\n",
    "            \n",
    "            # Extract test feature\n",
    "            test_feature = feature_extractor(img)\n",
    "            \n",
    "            # Query ChromaDB\n",
    "            results = collection.query(\n",
    "                query_embeddings=[test_feature.tolist()],\n",
    "                n_results=max(max(MAP_K_VALUES), max(RECALL_K_VALUES)),\n",
    "                where={\"type\": \"train\"}\n",
    "            )\n",
    "            \n",
    "            # L·∫•y labels c·ªßa k·∫øt qu·∫£\n",
    "            if results['ids'] and len(results['ids'][0]) > 0:\n",
    "                retrieved_ids = results['ids'][0]\n",
    "                retrieved_labels = [train_labels_map.get(id, -1) for id in retrieved_ids]\n",
    "                all_results.append(retrieved_labels)\n",
    "            else:\n",
    "                all_results.append([])\n",
    "            \n",
    "            test_labels.append(int(label))\n",
    "            tested_count += 1\n",
    "    \n",
    "    retrieval_time = time() - start_time\n",
    "    \n",
    "    # T√≠nh metrics\n",
    "    metrics_data = {}\n",
    "    \n",
    "    # T√≠nh mAP v·ªõi MAP_K_VALUES\n",
    "    for k in MAP_K_VALUES:\n",
    "        map_scores = []\n",
    "        \n",
    "        for retrieved_labels, gt_label in zip(all_results, test_labels):\n",
    "            if len(retrieved_labels) == 0:\n",
    "                map_scores.append(0.0)\n",
    "                continue\n",
    "            \n",
    "            # Top-k results\n",
    "            top_k_labels = retrieved_labels[:k]\n",
    "            \n",
    "            # T√≠nh mAP\n",
    "            ap = average_precision(top_k_labels, [gt_label], k)\n",
    "            map_scores.append(ap)\n",
    "        \n",
    "        # L∆∞u mAP\n",
    "        metrics_data[f'mAP@{k}'] = np.mean(map_scores)\n",
    "    \n",
    "    # T√≠nh Recall v·ªõi RECALL_K_VALUES\n",
    "    for k in RECALL_K_VALUES:\n",
    "        recall_scores = []\n",
    "        \n",
    "        for retrieved_labels, gt_label in zip(all_results, test_labels):\n",
    "            if len(retrieved_labels) == 0:\n",
    "                recall_scores.append(0.0)\n",
    "                continue\n",
    "            \n",
    "            # Top-k results\n",
    "            top_k_labels = retrieved_labels[:k]\n",
    "            \n",
    "            # T√≠nh Recall\n",
    "            relevant_in_topk = sum(1 for label in top_k_labels if label == gt_label)\n",
    "            # T·ªïng s·ªë relevant items trong to√†n b·ªô training set\n",
    "            total_relevant = sum(1 for label in train_labels_map.values() if label == gt_label)\n",
    "            \n",
    "            if total_relevant > 0:\n",
    "                rec = relevant_in_topk / total_relevant\n",
    "            else:\n",
    "                rec = 0.0\n",
    "            \n",
    "            recall_scores.append(rec)\n",
    "        \n",
    "        # L∆∞u Recall\n",
    "        metrics_data[f'Recall@{k}'] = np.mean(recall_scores)\n",
    "    \n",
    "    # T√≠nh average mAP\n",
    "    avg_map = np.mean([metrics_data[f'mAP@{k}'] for k in MAP_K_VALUES])\n",
    "    metrics_data['avg_mAP'] = avg_map\n",
    "    \n",
    "    # Hi·ªÉn th·ªã k·∫øt qu·∫£\n",
    "    print(\"üìä Evaluation results:\")\n",
    "    for k in MAP_K_VALUES:\n",
    "        print(f\"   mAP@{k}: {metrics_data[f'mAP@{k}']:.4f}\")\n",
    "    for k in RECALL_K_VALUES:\n",
    "        print(f\"   Recall@{k}: {metrics_data[f'Recall@{k}']:.4f}\")\n",
    "    print(f\"   Average mAP: {avg_map:.4f}\")\n",
    "    \n",
    "    # Th√™m th√¥ng tin c·∫•u h√¨nh v·ªõi average time\n",
    "    metrics_data.update({\n",
    "        'n_bin': n_bin,\n",
    "        'h_type': h_type,\n",
    "        'metric': metric,\n",
    "        'config_name': f\"{n_bin}bin_{h_type}_{metric}\",\n",
    "        'avg_retrieval_time': retrieval_time / tested_count,\n",
    "        'avg_retrieval_time_ms': (retrieval_time / tested_count) * 1000,\n",
    "        'tested_samples': tested_count,\n",
    "        'train_samples': len(train_labels_map)\n",
    "    })\n",
    "    \n",
    "    return metrics_data\n",
    "\n",
    "print(\"üìã H√†m evaluation  ƒë√£ s·∫µn s√†ng!\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã H√†m evaluation  ƒë√£ s·∫µn s√†ng!\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T05:45:59.488870Z",
     "start_time": "2025-07-13T03:09:59.723151Z"
    }
   },
   "source": [
    "print(f\"Evaluation cho {len(CONFIGS)} tr∆∞·ªùng h·ª£p...\")\n",
    "print(f\"Test tr√™n {TEST_SIZE} samples\")\n",
    "\n",
    "evaluation_results = []\n",
    "\n",
    "for i, (n_bin, h_type, metric) in enumerate(CONFIGS, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Evaluation {i}/{len(CONFIGS)}: {n_bin}bin_{h_type}_{metric}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    try:\n",
    "        result = evaluate_configuration_v2(n_bin, h_type, metric)\n",
    "        if result:\n",
    "            evaluation_results.append(result)\n",
    "            print(f\"Complete: avg_mAP = {result['avg_mAP']:.4f}\")\n",
    "            print(f\"Avg retrieval time: {result['avg_retrieval_time']:.4f}s ({result['avg_retrieval_time_ms']:.1f}ms)\")\n",
    "        else:\n",
    "            print(f\"Fail: {n_bin}bin_{h_type}_{metric}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error when evaluating {n_bin}bin_{h_type}_{metric}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(f\"Complete .\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation cho 8 tr∆∞·ªùng h·ª£p...\n",
      "Test tr√™n 5956 samples\n",
      "\n",
      "============================================================\n",
      "Evaluation 1/8: 4bin_global_cosine\n",
      "============================================================\n",
      "üìä Found 1632 training vectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 187/187 [14:41<00:00,  4.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Evaluation results:\n",
      "   mAP@1: 0.0155\n",
      "   mAP@5: 0.0276\n",
      "   mAP@10: 0.0307\n",
      "   Recall@10: 0.0194\n",
      "   Recall@100: 0.1201\n",
      "   Recall@1000: 0.6853\n",
      "   Average mAP: 0.0246\n",
      "Complete: avg_mAP = 0.0246\n",
      "Avg retrieval time: 0.1480s (148.0ms)\n",
      "\n",
      "============================================================\n",
      "Evaluation 2/8: 4bin_global_l2\n",
      "============================================================\n",
      "üìä Found 23824 training vectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 187/187 [40:06<00:00, 12.87s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Evaluation results:\n",
      "   mAP@1: 0.0315\n",
      "   mAP@5: 0.0493\n",
      "   mAP@10: 0.0537\n",
      "   Recall@10: 0.0024\n",
      "   Recall@100: 0.0147\n",
      "   Recall@1000: 0.0876\n",
      "   Average mAP: 0.0448\n",
      "Complete: avg_mAP = 0.0448\n",
      "Avg retrieval time: 0.4041s (404.1ms)\n",
      "\n",
      "============================================================\n",
      "Evaluation 3/8: 4bin_region_cosine\n",
      "============================================================\n",
      "üìä Found 23824 training vectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 187/187 [16:05<00:00,  5.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Evaluation results:\n",
      "   mAP@1: 0.0468\n",
      "   mAP@5: 0.0753\n",
      "   mAP@10: 0.0801\n",
      "   Recall@10: 0.0042\n",
      "   Recall@100: 0.0203\n",
      "   Recall@1000: 0.0930\n",
      "   Average mAP: 0.0674\n",
      "Complete: avg_mAP = 0.0674\n",
      "Avg retrieval time: 0.1621s (162.1ms)\n",
      "\n",
      "============================================================\n",
      "Evaluation 4/8: 4bin_region_l2\n",
      "============================================================\n",
      "üìä Found 23824 training vectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 187/187 [16:03<00:00,  5.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Evaluation results:\n",
      "   mAP@1: 0.0473\n",
      "   mAP@5: 0.0745\n",
      "   mAP@10: 0.0800\n",
      "   Recall@10: 0.0043\n",
      "   Recall@100: 0.0204\n",
      "   Recall@1000: 0.0928\n",
      "   Average mAP: 0.0673\n",
      "Complete: avg_mAP = 0.0673\n",
      "Avg retrieval time: 0.1618s (161.8ms)\n",
      "\n",
      "============================================================\n",
      "Evaluation 5/8: 8bin_global_cosine\n",
      "============================================================\n",
      "üìä Found 23824 training vectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 187/187 [16:13<00:00,  5.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Evaluation results:\n",
      "   mAP@1: 0.0345\n",
      "   mAP@5: 0.0547\n",
      "   mAP@10: 0.0591\n",
      "   Recall@10: 0.0027\n",
      "   Recall@100: 0.0152\n",
      "   Recall@1000: 0.0860\n",
      "   Average mAP: 0.0494\n",
      "Complete: avg_mAP = 0.0494\n",
      "Avg retrieval time: 0.1635s (163.5ms)\n",
      "\n",
      "============================================================\n",
      "Evaluation 6/8: 8bin_global_l2\n",
      "============================================================\n",
      "üìä Found 23824 training vectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 187/187 [16:44<00:00,  5.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Evaluation results:\n",
      "   mAP@1: 0.0344\n",
      "   mAP@5: 0.0547\n",
      "   mAP@10: 0.0591\n",
      "   Recall@10: 0.0027\n",
      "   Recall@100: 0.0152\n",
      "   Recall@1000: 0.0861\n",
      "   Average mAP: 0.0494\n",
      "Complete: avg_mAP = 0.0494\n",
      "Avg retrieval time: 0.1686s (168.6ms)\n",
      "\n",
      "============================================================\n",
      "Evaluation 7/8: 8bin_region_cosine\n",
      "============================================================\n",
      "üìä Found 23824 training vectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 187/187 [17:45<00:00,  5.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Evaluation results:\n",
      "   mAP@1: 0.0426\n",
      "   mAP@5: 0.0682\n",
      "   mAP@10: 0.0732\n",
      "   Recall@10: 0.0037\n",
      "   Recall@100: 0.0187\n",
      "   Recall@1000: 0.0859\n",
      "   Average mAP: 0.0613\n",
      "Complete: avg_mAP = 0.0613\n",
      "Avg retrieval time: 0.1790s (179.0ms)\n",
      "\n",
      "============================================================\n",
      "Evaluation 8/8: 8bin_region_l2\n",
      "============================================================\n",
      "üìä Found 23824 training vectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 187/187 [17:14<00:00,  5.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Evaluation results:\n",
      "   mAP@1: 0.0441\n",
      "   mAP@5: 0.0696\n",
      "   mAP@10: 0.0741\n",
      "   Recall@10: 0.0036\n",
      "   Recall@100: 0.0188\n",
      "   Recall@1000: 0.0862\n",
      "   Average mAP: 0.0626\n",
      "Complete: avg_mAP = 0.0626\n",
      "Avg retrieval time: 0.1737s (173.7ms)\n",
      "Complete .\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-13T08:56:06.798342Z",
     "start_time": "2025-07-13T08:56:06.774633Z"
    }
   },
   "source": [
    "if evaluation_results:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Hien thi ket qua theo thu tu cau hinh\n",
    "    print(f\"\\nResults:\")\n",
    "    print(\"-\" * 120)\n",
    "    print(f\"{'STT':<4} {'Configuration':<20} {'Avg mAP':<10} {'mAP@1':<8} {'mAP@5':<8} {'mAP@10':<8} {'R@10':<8} {'R@100':<8} {'R@1000':<8} {'Avg Time(ms)':<12}\")\n",
    "    print(\"-\" * 120)\n",
    "    \n",
    "    for i, result in enumerate(evaluation_results, 1):\n",
    "        print(f\"{i:<4} {result['config_name']:<20} {result['avg_mAP']:<10.4f} \"\n",
    "              f\"{result['mAP@1']:<8.4f} {result['mAP@5']:<8.4f} {result['mAP@10']:<8.4f} \"\n",
    "              f\"{result['Recall@10']:<8.4f} {result['Recall@100']:<8.4f} {result['Recall@1000']:<8.4f} \"\n",
    "              f\"{result['avg_retrieval_time_ms']:<12.1f}\")\n",
    "    \n",
    "    # Luu ket qua\n",
    "    df = pd.DataFrame(evaluation_results)\n",
    "    csv_path = 'out/evaluation_results_v2.csv'\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"\\nKet qua chi tiet luu tai: {csv_path}\")\n",
    "    \n",
    "    # Thong ke tong quan\n",
    "    print(f\"- S·ªë tr∆∞·ªùng h·ª£p ƒë√£ test: {len(evaluation_results)}\")\n",
    "    print(f\"- Test samples: {evaluation_results[0]['tested_samples']}\")\n",
    "    print(f\"- Training samples: {evaluation_results[0]['train_samples']}\")\n",
    "    \n",
    "    avg_times = [r['avg_retrieval_time_ms'] for r in evaluation_results]\n",
    "    avg_maps = [r['avg_mAP'] for r in evaluation_results]\n",
    "    \n",
    "    print(f\"- Avg time: {np.mean(avg_times):.1f}ms (min: {np.min(avg_times):.1f}ms, max: {np.max(avg_times):.1f}ms)\")\n",
    "else:\n",
    "    print(\"Empty !!\")\n",
    "    print(\"H√£y indexing tr∆∞·ªõc!.\")\n",
    "\n",
    "# GPU memory cleanup\n",
    "if device.type == \"cuda\":\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"\\nGPU memory cleaned up\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "================================================================================\n",
      "\n",
      "Results:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "STT  Configuration        Avg mAP    mAP@1    mAP@5    mAP@10   R@10     R@100    R@1000   Avg Time(ms)\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "1    4bin_global_cosine   0.0246     0.0155   0.0276   0.0307   0.0194   0.1201   0.6853   148.0       \n",
      "2    4bin_global_l2       0.0448     0.0315   0.0493   0.0537   0.0024   0.0147   0.0876   404.1       \n",
      "3    4bin_region_cosine   0.0674     0.0468   0.0753   0.0801   0.0042   0.0203   0.0930   162.1       \n",
      "4    4bin_region_l2       0.0673     0.0473   0.0745   0.0800   0.0043   0.0204   0.0928   161.8       \n",
      "5    8bin_global_cosine   0.0494     0.0345   0.0547   0.0591   0.0027   0.0152   0.0860   163.5       \n",
      "6    8bin_global_l2       0.0494     0.0344   0.0547   0.0591   0.0027   0.0152   0.0861   168.6       \n",
      "7    8bin_region_cosine   0.0613     0.0426   0.0682   0.0732   0.0037   0.0187   0.0859   179.0       \n",
      "8    8bin_region_l2       0.0626     0.0441   0.0696   0.0741   0.0036   0.0188   0.0862   173.7       \n",
      "\n",
      "Ket qua chi tiet luu tai: out/evaluation_results_v2.csv\n",
      "- S·ªë tr∆∞·ªùng h·ª£p ƒë√£ test: 8\n",
      "- Test samples: 5956\n",
      "- Training samples: 1632\n",
      "- Avg time: 195.1ms (min: 148.0ms, max: 404.1ms)\n",
      "\n",
      "GPU memory cleaned up\n"
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
